{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "[[ 0.          3.70444683  1.        ]]\n",
      "[ -5.12127643  10.90102736]\n",
      "WEIGHTS:\n",
      "[[ 0.77488385 -0.60950492  0.        ]\n",
      " [ 1.16653334 -2.25851615  0.        ]\n",
      " [ 0.23142668  0.83642576  0.        ]]\n",
      "[]\n",
      "[[ 1.27863786  0.04809447]\n",
      " [-1.37390038  3.01170934]\n",
      " [-0.03173551 -0.25568976]]\n",
      "ACTIVATIONS OUT\n",
      "[ -5.12127643  10.90102736]\n",
      "SOFTMAX_LAYER\n",
      "[1.1005298601100161e-07, 0.99999988994701394]\n",
      "LOSS PER INSTANCE: 0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 1\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "[[ 0.          3.79479812  1.        ]]\n",
      "[ -5.2454101   11.32371548]\n",
      "WEIGHTS:\n",
      "[[ 0.77488385 -0.63962202  0.        ]\n",
      " [ 1.16653334 -2.28863325  0.        ]\n",
      " [ 0.23142668  0.86654286  0.        ]]\n",
      "[]\n",
      "[[ 1.27863786  0.04809447]\n",
      " [-1.37390038  3.04875381]\n",
      " [-0.03173551 -0.24568976]]\n",
      "ACTIVATIONS OUT\n",
      "[ -5.2454101   11.32371548]\n",
      "SOFTMAX_LAYER\n",
      "[6.3697173915179789e-08, 0.99999993630282613]\n",
      "LOSS PER INSTANCE: 0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 2\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "[[ 0.          3.88626074  1.        ]]\n",
      "[ -5.37107063  11.76003825]\n",
      "WEIGHTS:\n",
      "[[ 0.77488385 -0.67010956  0.        ]\n",
      " [ 1.16653334 -2.31912079  0.        ]\n",
      " [ 0.23142668  0.8970304   0.        ]]\n",
      "[]\n",
      "[[ 1.27863786  0.04809447]\n",
      " [-1.37390038  3.08670179]\n",
      " [-0.03173551 -0.23568976]]\n",
      "ACTIVATIONS OUT\n",
      "[ -5.37107063  11.76003825]\n",
      "SOFTMAX_LAYER\n",
      "[3.6312314407128188e-08, 0.99999996368768551]\n",
      "LOSS PER INSTANCE: 0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 3\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "[[ 0.         3.9788618  1.       ]]\n",
      "[ -5.49829526  12.21049905]\n",
      "WEIGHTS:\n",
      "[[ 0.77488385 -0.70097658  0.        ]\n",
      " [ 1.16653334 -2.3499878   0.        ]\n",
      " [ 0.23142668  0.92789742  0.        ]]\n",
      "[]\n",
      "[[ 1.27863786  0.04809447]\n",
      " [-1.37390038  3.1255644 ]\n",
      " [-0.03173551 -0.22568976]]\n",
      "ACTIVATIONS OUT\n",
      "[ -5.49829526  12.21049905]\n",
      "SOFTMAX_LAYER\n",
      "[2.0378318408770352e-08, 0.99999997962168163]\n",
      "LOSS PER INSTANCE: 0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 4\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "[[ 0.          4.07262874  1.        ]]\n",
      "[ -5.62712168  12.67561791]\n",
      "WEIGHTS:\n",
      "[[ 0.77488385 -0.73223222  0.        ]\n",
      " [ 1.16653334 -2.38124345  0.        ]\n",
      " [ 0.23142668  0.95915306  0.        ]]\n",
      "[]\n",
      "[[ 1.27863786  0.04809447]\n",
      " [-1.37390038  3.16535302]\n",
      " [-0.03173551 -0.21568976]]\n",
      "ACTIVATIONS OUT\n",
      "[ -5.62712168  12.67561791]\n",
      "SOFTMAX_LAYER\n",
      "[1.1251778803629577e-08, 0.99999998874822127]\n",
      "LOSS PER INSTANCE: 0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 5\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "[[ 0.          4.16758933  1.        ]]\n",
      "[ -5.75758808  13.15593215]\n",
      "WEIGHTS:\n",
      "[[ 0.77488385 -0.76388575  0.        ]\n",
      " [ 1.16653334 -2.41289698  0.        ]\n",
      " [ 0.23142668  0.99080659  0.        ]]\n",
      "[]\n",
      "[[ 1.27863786  0.04809447]\n",
      " [-1.37390038  3.20607931]\n",
      " [-0.03173551 -0.20568976]]\n",
      "ACTIVATIONS OUT\n",
      "[ -5.75758808  13.15593215]\n",
      "SOFTMAX_LAYER\n",
      "[6.1088931681384729e-09, 0.99999999389110683]\n",
      "LOSS PER INSTANCE: 0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 6\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "[[ 0.          4.26377171  1.        ]]\n",
      "[ -5.88973309  13.65199698]\n",
      "WEIGHTS:\n",
      "[[ 0.77488385 -0.79594655  0.        ]\n",
      " [ 1.16653334 -2.44495777  0.        ]\n",
      " [ 0.23142668  1.02286739  0.        ]]\n",
      "[]\n",
      "[[ 1.27863786  0.04809447]\n",
      " [-1.37390038  3.2477552 ]\n",
      " [-0.03173551 -0.19568976]]\n",
      "ACTIVATIONS OUT\n",
      "[ -5.88973309  13.65199698]\n",
      "SOFTMAX_LAYER\n",
      "[3.259376003055206e-09, 0.99999999674062401]\n",
      "LOSS PER INSTANCE: 0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 7\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "[[ 0.          4.36120436  1.        ]]\n",
      "[ -6.02359585  14.1643862 ]\n",
      "WEIGHTS:\n",
      "[[ 0.77488385 -0.8284241   0.        ]\n",
      " [ 1.16653334 -2.47743533  0.        ]\n",
      " [ 0.23142668  1.05534494  0.        ]]\n",
      "[]\n",
      "[[ 1.27863786  0.04809447]\n",
      " [-1.37390038  3.29039292]\n",
      " [-0.03173551 -0.18568976]]\n",
      "ACTIVATIONS OUT\n",
      "[ -6.02359585  14.1643862 ]\n",
      "SOFTMAX_LAYER\n",
      "[1.7079328676379488e-09, 0.99999999829206709]\n",
      "LOSS PER INSTANCE: 0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 8\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "[[ 0.          4.45991615  1.        ]]\n",
      "[ -6.15921601  14.69369282]\n",
      "WEIGHTS:\n",
      "[[ 0.77488385 -0.86132803  0.        ]\n",
      " [ 1.16653334 -2.51033925  0.        ]\n",
      " [ 0.23142668  1.08824887  0.        ]]\n",
      "[]\n",
      "[[ 1.27863786  0.04809447]\n",
      " [-1.37390038  3.33400496]\n",
      " [-0.03173551 -0.17568976]]\n",
      "ACTIVATIONS OUT\n",
      "[ -6.15921601  14.69369282]\n",
      "SOFTMAX_LAYER\n",
      "[8.7840896915929874e-10, 0.99999999912159099]\n",
      "LOSS PER INSTANCE: 0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 9\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "[[ 0.         4.5599363  1.       ]]\n",
      "[ -6.29663373  15.24052983]\n",
      "WEIGHTS:\n",
      "[[ 0.77488385 -0.89466808  0.        ]\n",
      " [ 1.16653334 -2.5436793   0.        ]\n",
      " [ 0.23142668  1.12158892  0.        ]]\n",
      "[]\n",
      "[[ 1.27863786  0.04809447]\n",
      " [-1.37390038  3.37860412]\n",
      " [-0.03173551 -0.16568976]]\n",
      "ACTIVATIONS OUT\n",
      "[ -6.29663373  15.24052983]\n",
      "SOFTMAX_LAYER\n",
      "[4.4312750596151588e-10, 0.99999999955687247]\n",
      "LOSS PER INSTANCE: 0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 10\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "[[ 0.          4.66129442  1.        ]]\n",
      "[ -6.4358897   15.80553086]\n",
      "WEIGHTS:\n",
      "[[ 0.77488385 -0.92845412  0.        ]\n",
      " [ 1.16653334 -2.57746535  0.        ]\n",
      " [ 0.23142668  1.15537496  0.        ]]\n",
      "[]\n",
      "[[ 1.27863786  0.04809447]\n",
      " [-1.37390038  3.42420349]\n",
      " [-0.03173551 -0.15568976]]\n",
      "ACTIVATIONS OUT\n",
      "[ -6.4358897   15.80553086]\n",
      "SOFTMAX_LAYER\n",
      "[2.1911584362951133e-10, 0.99999999978088416]\n",
      "LOSS PER INSTANCE: 0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 11\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "[[ 0.          4.76402053  1.        ]]\n",
      "[ -6.57702513  16.38935097]\n",
      "WEIGHTS:\n",
      "[[ 0.77488385 -0.96269615  0.        ]\n",
      " [ 1.16653334 -2.61170738  0.        ]\n",
      " [ 0.23142668  1.18961699  0.        ]]\n",
      "[]\n",
      "[[ 1.27863786  0.04809447]\n",
      " [-1.37390038  3.47081643]\n",
      " [-0.03173551 -0.14568976]]\n",
      "ACTIVATIONS OUT\n",
      "[ -6.57702513  16.38935097]\n",
      "SOFTMAX_LAYER\n",
      "[1.061279045234913e-10, 0.99999999989387212]\n",
      "LOSS PER INSTANCE: 0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 12\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "[[ 0.          4.86814502  1.        ]]\n",
      "[ -6.72008181  16.9926674 ]\n",
      "WEIGHTS:\n",
      "[[ 0.77488385 -0.99740432  0.        ]\n",
      " [ 1.16653334 -2.64641554  0.        ]\n",
      " [ 0.23142668  1.22432516  0.        ]]\n",
      "[]\n",
      "[[ 1.27863786  0.04809447]\n",
      " [-1.37390038  3.51845664]\n",
      " [-0.03173551 -0.13568976]]\n",
      "ACTIVATIONS OUT\n",
      "[ -6.72008181  16.9926674 ]\n",
      "SOFTMAX_LAYER\n",
      "[5.0313423155948442e-11, 0.99999999994968658]\n",
      "LOSS PER INSTANCE: 0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 13\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "[[ 0.          4.97369872  1.        ]]\n",
      "[ -6.86510208  17.61618038]\n",
      "WEIGHTS:\n",
      "[[ 0.77488385 -1.03258888  0.        ]\n",
      " [ 1.16653334 -2.68160011  0.        ]\n",
      " [ 0.23142668  1.25950972  0.        ]]\n",
      "[]\n",
      "[[ 1.27863786  0.04809447]\n",
      " [-1.37390038  3.56713809]\n",
      " [-0.03173551 -0.12568976]]\n",
      "ACTIVATIONS OUT\n",
      "[ -6.86510208  17.61618038]\n",
      "SOFTMAX_LAYER\n",
      "[2.3329966644410411e-11, 0.99999999997667011]\n",
      "LOSS PER INSTANCE: 0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 14\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "[[ 0.          5.08071286  1.        ]]\n",
      "[ -7.01212885  18.26061395]\n",
      "WEIGHTS:\n",
      "[[ 0.77488385 -1.06826027  0.        ]\n",
      " [ 1.16653334 -2.71727149  0.        ]\n",
      " [ 0.23142668  1.29518111  0.        ]]\n",
      "[]\n",
      "[[ 1.27863786  0.04809447]\n",
      " [-1.37390038  3.61687507]\n",
      " [-0.03173551 -0.11568976]]\n",
      "ACTIVATIONS OUT\n",
      "[ -7.01212885  18.26061395]\n",
      "SOFTMAX_LAYER\n",
      "[1.0572732809865463e-11, 0.99999999998942724]\n",
      "LOSS PER INSTANCE: 0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 15\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "[[ 0.          5.18921912  1.        ]]\n",
      "[ -7.16120563  18.92671684]\n",
      "WEIGHTS:\n",
      "[[ 0.77488385 -1.10442902  0.        ]\n",
      " [ 1.16653334 -2.75344024  0.        ]\n",
      " [ 0.23142668  1.33134986  0.        ]]\n",
      "[]\n",
      "[[ 1.27863786  0.04809447]\n",
      " [-1.37390038  3.6676822 ]\n",
      " [-0.03173551 -0.10568976]]\n",
      "ACTIVATIONS OUT\n",
      "[ -7.16120563  18.92671684]\n",
      "SOFTMAX_LAYER\n",
      "[4.6790666069536989e-12, 0.99999999999532097]\n",
      "LOSS PER INSTANCE: 0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 16\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "[[ 0.          5.29924958  1.        ]]\n",
      "[ -7.31237653  19.61526329]\n",
      "WEIGHTS:\n",
      "[[ 0.77488385 -1.14110584  0.        ]\n",
      " [ 1.16653334 -2.79011706  0.        ]\n",
      " [ 0.23142668  1.36802668  0.        ]]\n",
      "[]\n",
      "[[ 1.27863786  0.04809447]\n",
      " [-1.37390038  3.71957439]\n",
      " [-0.03173551 -0.09568976]]\n",
      "ACTIVATIONS OUT\n",
      "[ -7.31237653  19.61526329]\n",
      "SOFTMAX_LAYER\n",
      "[2.0205733209557856e-12, 0.99999999999797951]\n",
      "LOSS PER INSTANCE: 0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 17\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "[[ 0.          5.41083681  1.        ]]\n",
      "[ -7.46568627  20.32705405]\n",
      "WEIGHTS:\n",
      "[[ 0.77488385 -1.17830158  0.        ]\n",
      " [ 1.16653334 -2.82731281  0.        ]\n",
      " [ 0.23142668  1.40522242  0.        ]]\n",
      "[]\n",
      "[[ 1.27863786  0.04809447]\n",
      " [-1.37390038  3.77256689]\n",
      " [-0.03173551 -0.08568976]]\n",
      "ACTIVATIONS OUT\n",
      "[ -7.46568627  20.32705405]\n",
      "SOFTMAX_LAYER\n",
      "[8.5068003840113077e-13, 0.99999999999914924]\n",
      "LOSS PER INSTANCE: 0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 18\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "[[ 0.          5.52401382  1.        ]]\n",
      "[ -7.62118021  21.06291725]\n",
      "WEIGHTS:\n",
      "[[ 0.77488385 -1.21602725  0.        ]\n",
      " [ 1.16653334 -2.86503848  0.        ]\n",
      " [ 0.23142668  1.44294809  0.        ]]\n",
      "[]\n",
      "[[ 1.27863786  0.04809447]\n",
      " [-1.37390038  3.82667526]\n",
      " [-0.03173551 -0.07568976]]\n",
      "ACTIVATIONS OUT\n",
      "[ -7.62118021  21.06291725]\n",
      "SOFTMAX_LAYER\n",
      "[3.4886287642942483e-13, 0.99999999999965117]\n",
      "LOSS PER INSTANCE: 0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 19\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "[[ 0.          5.63881408  1.        ]]\n",
      "[ -7.77890432  21.82370942]\n",
      "WEIGHTS:\n",
      "[[ 0.77488385 -1.254294    0.        ]\n",
      " [ 1.16653334 -2.90330523  0.        ]\n",
      " [ 0.23142668  1.48121484  0.        ]]\n",
      "[]\n",
      "[[ 1.27863786  0.04809447]\n",
      " [-1.37390038  3.8819154 ]\n",
      " [-0.03173551 -0.06568976]]\n",
      "ACTIVATIONS OUT\n",
      "[ -7.77890432  21.82370942]\n",
      "SOFTMAX_LAYER\n",
      "[1.3923492970341446e-13, 0.99999999999986067]\n",
      "LOSS PER INSTANCE: 0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 20\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "[[ 0.          5.75527154  1.        ]]\n",
      "[ -7.93890527  22.6103165 ]\n",
      "WEIGHTS:\n",
      "[[ 0.77488385 -1.29311316  0.        ]\n",
      " [ 1.16653334 -2.94212438  0.        ]\n",
      " [ 0.23142668  1.520034    0.        ]]\n",
      "[]\n",
      "[[ 1.27863786  0.04809447]\n",
      " [-1.37390038  3.93830354]\n",
      " [-0.03173551 -0.05568976]]\n",
      "ACTIVATIONS OUT\n",
      "[ -7.93890527  22.6103165 ]\n",
      "SOFTMAX_LAYER\n",
      "[5.4030819809714786e-14, 0.99999999999994593]\n",
      "LOSS PER INSTANCE: 0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 21\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "[[ 0.          5.87342065  1.        ]]\n",
      "[ -8.10123038  23.42365485]\n",
      "WEIGHTS:\n",
      "[[ 0.77488385 -1.33249619  0.        ]\n",
      " [ 1.16653334 -2.98150742  0.        ]\n",
      " [ 0.23142668  1.55941703  0.        ]]\n",
      "[]\n",
      "[[ 1.27863786  0.04809447]\n",
      " [-1.37390038  3.99585625]\n",
      " [-0.03173551 -0.04568976]]\n",
      "ACTIVATIONS OUT\n",
      "[ -8.10123038  23.42365485]\n",
      "SOFTMAX_LAYER\n",
      "[2.0366495432131235e-14, 0.99999999999997957]\n",
      "LOSS PER INSTANCE: 0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 22\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "[[ 0.          5.99329633  1.        ]]\n",
      "[ -8.26592763  24.26467237]\n",
      "WEIGHTS:\n",
      "[[ 0.77488385 -1.37245476  0.        ]\n",
      " [ 1.16653334 -3.02146598  0.        ]\n",
      " [ 0.23142668  1.5993756   0.        ]]\n",
      "[]\n",
      "[[ 1.27863786  0.04809447]\n",
      " [-1.37390038  4.05459046]\n",
      " [-0.03173551 -0.03568976]]\n",
      "ACTIVATIONS OUT\n",
      "[ -8.26592763  24.26467237]\n",
      "SOFTMAX_LAYER\n",
      "[7.4497196238079996e-15, 0.99999999999999245]\n",
      "LOSS PER INSTANCE: 0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 23\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "[[ 0.          6.11493405  1.        ]]\n",
      "[ -8.43304573  25.1343496 ]\n",
      "WEIGHTS:\n",
      "[[ 0.77488385 -1.41300066  0.        ]\n",
      " [ 1.16653334 -3.06201189  0.        ]\n",
      " [ 0.23142668  1.6399215   0.        ]]\n",
      "[]\n",
      "[[ 1.27863786  0.04809447]\n",
      " [-1.37390038  4.11452342]\n",
      " [-0.03173551 -0.02568976]]\n",
      "ACTIVATIONS OUT\n",
      "[ -8.43304573  25.1343496 ]\n",
      "SOFTMAX_LAYER\n",
      "[2.6415901475464284e-15, 0.99999999999999745]\n",
      "LOSS PER INSTANCE: 0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 24\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "[[ 0.          6.23836975  1.        ]]\n",
      "[ -8.60263409  26.03370088]\n",
      "WEIGHTS:\n",
      "[[ 0.77488385 -1.45414589  0.        ]\n",
      " [ 1.16653334 -3.10315712  0.        ]\n",
      " [ 0.23142668  1.68106673  0.        ]]\n",
      "[]\n",
      "[[ 1.27863786  0.04809447]\n",
      " [-1.37390038  4.17567276]\n",
      " [-0.03173551 -0.01568976]]\n",
      "ACTIVATIONS OUT\n",
      "[ -8.60263409  26.03370088]\n",
      "SOFTMAX_LAYER\n",
      "[9.0704920515485218e-16, 0.99999999999999911]\n",
      "LOSS PER INSTANCE: 0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 25\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "[[ 0.          6.36363993  1.        ]]\n",
      "[ -8.77474284  26.96377556]\n",
      "WEIGHTS:\n",
      "[[ 0.77488385 -1.49590262  0.        ]\n",
      " [ 1.16653334 -3.14491385  0.        ]\n",
      " [ 0.23142668  1.72282346  0.        ]]\n",
      "[]\n",
      "[[ 1.27863786  0.04809447]\n",
      " [-1.37390038  4.23805646]\n",
      " [-0.03173551 -0.00568976]]\n",
      "ACTIVATIONS OUT\n",
      "[ -8.77474284  26.96377556]\n",
      "SOFTMAX_LAYER\n",
      "[3.012719267624551e-16, 0.99999999999999967]\n",
      "LOSS PER INSTANCE: 0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 26\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "[[ 0.          6.49078163  1.        ]]\n",
      "[ -8.94942286  27.92565921]\n",
      "WEIGHTS:\n",
      "[[ 0.77488385 -1.53828319  0.        ]\n",
      " [ 1.16653334 -3.18729441  0.        ]\n",
      " [ 0.23142668  1.76520403  0.        ]]\n",
      "[]\n",
      "[[ 1.27863786  0.04809447]\n",
      " [-1.37390038  4.30169286]\n",
      " [-0.03173551  0.00431024]]\n",
      "ACTIVATIONS OUT\n",
      "[ -8.94942286  27.92565921]\n",
      "SOFTMAX_LAYER\n",
      "[9.6684161443114065e-17, 0.99999999999999978]\n",
      "LOSS PER INSTANCE: 0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 27\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "[[ 0.          6.61983241  1.        ]]\n",
      "[ -9.12672579  28.92047492]\n",
      "WEIGHTS:\n",
      "[[ 0.77488385 -1.58130011  0.        ]\n",
      " [ 1.16653334 -3.23031134  0.        ]\n",
      " [ 0.23142668  1.80822096  0.        ]]\n",
      "[]\n",
      "[[ 1.27863786  0.04809447]\n",
      " [-1.37390038  4.36660068]\n",
      " [-0.03173551  0.01431024]]\n",
      "ACTIVATIONS OUT\n",
      "[ -9.12672579  28.92047492]\n",
      "SOFTMAX_LAYER\n",
      "[2.9944059724995664e-17, 1.0]\n",
      "LOSS PER INSTANCE: -0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 28\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "[[ 0.          6.75083043  1.        ]]\n",
      "[ -9.30670402  29.94938463]\n",
      "WEIGHTS:\n",
      "[[ 0.77488385 -1.62496612  0.        ]\n",
      " [ 1.16653334 -3.27397735  0.        ]\n",
      " [ 0.23142668  1.85188696  0.        ]]\n",
      "[]\n",
      "[[ 1.27863786  0.04809447]\n",
      " [-1.37390038  4.432799  ]\n",
      " [-0.03173551  0.02431024]]\n",
      "ACTIVATIONS OUT\n",
      "[ -9.30670402  29.94938463]\n",
      "SOFTMAX_LAYER\n",
      "[8.9391725632648524e-18, 1.0]\n",
      "LOSS PER INSTANCE: -0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 29\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "[[ 0.         6.8838144  1.       ]]\n",
      "[ -9.48941074  31.01359047]\n",
      "WEIGHTS:\n",
      "[[ 0.77488385 -1.66929411  0.        ]\n",
      " [ 1.16653334 -3.31830534  0.        ]\n",
      " [ 0.23142668  1.89621495  0.        ]]\n",
      "[]\n",
      "[[ 1.27863786  0.04809447]\n",
      " [-1.37390038  4.5003073 ]\n",
      " [-0.03173551  0.03431024]]\n",
      "ACTIVATIONS OUT\n",
      "[ -9.48941074  31.01359047]\n",
      "SOFTMAX_LAYER\n",
      "[2.5690352948755834e-18, 1.0]\n",
      "LOSS PER INSTANCE: -0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 30\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "[[ 0.          7.01882362  1.        ]]\n",
      "[ -9.67489996  32.11433624]\n",
      "WEIGHTS:\n",
      "[[ 0.77488385 -1.71429718  0.        ]\n",
      " [ 1.16653334 -3.36330841  0.        ]\n",
      " [ 0.23142668  1.94121803  0.        ]]\n",
      "[]\n",
      "[[ 1.27863786  0.04809447]\n",
      " [-1.37390038  4.56914545]\n",
      " [-0.03173551  0.04431024]]\n",
      "ACTIVATIONS OUT\n",
      "[ -9.67489996  32.11433624]\n",
      "SOFTMAX_LAYER\n",
      "[7.0984792152008814e-19, 1.0]\n",
      "LOSS PER INSTANCE: -0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 31\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "[[ 0.          7.15589798  1.        ]]\n",
      "[ -9.86322648  33.2529088 ]\n",
      "WEIGHTS:\n",
      "[[ 0.77488385 -1.75998864  0.        ]\n",
      " [ 1.16653334 -3.40899987  0.        ]\n",
      " [ 0.23142668  1.98690948  0.        ]]\n",
      "[]\n",
      "[[ 1.27863786  0.04809447]\n",
      " [-1.37390038  4.63933368]\n",
      " [-0.03173551  0.05431024]]\n",
      "ACTIVATIONS OUT\n",
      "[ -9.86322648  33.2529088 ]\n",
      "SOFTMAX_LAYER\n",
      "[1.883216999050993e-19, 1.0]\n",
      "LOSS PER INSTANCE: -0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 32\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "[[ 0.          7.29507799  1.        ]]\n",
      "[-10.05444595  34.43063965]\n",
      "WEIGHTS:\n",
      "[[ 0.77488385 -1.80638198  0.        ]\n",
      " [ 1.16653334 -3.4553932   0.        ]\n",
      " [ 0.23142668  2.03330282  0.        ]]\n",
      "[]\n",
      "[[ 1.27863786  0.04809447]\n",
      " [-1.37390038  4.71089266]\n",
      " [-0.03173551  0.06431024]]\n",
      "ACTIVATIONS OUT\n",
      "[-10.05444595  34.43063965]\n",
      "SOFTMAX_LAYER\n",
      "[4.7904112203684129e-20, 1.0]\n",
      "LOSS PER INSTANCE: -0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 33\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "[[ 0.          7.43640477  1.        ]]\n",
      "[-10.24861487  35.64890647]\n",
      "WEIGHTS:\n",
      "[[ 0.77488385 -1.8534909   0.        ]\n",
      " [ 1.16653334 -3.50250213  0.        ]\n",
      " [ 0.23142668  2.08041174  0.        ]]\n",
      "[]\n",
      "[[ 1.27863786  0.04809447]\n",
      " [-1.37390038  4.78384344]\n",
      " [-0.03173551  0.07431024]]\n",
      "ACTIVATIONS OUT\n",
      "[-10.24861487  35.64890647]\n",
      "SOFTMAX_LAYER\n",
      "[1.1667014826421265e-20, 1.0]\n",
      "LOSS PER INSTANCE: -0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 34\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "[[ 0.          7.57992008  1.        ]]\n",
      "[-10.4457906   36.90913475]\n",
      "WEIGHTS:\n",
      "[[ 0.77488385 -1.90132934  0.        ]\n",
      " [ 1.16653334 -3.55034056  0.        ]\n",
      " [ 0.23142668  2.12825018  0.        ]]\n",
      "[]\n",
      "[[ 1.27863786  0.04809447]\n",
      " [-1.37390038  4.85820749]\n",
      " [-0.03173551  0.08431024]]\n",
      "ACTIVATIONS OUT\n",
      "[-10.4457906   36.90913475]\n",
      "SOFTMAX_LAYER\n",
      "[2.7165470399568564e-21, 1.0]\n",
      "LOSS PER INSTANCE: -0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 35\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "[[ 0.         7.7256663  1.       ]]\n",
      "[-10.64603139  38.21279948]\n",
      "WEIGHTS:\n",
      "[[ 0.77488385 -1.94991141  0.        ]\n",
      " [ 1.16653334 -3.59892264  0.        ]\n",
      " [ 0.23142668  2.17683225  0.        ]]\n",
      "[]\n",
      "[[ 1.27863786  0.04809447]\n",
      " [-1.37390038  4.93400669]\n",
      " [-0.03173551  0.09431024]]\n",
      "ACTIVATIONS OUT\n",
      "[-10.64603139  38.21279948]\n",
      "SOFTMAX_LAYER\n",
      "[6.0378088340411029e-22, 1.0]\n",
      "LOSS PER INSTANCE: -0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 36\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "[[ 0.         7.8736865  1.       ]]\n",
      "[-10.8493964   39.56142689]\n",
      "WEIGHTS:\n",
      "[[ 0.77488385 -1.99925148  0.        ]\n",
      " [ 1.16653334 -3.64826271  0.        ]\n",
      " [ 0.23142668  2.22617232  0.        ]]\n",
      "[]\n",
      "[[ 1.27863786  0.04809447]\n",
      " [-1.37390038  5.01126336]\n",
      " [-0.03173551  0.10431024]]\n",
      "ACTIVATIONS OUT\n",
      "[-10.8493964   39.56142689]\n",
      "SOFTMAX_LAYER\n",
      "[1.2789619263214707e-22, 1.0]\n",
      "LOSS PER INSTANCE: -0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 37\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "[[ 0.         8.0240244  1.       ]]\n",
      "[-11.0559457   40.95659623]\n",
      "WEIGHTS:\n",
      "[[ 0.77488385 -2.04936411  0.        ]\n",
      " [ 1.16653334 -3.69837534  0.        ]\n",
      " [ 0.23142668  2.27628495  0.        ]]\n",
      "[]\n",
      "[[ 1.27863786  0.04809447]\n",
      " [-1.37390038  5.09000022]\n",
      " [-0.03173551  0.11431024]]\n",
      "ACTIVATIONS OUT\n",
      "[-11.0559457   40.95659623]\n",
      "SOFTMAX_LAYER\n",
      "[2.5777455748105485e-23, 1.0]\n",
      "LOSS PER INSTANCE: -0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 38\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "[[ 0.          8.17672441  1.        ]]\n",
      "[-11.2657403   42.39994166]\n",
      "WEIGHTS:\n",
      "[[ 0.77488385 -2.10026411  0.        ]\n",
      " [ 1.16653334 -3.74927534  0.        ]\n",
      " [ 0.23142668  2.32718496  0.        ]]\n",
      "[]\n",
      "[[ 1.27863786  0.04809447]\n",
      " [-1.37390038  5.17024046]\n",
      " [-0.03173551  0.12431024]]\n",
      "ACTIVATIONS OUT\n",
      "[-11.2657403   42.39994166]\n",
      "SOFTMAX_LAYER\n",
      "[4.9350375161558324e-24, 1.0]\n",
      "LOSS PER INSTANCE: -0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 39\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "[[ 0.          8.33183162  1.        ]]\n",
      "[-11.47884216  43.89315416]\n",
      "WEIGHTS:\n",
      "[[ 0.77488385 -2.15196652  0.        ]\n",
      " [ 1.16653334 -3.80097775  0.        ]\n",
      " [ 0.23142668  2.37888736  0.        ]]\n",
      "[]\n",
      "[[ 1.27863786  0.04809447]\n",
      " [-1.37390038  5.25200771]\n",
      " [-0.03173551  0.13431024]]\n",
      "ACTIVATIONS OUT\n",
      "[-11.47884216  43.89315416]\n",
      "SOFTMAX_LAYER\n",
      "[8.9587526435911429e-25, 1.0]\n",
      "LOSS PER INSTANCE: -0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 40\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "[[ 0.          8.48939186  1.        ]]\n",
      "[-11.69531422  45.43798355]\n",
      "WEIGHTS:\n",
      "[[ 0.77488385 -2.2044866   0.        ]\n",
      " [ 1.16653334 -3.85349782  0.        ]\n",
      " [ 0.23142668  2.43140744  0.        ]]\n",
      "[]\n",
      "[[ 1.27863786  0.04809447]\n",
      " [-1.37390038  5.33532602]\n",
      " [-0.03173551  0.14431024]]\n",
      "ACTIVATIONS OUT\n",
      "[-11.69531422  45.43798355]\n",
      "SOFTMAX_LAYER\n",
      "[1.5393027545034141e-25, 1.0]\n",
      "LOSS PER INSTANCE: -0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 41\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "[[ 0.          8.64945164  1.        ]]\n",
      "[-11.91522042  47.0362405 ]\n",
      "WEIGHTS:\n",
      "[[ 0.77488385 -2.25783986  0.        ]\n",
      " [ 1.16653334 -3.90685108  0.        ]\n",
      " [ 0.23142668  2.4847607   0.        ]]\n",
      "[]\n",
      "[[ 1.27863786  0.04809447]\n",
      " [-1.37390038  5.42021994]\n",
      " [-0.03173551  0.15431024]]\n",
      "ACTIVATIONS OUT\n",
      "[-11.91522042  47.0362405 ]\n",
      "SOFTMAX_LAYER\n",
      "[2.498652283015767e-26, 1.0]\n",
      "LOSS PER INSTANCE: -0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 42\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "[[ 0.          8.81205824  1.        ]]\n",
      "[-12.13862568  48.68979874]\n",
      "WEIGHTS:\n",
      "[[ 0.77488385 -2.31204206  0.        ]\n",
      " [ 1.16653334 -3.96105328  0.        ]\n",
      " [ 0.23142668  2.5389629   0.        ]]\n",
      "[]\n",
      "[[ 1.27863786  0.04809447]\n",
      " [-1.37390038  5.50671446]\n",
      " [-0.03173551  0.16431024]]\n",
      "ACTIVATIONS OUT\n",
      "[-12.13862568  48.68979874]\n",
      "SOFTMAX_LAYER\n",
      "[3.8242909710046466e-27, 1.0]\n",
      "LOSS PER INSTANCE: -0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 43\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "[[ 0.          8.97725967  1.        ]]\n",
      "[-12.365596    50.40059722]\n",
      "WEIGHTS:\n",
      "[[ 0.77488385 -2.3671092   0.        ]\n",
      " [ 1.16653334 -4.01612043  0.        ]\n",
      " [ 0.23142668  2.59403004  0.        ]]\n",
      "[]\n",
      "[[ 1.27863786  0.04809447]\n",
      " [-1.37390038  5.59483504]\n",
      " [-0.03173551  0.17431024]]\n",
      "ACTIVATIONS OUT\n",
      "[-12.365596    50.40059722]\n",
      "SOFTMAX_LAYER\n",
      "[5.5079328476205768e-28, 1.0]\n",
      "LOSS PER INSTANCE: -0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 44\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "[[ 0.          9.14510472  1.        ]]\n",
      "[-12.59619838  52.17064239]\n",
      "WEIGHTS:\n",
      "[[ 0.77488385 -2.42305755  0.        ]\n",
      " [ 1.16653334 -4.07206878  0.        ]\n",
      " [ 0.23142668  2.64997839  0.        ]]\n",
      "[]\n",
      "[[ 1.27863786  0.04809447]\n",
      " [-1.37390038  5.68460764]\n",
      " [-0.03173551  0.18431024]]\n",
      "ACTIVATIONS OUT\n",
      "[-12.59619838  52.17064239]\n",
      "SOFTMAX_LAYER\n",
      "[7.4493511148665754e-29, 1.0]\n",
      "LOSS PER INSTANCE: -0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 45\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "[[ 0.          9.31564295  1.        ]]\n",
      "[-12.83050091  54.00201061]\n",
      "WEIGHTS:\n",
      "[[ 0.77488385 -2.47990363  0.        ]\n",
      " [ 1.16653334 -4.12891485  0.        ]\n",
      " [ 0.23142668  2.70682447  0.        ]]\n",
      "[]\n",
      "[[ 1.27863786  0.04809447]\n",
      " [-1.37390038  5.77605869]\n",
      " [-0.03173551  0.19431024]]\n",
      "ACTIVATIONS OUT\n",
      "[-12.83050091  54.00201061]\n",
      "SOFTMAX_LAYER\n",
      "[9.4408050910527494e-30, 1.0]\n",
      "LOSS PER INSTANCE: -0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 46\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "[[ 0.          9.48892471  1.        ]]\n",
      "[-13.06857279  55.89685058]\n",
      "WEIGHTS:\n",
      "[[ 0.77488385 -2.53766421  0.        ]\n",
      " [ 1.16653334 -4.18667544  0.        ]\n",
      " [ 0.23142668  2.76458505  0.        ]]\n",
      "[]\n",
      "[[ 1.27863786  0.04809447]\n",
      " [-1.37390038  5.86921512]\n",
      " [-0.03173551  0.20431024]]\n",
      "ACTIVATIONS OUT\n",
      "[-13.06857279  55.89685058]\n",
      "SOFTMAX_LAYER\n",
      "[1.1186576286891754e-30, 1.0]\n",
      "LOSS PER INSTANCE: -0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 47\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "[[ 0.          9.66500116  1.        ]]\n",
      "[-13.3104843   57.85738584]\n",
      "WEIGHTS:\n",
      "[[ 0.77488385 -2.59635637  0.        ]\n",
      " [ 1.16653334 -4.24536759  0.        ]\n",
      " [ 0.23142668  2.82327721  0.        ]]\n",
      "[]\n",
      "[[ 1.27863786  0.04809447]\n",
      " [-1.37390038  5.96410436]\n",
      " [-0.03173551  0.21431024]]\n",
      "ACTIVATIONS OUT\n",
      "[-13.3104843   57.85738584]\n",
      "SOFTMAX_LAYER\n",
      "[1.2364788973300494e-31, 1.0]\n",
      "LOSS PER INSTANCE: -0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 48\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "[[ 0.          9.84392429  1.        ]]\n",
      "[-13.55630686  59.88591747]\n",
      "WEIGHTS:\n",
      "[[ 0.77488385 -2.65599741  0.        ]\n",
      " [ 1.16653334 -4.30500864  0.        ]\n",
      " [ 0.23142668  2.88291825  0.        ]]\n",
      "[]\n",
      "[[ 1.27863786  0.04809447]\n",
      " [-1.37390038  6.06075437]\n",
      " [-0.03173551  0.22431024]]\n",
      "ACTIVATIONS OUT\n",
      "[-13.55630686  59.88591747]\n",
      "SOFTMAX_LAYER\n",
      "[1.2718832214673862e-32, 1.0]\n",
      "LOSS PER INSTANCE: -0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 49\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "[[  0.          10.02574693   1.        ]]\n",
      "[-13.80611304  61.98482671]\n",
      "WEIGHTS:\n",
      "[[ 0.77488385 -2.71660495  0.        ]\n",
      " [ 1.16653334 -4.36561618  0.        ]\n",
      " [ 0.23142668  2.94352579  0.        ]]\n",
      "[]\n",
      "[[ 1.27863786  0.04809447]\n",
      " [-1.37390038  6.15919362]\n",
      " [-0.03173551  0.23431024]]\n",
      "ACTIVATIONS OUT\n",
      "[-13.80611304  61.98482671]\n",
      "SOFTMAX_LAYER\n",
      "[1.2145435406891551e-33, 1.0]\n",
      "LOSS PER INSTANCE: -0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nclass Node(Object):\\n    def __init__(self):\\n        \\n    def \\n'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class NN():\n",
    "    \"\"\"\n",
    "    Class for a neural network. Requires input/output sizes, number of hidden layers, and number of neurons\n",
    "    at each layer (we assume all hidden layers are of the same size)\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, num_HL, hidden_size, output_size):\n",
    "        # Initialize by setting random \n",
    "        self.input_size = input_size\n",
    "        self.hidden_layers = num_HL\n",
    "        # NOTE we are assuming all hidden layers are the same size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        # Activations for each neuron\n",
    "        # + 1 for bias neuron\n",
    "        self.activations_in = np.ones(self.input_size + 1)\n",
    "        # Hidden can comprise multiple layers, so we have a matrix\n",
    "        # + 1 for bias neuron\n",
    "        self.activations_hidden = np.ones((self.hidden_layers, self.hidden_size + 1))\n",
    "        self.activations_out = np.ones(self.output_size)\n",
    "        # Weights of all the edges, randomized for good results\n",
    "        # PLUS ONE FOR BIASES\n",
    "        self.weights_in = np.random.randn(self.input_size + 1, self.hidden_size)\n",
    "        self.weights_in = np.column_stack((self.weights_in, np.zeros(self.input_size + 1)))\n",
    "        # We will only have hidden weights if there are multiple hidden layers\n",
    "        if self.hidden_layers > 1:\n",
    "            self.weights_hidden = np.random.randn(self.hidden_layers - 1, self.hidden_size + 1, self.hidden_size + 1)\n",
    "            # Set the weights corresponding with next layers biases to 0\n",
    "            for weights in self.weights_hidden:\n",
    "                weights[-1] = 0.0\n",
    "        else:\n",
    "            self.weights_hidden = []\n",
    "        # No plus one for output, as it should not have a bias parameter\n",
    "        self.weights_out = np.random.randn(self.hidden_size + 1, self.output_size)\n",
    "        # To be valued when train() is called\n",
    "        self.learning_rate = 0.0\n",
    "\n",
    "        # Instantiate deltas for holding gradients\n",
    "        self.deltas_in = []\n",
    "        self.Deltas_hidden = []\n",
    "        self.deltas_out = []\n",
    "    \n",
    "    def _sigmoid(self, x):\n",
    "        \"\"\"\n",
    "        Sigmoid function for calculating a distribution over 2 classes\n",
    "        \"\"\"\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def _derivative_sigmoid(self, x):\n",
    "        \"\"\"\n",
    "        Derivative of the sigmoid function where x = the output of the sigmoid\n",
    "        \n",
    "        This can be used in backpropogation, wherein we would have \n",
    "        already computed the sigmoid in the forward pass, and we can draw upon its cached value\n",
    "        \"\"\"\n",
    "        return x * (1.0 - x)\n",
    "    \n",
    "    def _softmax(self, x):\n",
    "        exponentials = [np.exp(p) for p in x]\n",
    "        denominator = sum(exponentials)\n",
    "        return [p / denominator for p in exponentials]\n",
    "    \n",
    "    def _relu(self, x):\n",
    "        \"\"\"\n",
    "        relu function used for activation\n",
    "        \"\"\"\n",
    "        return max(x, 0.0)\n",
    "    \n",
    "    def _derivative_relu(self, x):\n",
    "        \"\"\"\n",
    "        Derivative of the relu function, the input will be the output of the relu function.\n",
    "        This is because in practice we will have already performed this computation in the forward pass\n",
    "        so in the backward pass, we need to find its derivative drawing upon the cached relu(x).\n",
    "        \"\"\"\n",
    "        return 1 if x > 0.0 else 0.0\n",
    "    \n",
    "    def _binary_cross_ent(self, y_hat, y):\n",
    "        \"\"\"\n",
    "        This basically finds the negative of the log probability of class1 - its inverse\n",
    "        \"\"\"\n",
    "        return (-y * np.log(y_hat)) - ((1 - y) * np.log(1 - y_hat))\n",
    "    \n",
    "    def _negative_log_likelihood(self, y_hat):\n",
    "        return -np.log(y_hat)\n",
    "    \n",
    "    def _derivative_negative_log_likelihood(self, y_hat):\n",
    "        return -1/y_hat\n",
    "    \n",
    "    def _derivative_binary_cross_ent(self, y_hat, y):\n",
    "        \"\"\"\n",
    "        Derivative of binary cross-entropy\n",
    "        \n",
    "        This description is misleading. \n",
    "        This is the part of the partial derivative of binary cross-entropy \n",
    "        w.r.t the parameters of our function. In practice, the other part is \n",
    "        the dot product of this and the activations (activate(w, x))\n",
    "        \"\"\"\n",
    "        #return -(y / y_hat) - ((1 - y) / (1 - y_hat))\n",
    "        return (y_hat - y)\n",
    "\n",
    "    def _activate(self, x):\n",
    "        \"\"\"\n",
    "        RELU for non-linear activation function\n",
    "        \"\"\"\n",
    "        return self._relu(x)\n",
    "    \n",
    "    def _activate_vector(self, X):\n",
    "        \"\"\"\n",
    "        Run on a numpy vector\n",
    "        \"\"\"\n",
    "        activations = np.vectorize(self._activate)\n",
    "        return activations(X)\n",
    "    \n",
    "    def _derivative_activation(self, x):\n",
    "        \"\"\"\n",
    "        Compute the derivative of the activation function given the activation output\n",
    "        \n",
    "        x: activate(node)\n",
    "        \"\"\"\n",
    "        return self._derivative_relu(x)\n",
    "    \n",
    "    def _derivative_vector_activation(self, X):\n",
    "        \"\"\"\n",
    "        Derivative for each scalar in a numpy vector\n",
    "        \"\"\"\n",
    "        derivative_activations = np.vectorize(self._derivative_activation)\n",
    "        return derivative_activations(X)\n",
    "\n",
    "    def _loss(self, y_hat, y):\n",
    "        \"\"\"\n",
    "        y_hat: sofmax vector\n",
    "        y:     one-hot vector for the target\n",
    "        \n",
    "        Here we will plug in the negative_log_likelihood\n",
    "        in order to be able to compare the proability of our output at\n",
    "        the correct class, to 1.\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        Get the index of the correct class \n",
    "        (numpy will return a tuple of the index in each dimension)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Get the first (and only) dim, and the first (and only) index\n",
    "        i = np.where(y==1)[0][0]\n",
    "        return self._negative_log_likelihood(y_hat[i])\n",
    "    \n",
    "    def _derivative_loss(self, y_hat, y):\n",
    "        \"\"\"\n",
    "        This will be used in backprop for finding L'(output_layer_node)\n",
    "        \"\"\"\n",
    "        # Get the first (and only) dim, and the first (and only) index\n",
    "        i = np.where(y==1)[0][0]\n",
    "        return self._derivative_negative_log_likelihood(y_hat[i])\n",
    "    \n",
    "    def _targets_to_one_hots(self, targets):\n",
    "        \"\"\"\n",
    "        Interpret a vector of targets into a matrix\n",
    "        of one-hot representations\n",
    "        \"\"\"\n",
    "        # Get the number of unique target classes\n",
    "        num_classes = len(set(targets))\n",
    "        # Instantiate a matrix of one-hot vectors\n",
    "        # with one row per target, and one col per class\n",
    "        one_hots = np.zeros((len(targets), num_classes))\n",
    "        for i, one_hot in enumerate(one_hots):\n",
    "            # Set the one-hot vector to hae a 1 at its corresponding target slot\n",
    "            t = targets[i]\n",
    "            one_hot[t] = 1\n",
    "            \n",
    "        return one_hots\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Forward pass: Calculate the activations of each neuron\n",
    "        \"\"\"\n",
    "        if len(inputs) != self.input_size:\n",
    "          raise Exception(\"That is not the size of the input layer... try %i\" % self.input_size)\n",
    "        \n",
    "        # Set input activations, no need to actually calculate anything\n",
    "        for i, input in enumerate(inputs):\n",
    "            self.activations_in[i] = input\n",
    "        # Add 1 for BIAS \n",
    "        np.append(self.activations_in, 1.0)\n",
    "        \n",
    "        # calculate the activations for each hidden layer\n",
    "        for h_layer_i in range(self.hidden_layers):\n",
    "            # Need to take previous layer activation value * weights for a given layer\n",
    "            # Starting with input layer X first hidden layer\n",
    "            if h_layer_i == 0:\n",
    "                \"\"\"\n",
    "                # Loop over the layer\n",
    "                for h_dim_j in range(self.hidden_size):\n",
    "                    # Loop over neurons in the layer before it\n",
    "                    for k in range(self.input_size):\n",
    "                        # Sum [f_k * w_k_j for k in input layer]\n",
    "                        self.activations_hidden[h_layer_i][h_dim_j] += self.activations_in[k] * self.weights_in[k][h_dim_j]\n",
    "                    # h(sum from above), aka run the nonlinear activation function\n",
    "                    self.activations_hidden[h_layer_i][h_dim_j] = self._activate(self.activations_hidden[h_layer_i][h_dim_j])\n",
    "                \"\"\"\n",
    "                # multiply the previous layer's activations by its weight vector for this layer's activations\n",
    "                self.activations_hidden[h_layer_i] = self._activate_vector(self.activations_in.T.dot(self.weights_in))\n",
    "                # Reset bias activation to 1.0\n",
    "                self.activations_hidden[h_layer_i][-1] = 1.0\n",
    "            else:\n",
    "                if h_layer_i == 0:\n",
    "                    # Loop over the layer\n",
    "                    for h_dim_j in range(self.hidden_size):\n",
    "                        # Loop over neurons in the layer before it\n",
    "                        for k in range(self.hidden_size):\n",
    "                            # Sum [f_k * w_k_j for k in previous hidden layer]\n",
    "                            self.activations_hidden[h_layer_i][h_dim_j] += self.activations_hidden[h_layer_i - 1][k]\\\n",
    "                            * self.weights_hidden[h_layer_i][k][h_dim_j]\n",
    "                        # h(sum from above), aka run the nonlinear activation function\n",
    "                        self.activations_hidden[h_layer_i][h_dim_j] = self._activate(self.activations_hidden[h_layer_i][h_dim_j])\n",
    "                # multiply the previous layer's activations by its weight vector for this layer's activations\n",
    "                #self.activations_hidden[h_layer_i] = self._activate_vector(self.activations_hidden[h_layer_i - 1].T.dot(self.weights_hidden[h_layer_i - 1]))\n",
    "                # Reset bias activation to 1.0\n",
    "                #self.activations_hidden[h_layer_i][-1] = 1.0\n",
    "\n",
    "                \n",
    "        # Output activations will be the dot product of the final hidden layer, and the output weights\n",
    "        \"\"\"\n",
    "        for i in range(self.output_size):\n",
    "            for j in range(self.hidden_size):\n",
    "                print(self.weights_out)\n",
    "                print(self.weights_out[j][i])\n",
    "                self.activations_out[i] += self.activations_hidden[-1][j] * self.weights_out[j][i]\n",
    "            # h(sum from above), aka run the nonlinear activation function\n",
    "            self.activations_out[i] = self._activate(self.activations_out[i])\n",
    "        \"\"\"\n",
    "        self.activations_out = self.activations_hidden[-1].T.dot(self.weights_out)\n",
    "        # [:-1] because this one should not have a bias parameter\n",
    "        #self.activations_out = self._activate_vector(self.activations_out)\n",
    "        \n",
    "        #Print all of the weights, to see updates\n",
    "\n",
    "        print(\"ACTIVATIONS\")\n",
    "        print(self.activations_in)\n",
    "        print(self.activations_hidden)\n",
    "        print(self.activations_out)\n",
    "        \n",
    "        print(\"WEIGHTS:\")\n",
    "        print(self.weights_in)\n",
    "        print(self.weights_hidden)\n",
    "        print(self.weights_out)\n",
    "\n",
    "\n",
    "    def backward(self, targets):\n",
    "        \"\"\"\n",
    "        Backpropogation for finding the partial derivative of the each node w.r.t the loss function,\n",
    "        and updating weights based on those gradients\n",
    "        \"\"\"\n",
    "        if len(targets) != len(self.activations_out):\n",
    "            raise Exception(\"Your labels are not the same size as your output layer!\")\n",
    "        # Calculate loss - there will be a value for each node in the output layer\n",
    "        # Take the simoid of the activations of the output layer, because we are doing 2 class classification\n",
    "        # ***If we have >2 classes, we would use softmax***\n",
    "        \"\"\"\n",
    "        print(\"ACTIVATIONS IN\")\n",
    "        print(self.activations_in)\n",
    "        \n",
    "        print(\"ACTIVATIONS HIDDEN\")\n",
    "        print(self.activations_hidden)\n",
    "        \"\"\"\n",
    "        print(\"ACTIVATIONS OUT\")\n",
    "        print(self.activations_out)\n",
    "        \n",
    "        print(\"SOFTMAX_LAYER\")\n",
    "        print(self._softmax(self.activations_out))\n",
    "        \"\"\"\n",
    "        print(\"TARGETS\")\n",
    "        print(targets)\n",
    "        \"\"\"\n",
    "        loss = self._loss(self._softmax(self.activations_out), targets)\n",
    "        \n",
    "        \"\"\"\n",
    "        Now we need to calculate the partial derivative of the loss w.r.t each weight.\n",
    "        Think of this as finding the amount that each node contributes to a change in the final loss.\n",
    "        \n",
    "        Each node has a value \"delta\", which represents the partial derivative of the loss w.r.t. its value:\n",
    "        Use the partial derivative of the loss function, in our case binary cross-entropy\n",
    "        \"\"\"\n",
    "        self.deltas_out = np.zeros([self.output_size])\n",
    "        derivative_loss = self._derivative_loss(self._softmax(self.activations_out), targets)\n",
    "        print(\"LOSS PER INSTANCE: %2f\" % loss)\n",
    "        print(\"DERIVATIVE LOSS: %2f\" % derivative_loss)\n",
    "        for i, activation_out in enumerate(self.activations_out):\n",
    "            self.deltas_out[i] = derivative_loss * self._derivative_activation(activation_out)\n",
    "        \n",
    "        \"\"\"\n",
    "        Find derivative of activation (activation was found in the forward pass) * derivative of the inner function,\n",
    "        which is the parameter w\n",
    "        \"\"\"\n",
    "        self.Deltas_hidden = np.zeros([self.hidden_layers, self.hidden_size + 1])\n",
    "        \n",
    "        # Traverse in the reverse, as each delta depends on the layer in the direction of the loss\n",
    "        for h_layer_i in reversed(range(self.hidden_layers)):\n",
    "            # If it is the last hidden layer, then we look at the activations and deltas\n",
    "            # of the output layer, not the next hidden layer\n",
    "            if h_layer_i == self.hidden_layers - 1:\n",
    "                # Loop over each in hidden activation, +1 for bias\n",
    "                for h_dim_j in range(self.hidden_size + 1):\n",
    "                    for k, delta_out in enumerate(self.deltas_out):\n",
    "                        self.Deltas_hidden[h_layer_i][h_dim_j] += delta_out * self._derivative_activation(self.activations_out[k]) * self.weights_out[h_dim_j][k]\n",
    "            else:\n",
    "                # Do the same to find the hidden deltas\n",
    "                for h_dim_j in range(self.hidden_size + 1):\n",
    "                    for k, delta_h in enumerate(self.Deltas_hidden[h_layer_i + 1]):\n",
    "                        self.Deltas_hidden[h_layer_i][h_dim_j] += delta_h * self._derivative_activation(self.activations_hidden[h_layer_i + 1][k]) * self.weights_hidden[h_layer_i][h_dim_j][k]\n",
    "                        \n",
    "        \"\"\"\n",
    "        Now just do the same for L'(input layer)\n",
    "        \"\"\"\n",
    "        self.deltas_in = np.zeros([self.input_size+1])\n",
    "        #### Need deltas_hidden[0].dot(der_act_hidden[0] * weights_in)\n",
    "        # Loop over each in input activation, +1 for bias\n",
    "        for i_dim in range(self.input_size + 1):\n",
    "            for k, delta_h in enumerate(self.Deltas_hidden[0]):\n",
    "                self.deltas_in[i_dim] += delta_h * self._derivative_activation(self.activations_hidden[0][k]) * self.weights_in[i_dim][k]\n",
    "        \n",
    "        self.update_weights()\n",
    "        return loss\n",
    "        \n",
    "    def update_weights(self):\n",
    "        print(\"UPDATING WEIGHTS\")\n",
    "        # Now we can use the deltas to adjust each weight by L'(w_i_j)\n",
    "        # These weights are the edges shared between last hidden layer, and output layer\n",
    "        # Rows of weights_out correponds with length of last hidden layer\n",
    "        for i in range(len(self.weights_out)):\n",
    "            # Cols of weights_out correspinds with length of output layer\n",
    "            for j in range(len(self.weights_out[i])):\n",
    "                self.weights_out[i][j] -= self.activations_hidden[-1][i]\\\n",
    "                * self._derivative_activation(self.activations_out[j])\\\n",
    "                * self.deltas_out[j]\\\n",
    "                * self.learning_rate\n",
    "                    \n",
    "        # Loop over each hidden layer\n",
    "        for w_i in reversed(range(len(self.weights_hidden))):\n",
    "            # Rows (i) in the weights for this layer will correspond to the size of the layer BEFORE (hidden or input)\n",
    "            for i in range(len(self.weights_hidden[w_i])):\n",
    "                # Cols (j) in these weights will correspond to the size of hidden layer w_i\n",
    "                for j in range(len(self.weights_hidden[w_i][i])):\n",
    "                    # We do not want to update the dummy 0 weight going TO the extra bias dimension\n",
    "                    if j == len(self.weights_hidden[w_i][i]) - 1:\n",
    "                        continue\n",
    "                    else:\n",
    "                        # + 1 for layer before, because we are looping in reverse\n",
    "                        self.weights_hidden[w_i][i][j] -= self.activations_hidden[w_i + 1][i]\\\n",
    "                        * self._derivative_activation(self.activations_hidden[w_i][j])\\\n",
    "                        * self.Deltas_hidden[w_i][j]\\\n",
    "                        * self.learning_rate\n",
    "                        \n",
    "            #self.weights_hidden[w_i] -= self.activations_hidden[w_i].T.dot(self.Deltas_hidden[w_i]) * self.learning_rate\n",
    "        # Rows (i) of weights_in corresponds to size of the input layer\n",
    "        for i in range(len(self.weights_in)):\n",
    "            # Cols (j) corresponds to size of the first hidden layer (layer above input layer)\n",
    "            for j in range(len(self.weights_in[i])):\n",
    "                # We do not want to update the dummy 0 weight going TO the extra bias dimension\n",
    "                if j == len(self.weights_in[i]) - 1:\n",
    "                    continue\n",
    "                else:\n",
    "                    \"\"\"\n",
    "                    print(\"act, deriv_act, delta, weight update val\")\n",
    "                    print(self.activations_in[i])\n",
    "                    print(self._derivative_activation(self.activations_hidden[0][j]))\n",
    "                    print(self.Deltas_hidden[0][j])\n",
    "                    print(self.activations_in[i]\\\n",
    "                    * self._derivative_activation(self.activations_hidden[0][j])\\\n",
    "                    * self.Deltas_hidden[0][j]\\\n",
    "                    * self.learning_rate)\n",
    "                    \"\"\"\n",
    "                    \n",
    "                    self.weights_in[i][j] -= self.activations_in[i]\\\n",
    "                    * self._derivative_activation(self.activations_hidden[0][j])\\\n",
    "                    * self.Deltas_hidden[0][j]\\\n",
    "                    * self.learning_rate\n",
    "    \n",
    "    def train(self, inputs, targets, epochs=50, lr=.01):\n",
    "        self.learning_rate = lr\n",
    "        one_hot_targets = self._targets_to_one_hots(targets)\n",
    "        for e in range(epochs):\n",
    "            print(\"EPOCH %i\" % e)\n",
    "            \"\"\"\n",
    "            SGD - randomize the order of the training samples, and \n",
    "            \"\"\"\n",
    "            in_out = list(zip(inputs, one_hot_targets))\n",
    "            random.shuffle(in_out)\n",
    "            # For tracking average loss over SGD, just for logging\n",
    "            losses = []\n",
    "            \n",
    "            for inp, target in in_out:\n",
    "                if inp == [-1, -1]:\n",
    "                    print(\"INPUT: \")\n",
    "                    print(inp)\n",
    "                    print(\"TARGET: \")\n",
    "                    print(target)\n",
    "                    self.forward(inp)\n",
    "                    losses.append(self.backward(target))\n",
    "\n",
    "            print(\"LOSS: %2f\" % (sum(losses)/len(losses)))\n",
    "            \n",
    "\"\"\"\n",
    "Note that the 4th param, the size of the output layer, should be the\n",
    "number of classes\n",
    "\"\"\"\n",
    "MLP = NN(2, 1, 2, 2)\n",
    "xor_inputs = [[1, 1], [-1, 1], [-1, -1], [1, -1]]\n",
    "xor_labels = ([1, 0, 1, 0])\n",
    "MLP.train(xor_inputs, xor_labels)\n",
    "\"\"\"\n",
    "class Node(Object):\n",
    "    def __init__(self):\n",
    "        \n",
    "    def \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.80581961  0.71509287]\n",
      "SOFTMAX_LAYER\n",
      "[0.52266614001681522, 0.47733385998318484]\n",
      "LOSS PER INSTANCE: 0.739539\n",
      "DERIVATIVE LOSS: -2.094970\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.739539\n",
      "EPOCH 1\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.80683483  0.71673427]\n",
      "SOFTMAX_LAYER\n",
      "[0.52250991542131076, 0.47749008457868924]\n",
      "LOSS PER INSTANCE: 0.739212\n",
      "DERIVATIVE LOSS: -2.094284\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.739212\n",
      "EPOCH 2\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.80784171  0.71836364]\n",
      "SOFTMAX_LAYER\n",
      "[0.52235460364477726, 0.47764539635522268]\n",
      "LOSS PER INSTANCE: 0.738887\n",
      "DERIVATIVE LOSS: -2.093603\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.738887\n",
      "EPOCH 3\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.80884031  0.71998104]\n",
      "SOFTMAX_LAYER\n",
      "[0.5222002115218447, 0.47779978847815541]\n",
      "LOSS PER INSTANCE: 0.738563\n",
      "DERIVATIVE LOSS: -2.092927\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.738563\n",
      "EPOCH 4\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.80983073  0.72158653]\n",
      "SOFTMAX_LAYER\n",
      "[0.52204674540619644, 0.47795325459380339]\n",
      "LOSS PER INSTANCE: 0.738242\n",
      "DERIVATIVE LOSS: -2.092255\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.738242\n",
      "EPOCH 5\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.81081302  0.72318014]\n",
      "SOFTMAX_LAYER\n",
      "[0.52189421118321033, 0.47810578881678972]\n",
      "LOSS PER INSTANCE: 0.737923\n",
      "DERIVATIVE LOSS: -2.091587\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.737923\n",
      "EPOCH 6\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.81178728  0.72476194]\n",
      "SOFTMAX_LAYER\n",
      "[0.52174261428246294, 0.47825738571753706]\n",
      "LOSS PER INSTANCE: 0.737606\n",
      "DERIVATIVE LOSS: -2.090924\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.737606\n",
      "EPOCH 7\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.81275357  0.72633198]\n",
      "SOFTMAX_LAYER\n",
      "[0.52159195969009797, 0.47840804030990197]\n",
      "LOSS PER INSTANCE: 0.737291\n",
      "DERIVATIVE LOSS: -2.090266\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.737291\n",
      "EPOCH 8\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.81371197  0.72789033]\n",
      "SOFTMAX_LAYER\n",
      "[0.5214422519610481, 0.47855774803895185]\n",
      "LOSS PER INSTANCE: 0.736978\n",
      "DERIVATIVE LOSS: -2.089612\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.736978\n",
      "EPOCH 9\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.81466256  0.72943703]\n",
      "SOFTMAX_LAYER\n",
      "[0.52129349523110169, 0.47870650476889831]\n",
      "LOSS PER INSTANCE: 0.736668\n",
      "DERIVATIVE LOSS: -2.088963\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.736668\n",
      "EPOCH 10\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.8156054   0.73097215]\n",
      "SOFTMAX_LAYER\n",
      "[0.52114569322881354, 0.47885430677118651]\n",
      "LOSS PER INSTANCE: 0.736359\n",
      "DERIVATIVE LOSS: -2.088318\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.736359\n",
      "EPOCH 11\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.81654058  0.73249574]\n",
      "SOFTMAX_LAYER\n",
      "[0.52099884928724971, 0.4790011507127504]\n",
      "LOSS PER INSTANCE: 0.736052\n",
      "DERIVATIVE LOSS: -2.087678\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.736052\n",
      "EPOCH 12\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.81746816  0.73400788]\n",
      "SOFTMAX_LAYER\n",
      "[0.52085296635556477, 0.47914703364443523]\n",
      "LOSS PER INSTANCE: 0.735748\n",
      "DERIVATIVE LOSS: -2.087042\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.735748\n",
      "EPOCH 13\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.81838822  0.73550862]\n",
      "SOFTMAX_LAYER\n",
      "[0.52070804701040529, 0.47929195298959476]\n",
      "LOSS PER INSTANCE: 0.735445\n",
      "DERIVATIVE LOSS: -2.086411\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.735445\n",
      "EPOCH 14\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.81930083  0.73699803]\n",
      "SOFTMAX_LAYER\n",
      "[0.52056409346713639, 0.47943590653286355]\n",
      "LOSS PER INSTANCE: 0.735145\n",
      "DERIVATIVE LOSS: -2.085785\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.735145\n",
      "EPOCH 15\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.82020605  0.73847616]\n",
      "SOFTMAX_LAYER\n",
      "[0.52042110759088767, 0.47957889240911228]\n",
      "LOSS PER INSTANCE: 0.734847\n",
      "DERIVATIVE LOSS: -2.085163\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.734847\n",
      "EPOCH 16\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.82110397  0.73994308]\n",
      "SOFTMAX_LAYER\n",
      "[0.52027909090741598, 0.47972090909258391]\n",
      "LOSS PER INSTANCE: 0.734551\n",
      "DERIVATIVE LOSS: -2.084545\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.734551\n",
      "EPOCH 17\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.82199465  0.74139887]\n",
      "SOFTMAX_LAYER\n",
      "[0.52013804461378099, 0.4798619553862189]\n",
      "LOSS PER INSTANCE: 0.734257\n",
      "DERIVATIVE LOSS: -2.083933\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.734257\n",
      "EPOCH 18\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.82287816  0.74284358]\n",
      "SOFTMAX_LAYER\n",
      "[0.51999796958883482, 0.48000203041116524]\n",
      "LOSS PER INSTANCE: 0.733965\n",
      "DERIVATIVE LOSS: -2.083325\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.733965\n",
      "EPOCH 19\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.82375456  0.74427729]\n",
      "SOFTMAX_LAYER\n",
      "[0.51985886640351764, 0.48014113359648242]\n",
      "LOSS PER INSTANCE: 0.733675\n",
      "DERIVATIVE LOSS: -2.082721\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.733675\n",
      "EPOCH 20\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.82462393  0.74570005]\n",
      "SOFTMAX_LAYER\n",
      "[0.5197207353309663, 0.48027926466903365]\n",
      "LOSS PER INSTANCE: 0.733388\n",
      "DERIVATIVE LOSS: -2.082122\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.733388\n",
      "EPOCH 21\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.82548634  0.74711194]\n",
      "SOFTMAX_LAYER\n",
      "[0.51958357635642638, 0.48041642364357373]\n",
      "LOSS PER INSTANCE: 0.733102\n",
      "DERIVATIVE LOSS: -2.081528\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.733102\n",
      "EPOCH 22\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.82634185  0.74851303]\n",
      "SOFTMAX_LAYER\n",
      "[0.51944738918697109, 0.48055261081302886]\n",
      "LOSS PER INSTANCE: 0.732819\n",
      "DERIVATIVE LOSS: -2.080938\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.732819\n",
      "EPOCH 23\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.82719052  0.74990338]\n",
      "SOFTMAX_LAYER\n",
      "[0.51931217326102896, 0.48068782673897115]\n",
      "LOSS PER INSTANCE: 0.732537\n",
      "DERIVATIVE LOSS: -2.080352\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.732537\n",
      "EPOCH 24\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.82803243  0.75128307]\n",
      "SOFTMAX_LAYER\n",
      "[0.51917792775771188, 0.48082207224228812]\n",
      "LOSS PER INSTANCE: 0.732258\n",
      "DERIVATIVE LOSS: -2.079771\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.732258\n",
      "EPOCH 25\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.82886764  0.75265216]\n",
      "SOFTMAX_LAYER\n",
      "[0.51904465160595403, 0.48095534839404586]\n",
      "LOSS PER INSTANCE: 0.731981\n",
      "DERIVATIVE LOSS: -2.079195\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.731981\n",
      "EPOCH 26\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.82969621  0.75401073]\n",
      "SOFTMAX_LAYER\n",
      "[0.51891234349345228, 0.48108765650654772]\n",
      "LOSS PER INSTANCE: 0.731706\n",
      "DERIVATIVE LOSS: -2.078623\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.731706\n",
      "EPOCH 27\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.83051821  0.75535884]\n",
      "SOFTMAX_LAYER\n",
      "[0.51878100187541465, 0.48121899812458546]\n",
      "LOSS PER INSTANCE: 0.731433\n",
      "DERIVATIVE LOSS: -2.078056\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.731433\n",
      "EPOCH 28\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.8313337   0.75669657]\n",
      "SOFTMAX_LAYER\n",
      "[0.51865062498311609, 0.48134937501688391]\n",
      "LOSS PER INSTANCE: 0.731162\n",
      "DERIVATIVE LOSS: -2.077493\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.731162\n",
      "EPOCH 29\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.83214274  0.75802399]\n",
      "SOFTMAX_LAYER\n",
      "[0.51852121083226099, 0.48147878916773912]\n",
      "LOSS PER INSTANCE: 0.730893\n",
      "DERIVATIVE LOSS: -2.076935\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.730893\n",
      "EPOCH 30\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.8329454   0.75934116]\n",
      "SOFTMAX_LAYER\n",
      "[0.51839275723115452, 0.48160724276884537]\n",
      "LOSS PER INSTANCE: 0.730626\n",
      "DERIVATIVE LOSS: -2.076381\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.730626\n",
      "EPOCH 31\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.83374174  0.76064817]\n",
      "SOFTMAX_LAYER\n",
      "[0.51826526178868582, 0.48173473821131413]\n",
      "LOSS PER INSTANCE: 0.730362\n",
      "DERIVATIVE LOSS: -2.075831\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.730362\n",
      "EPOCH 32\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.83453182  0.76194508]\n",
      "SOFTMAX_LAYER\n",
      "[0.51813872192212007, 0.48186127807788004]\n",
      "LOSS PER INSTANCE: 0.730099\n",
      "DERIVATIVE LOSS: -2.075286\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.730099\n",
      "EPOCH 33\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.8353157   0.76323196]\n",
      "SOFTMAX_LAYER\n",
      "[0.5180131348647059, 0.4819868651352941]\n",
      "LOSS PER INSTANCE: 0.729838\n",
      "DERIVATIVE LOSS: -2.074745\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.729838\n",
      "EPOCH 34\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.83609343  0.76450889]\n",
      "SOFTMAX_LAYER\n",
      "[0.51788849767309753, 0.48211150232690242]\n",
      "LOSS PER INSTANCE: 0.729580\n",
      "DERIVATIVE LOSS: -2.074209\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.729580\n",
      "EPOCH 35\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.83686509  0.76577594]\n",
      "SOFTMAX_LAYER\n",
      "[0.51776480723459239, 0.48223519276540761]\n",
      "LOSS PER INSTANCE: 0.729323\n",
      "DERIVATIVE LOSS: -2.073677\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.729323\n",
      "EPOCH 36\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.83763072  0.76703317]\n",
      "SOFTMAX_LAYER\n",
      "[0.51764206027418869, 0.48235793972581137]\n",
      "LOSS PER INSTANCE: 0.729069\n",
      "DERIVATIVE LOSS: -2.073149\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.729069\n",
      "EPOCH 37\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.83839039  0.76828068]\n",
      "SOFTMAX_LAYER\n",
      "[0.51752025336146368, 0.48247974663853632]\n",
      "LOSS PER INSTANCE: 0.728816\n",
      "DERIVATIVE LOSS: -2.072626\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.728816\n",
      "EPOCH 38\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.83914416  0.76951851]\n",
      "SOFTMAX_LAYER\n",
      "[0.51739938291727472, 0.48260061708272528]\n",
      "LOSS PER INSTANCE: 0.728566\n",
      "DERIVATIVE LOSS: -2.072107\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.728566\n",
      "EPOCH 39\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.83989207  0.77074676]\n",
      "SOFTMAX_LAYER\n",
      "[0.51727944522028591, 0.48272055477971398]\n",
      "LOSS PER INSTANCE: 0.728317\n",
      "DERIVATIVE LOSS: -2.071592\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.728317\n",
      "EPOCH 40\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.8406342   0.77196548]\n",
      "SOFTMAX_LAYER\n",
      "[0.51716043641332277, 0.48283956358667734]\n",
      "LOSS PER INSTANCE: 0.728071\n",
      "DERIVATIVE LOSS: -2.071081\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.728071\n",
      "EPOCH 41\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.84137059  0.77317476]\n",
      "SOFTMAX_LAYER\n",
      "[0.51704235250955588, 0.48295764749044401]\n",
      "LOSS PER INSTANCE: 0.727826\n",
      "DERIVATIVE LOSS: -2.070575\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.727826\n",
      "EPOCH 42\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.84210129  0.77437466]\n",
      "SOFTMAX_LAYER\n",
      "[0.51692518939851984, 0.48307481060148016]\n",
      "LOSS PER INSTANCE: 0.727584\n",
      "DERIVATIVE LOSS: -2.070073\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.727584\n",
      "EPOCH 43\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.84282638  0.77556526]\n",
      "SOFTMAX_LAYER\n",
      "[0.51680894285196388, 0.48319105714803595]\n",
      "LOSS PER INSTANCE: 0.727343\n",
      "DERIVATIVE LOSS: -2.069575\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.727343\n",
      "EPOCH 44\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.84354589  0.77674663]\n",
      "SOFTMAX_LAYER\n",
      "[0.51669360852954482, 0.48330639147045529]\n",
      "LOSS PER INSTANCE: 0.727104\n",
      "DERIVATIVE LOSS: -2.069081\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.727104\n",
      "EPOCH 45\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.84425988  0.77791883]\n",
      "SOFTMAX_LAYER\n",
      "[0.51657918198435571, 0.48342081801564424]\n",
      "LOSS PER INSTANCE: 0.726868\n",
      "DERIVATIVE LOSS: -2.068591\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.726868\n",
      "EPOCH 46\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.84496841  0.77908195]\n",
      "SOFTMAX_LAYER\n",
      "[0.51646565866830274, 0.48353434133169731]\n",
      "LOSS PER INSTANCE: 0.726633\n",
      "DERIVATIVE LOSS: -2.068105\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.726633\n",
      "EPOCH 47\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.84567153  0.78023606]\n",
      "SOFTMAX_LAYER\n",
      "[0.51635303393732401, 0.48364696606267604]\n",
      "LOSS PER INSTANCE: 0.726400\n",
      "DERIVATIVE LOSS: -2.067624\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.726400\n",
      "EPOCH 48\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.84636929  0.78138122]\n",
      "SOFTMAX_LAYER\n",
      "[0.51624130305646032, 0.48375869694353968]\n",
      "LOSS PER INSTANCE: 0.726169\n",
      "DERIVATIVE LOSS: -2.067146\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.726169\n",
      "EPOCH 49\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.84706175  0.7825175 ]\n",
      "SOFTMAX_LAYER\n",
      "[0.51613046120477557, 0.48386953879522454]\n",
      "LOSS PER INSTANCE: 0.725940\n",
      "DERIVATIVE LOSS: -2.066673\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.725940\n",
      "EPOCH 50\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.84774894  0.78364499]\n",
      "SOFTMAX_LAYER\n",
      "[0.51602050348013251, 0.48397949651986749]\n",
      "LOSS PER INSTANCE: 0.725713\n",
      "DERIVATIVE LOSS: -2.066203\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.725713\n",
      "EPOCH 51\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.84843094  0.78476374]\n",
      "SOFTMAX_LAYER\n",
      "[0.51591142490382558, 0.48408857509617448]\n",
      "LOSS PER INSTANCE: 0.725487\n",
      "DERIVATIVE LOSS: -2.065738\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.725487\n",
      "EPOCH 52\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.84910777  0.78587383]\n",
      "SOFTMAX_LAYER\n",
      "[0.51580322042507409, 0.48419677957492602]\n",
      "LOSS PER INSTANCE: 0.725264\n",
      "DERIVATIVE LOSS: -2.065276\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.725264\n",
      "EPOCH 53\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.8497795   0.78697533]\n",
      "SOFTMAX_LAYER\n",
      "[0.51569588492537732, 0.48430411507462257]\n",
      "LOSS PER INSTANCE: 0.725042\n",
      "DERIVATIVE LOSS: -2.064818\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.725042\n",
      "EPOCH 54\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.85044618  0.78806831]\n",
      "SOFTMAX_LAYER\n",
      "[0.51558941322273744, 0.48441058677726245]\n",
      "LOSS PER INSTANCE: 0.724822\n",
      "DERIVATIVE LOSS: -2.064364\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.724822\n",
      "EPOCH 55\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.85110785  0.78915284]\n",
      "SOFTMAX_LAYER\n",
      "[0.51548380007574868, 0.48451619992425143]\n",
      "LOSS PER INSTANCE: 0.724604\n",
      "DERIVATIVE LOSS: -2.063914\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.724604\n",
      "EPOCH 56\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.85176456  0.79022899]\n",
      "SOFTMAX_LAYER\n",
      "[0.51537904018755853, 0.48462095981244158]\n",
      "LOSS PER INSTANCE: 0.724388\n",
      "DERIVATIVE LOSS: -2.063468\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.724388\n",
      "EPOCH 57\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.85241635  0.79129682]\n",
      "SOFTMAX_LAYER\n",
      "[0.515275128209705, 0.48472487179029505]\n",
      "LOSS PER INSTANCE: 0.724174\n",
      "DERIVATIVE LOSS: -2.063026\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.724174\n",
      "EPOCH 58\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.85306329  0.79235641]\n",
      "SOFTMAX_LAYER\n",
      "[0.51517205874582783, 0.48482794125417206]\n",
      "LOSS PER INSTANCE: 0.723961\n",
      "DERIVATIVE LOSS: -2.062587\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.723961\n",
      "EPOCH 59\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.8537054   0.79340783]\n",
      "SOFTMAX_LAYER\n",
      "[0.51506982635526233, 0.48493017364473773]\n",
      "LOSS PER INSTANCE: 0.723750\n",
      "DERIVATIVE LOSS: -2.062153\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.723750\n",
      "EPOCH 60\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.85434274  0.79445114]\n",
      "SOFTMAX_LAYER\n",
      "[0.5149684255565129, 0.48503157444348699]\n",
      "LOSS PER INSTANCE: 0.723541\n",
      "DERIVATIVE LOSS: -2.061721\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.723541\n",
      "EPOCH 61\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.85497536  0.79548642]\n",
      "SOFTMAX_LAYER\n",
      "[0.51486785083061404, 0.48513214916938585]\n",
      "LOSS PER INSTANCE: 0.723334\n",
      "DERIVATIVE LOSS: -2.061294\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.723334\n",
      "EPOCH 62\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.85560329  0.79651372]\n",
      "SOFTMAX_LAYER\n",
      "[0.51476809662437828, 0.48523190337562172]\n",
      "LOSS PER INSTANCE: 0.723128\n",
      "DERIVATIVE LOSS: -2.060870\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.723128\n",
      "EPOCH 63\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.85622659  0.79753312]\n",
      "SOFTMAX_LAYER\n",
      "[0.51466915735353447, 0.48533084264646542]\n",
      "LOSS PER INSTANCE: 0.722924\n",
      "DERIVATIVE LOSS: -2.060450\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.722924\n",
      "EPOCH 64\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.8568453   0.79854468]\n",
      "SOFTMAX_LAYER\n",
      "[0.51457102740576011, 0.48542897259423989]\n",
      "LOSS PER INSTANCE: 0.722722\n",
      "DERIVATIVE LOSS: -2.060034\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.722722\n",
      "EPOCH 65\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.85745945  0.79954847]\n",
      "SOFTMAX_LAYER\n",
      "[0.51447370114360846, 0.48552629885639159]\n",
      "LOSS PER INSTANCE: 0.722522\n",
      "DERIVATIVE LOSS: -2.059621\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.722522\n",
      "EPOCH 66\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.85806911  0.80054456]\n",
      "SOFTMAX_LAYER\n",
      "[0.51437717290733431, 0.48562282709266558]\n",
      "LOSS PER INSTANCE: 0.722323\n",
      "DERIVATIVE LOSS: -2.059211\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.722323\n",
      "EPOCH 67\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.8586743   0.80153301]\n",
      "SOFTMAX_LAYER\n",
      "[0.51428143701762208, 0.48571856298237787]\n",
      "LOSS PER INSTANCE: 0.722126\n",
      "DERIVATIVE LOSS: -2.058805\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.722126\n",
      "EPOCH 68\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.85927507  0.80251388]\n",
      "SOFTMAX_LAYER\n",
      "[0.51418648777821507, 0.48581351222178493]\n",
      "LOSS PER INSTANCE: 0.721930\n",
      "DERIVATIVE LOSS: -2.058403\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.721930\n",
      "EPOCH 69\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.85987146  0.80348725]\n",
      "SOFTMAX_LAYER\n",
      "[0.51409231947845202, 0.48590768052154792]\n",
      "LOSS PER INSTANCE: 0.721737\n",
      "DERIVATIVE LOSS: -2.058004\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.721737\n",
      "EPOCH 70\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.86046352  0.80445318]\n",
      "SOFTMAX_LAYER\n",
      "[0.51399892639571221, 0.48600107360428785]\n",
      "LOSS PER INSTANCE: 0.721544\n",
      "DERIVATIVE LOSS: -2.057609\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.721544\n",
      "EPOCH 71\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.86105128  0.80541172]\n",
      "SOFTMAX_LAYER\n",
      "[0.51390630279777016, 0.48609369720222989]\n",
      "LOSS PER INSTANCE: 0.721354\n",
      "DERIVATIVE LOSS: -2.057217\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.721354\n",
      "EPOCH 72\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.86163479  0.80636295]\n",
      "SOFTMAX_LAYER\n",
      "[0.5138144429450644, 0.4861855570549356]\n",
      "LOSS PER INSTANCE: 0.721165\n",
      "DERIVATIVE LOSS: -2.056828\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.721165\n",
      "EPOCH 73\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.86221408  0.80730693]\n",
      "SOFTMAX_LAYER\n",
      "[0.51372334109288187, 0.48627665890711808]\n",
      "LOSS PER INSTANCE: 0.720978\n",
      "DERIVATIVE LOSS: -2.056443\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.720978\n",
      "EPOCH 74\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.8627892   0.80824372]\n",
      "SOFTMAX_LAYER\n",
      "[0.5136329914934592, 0.48636700850654074]\n",
      "LOSS PER INSTANCE: 0.720792\n",
      "DERIVATIVE LOSS: -2.056061\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.720792\n",
      "EPOCH 75\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.86336019  0.80917338]\n",
      "SOFTMAX_LAYER\n",
      "[0.51354338839800384, 0.4864566116019961]\n",
      "LOSS PER INSTANCE: 0.720608\n",
      "DERIVATIVE LOSS: -2.055682\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.720608\n",
      "EPOCH 76\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.86392708  0.81009598]\n",
      "SOFTMAX_LAYER\n",
      "[0.51345452605863817, 0.48654547394136183]\n",
      "LOSS PER INSTANCE: 0.720425\n",
      "DERIVATIVE LOSS: -2.055306\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.720425\n",
      "EPOCH 77\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.86448991  0.81101157]\n",
      "SOFTMAX_LAYER\n",
      "[0.51336639873026779, 0.48663360126973215]\n",
      "LOSS PER INSTANCE: 0.720244\n",
      "DERIVATIVE LOSS: -2.054934\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.720244\n",
      "EPOCH 78\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.86504872  0.81192022]\n",
      "SOFTMAX_LAYER\n",
      "[0.51327900067237531, 0.48672099932762469]\n",
      "LOSS PER INSTANCE: 0.720064\n",
      "DERIVATIVE LOSS: -2.054565\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.720064\n",
      "EPOCH 79\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.86560355  0.81282199]\n",
      "SOFTMAX_LAYER\n",
      "[0.51319232615074406, 0.48680767384925605]\n",
      "LOSS PER INSTANCE: 0.719886\n",
      "DERIVATIVE LOSS: -2.054199\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.719886\n",
      "EPOCH 80\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.86615443  0.81371694]\n",
      "SOFTMAX_LAYER\n",
      "[0.51310636943911059, 0.48689363056088941]\n",
      "LOSS PER INSTANCE: 0.719710\n",
      "DERIVATIVE LOSS: -2.053837\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.719710\n",
      "EPOCH 81\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.86670141  0.81460513]\n",
      "SOFTMAX_LAYER\n",
      "[0.51302112482075168, 0.48697887517924832]\n",
      "LOSS PER INSTANCE: 0.719535\n",
      "DERIVATIVE LOSS: -2.053477\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.719535\n",
      "EPOCH 82\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.86724452  0.81548662]\n",
      "SOFTMAX_LAYER\n",
      "[0.51293658659000363, 0.48706341340999648]\n",
      "LOSS PER INSTANCE: 0.719361\n",
      "DERIVATIVE LOSS: -2.053121\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.719361\n",
      "EPOCH 83\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.86778379  0.81636146]\n",
      "SOFTMAX_LAYER\n",
      "[0.51285274905372014, 0.48714725094627986]\n",
      "LOSS PER INSTANCE: 0.719189\n",
      "DERIVATIVE LOSS: -2.052767\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.719189\n",
      "EPOCH 84\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.86831926  0.81722972]\n",
      "SOFTMAX_LAYER\n",
      "[0.51276960653266668, 0.48723039346733327]\n",
      "LOSS PER INSTANCE: 0.719018\n",
      "DERIVATIVE LOSS: -2.052417\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.719018\n",
      "EPOCH 85\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.86885097  0.81809146]\n",
      "SOFTMAX_LAYER\n",
      "[0.5126871533628562, 0.48731284663714369]\n",
      "LOSS PER INSTANCE: 0.718849\n",
      "DERIVATIVE LOSS: -2.052070\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.718849\n",
      "EPOCH 86\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.86937895  0.81894673]\n",
      "SOFTMAX_LAYER\n",
      "[0.51260538389682575, 0.48739461610317431]\n",
      "LOSS PER INSTANCE: 0.718681\n",
      "DERIVATIVE LOSS: -2.051726\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.718681\n",
      "EPOCH 87\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.86990323  0.81979558]\n",
      "SOFTMAX_LAYER\n",
      "[0.51252429250485687, 0.48747570749514318]\n",
      "LOSS PER INSTANCE: 0.718515\n",
      "DERIVATIVE LOSS: -2.051384\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.718515\n",
      "EPOCH 88\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.87042386  0.82063808]\n",
      "SOFTMAX_LAYER\n",
      "[0.51244387357614229, 0.48755612642385771]\n",
      "LOSS PER INSTANCE: 0.718350\n",
      "DERIVATIVE LOSS: -2.051046\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.718350\n",
      "EPOCH 89\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.87094086  0.82147429]\n",
      "SOFTMAX_LAYER\n",
      "[0.51236412151989852, 0.48763587848010148]\n",
      "LOSS PER INSTANCE: 0.718186\n",
      "DERIVATIVE LOSS: -2.050710\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.718186\n",
      "EPOCH 90\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.87145427  0.82230425]\n",
      "SOFTMAX_LAYER\n",
      "[0.5122850307664274, 0.48771496923357249]\n",
      "LOSS PER INSTANCE: 0.718024\n",
      "DERIVATIVE LOSS: -2.050378\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.718024\n",
      "EPOCH 91\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.87196411  0.82312803]\n",
      "SOFTMAX_LAYER\n",
      "[0.51220659576812833, 0.48779340423187179]\n",
      "LOSS PER INSTANCE: 0.717863\n",
      "DERIVATIVE LOSS: -2.050048\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.717863\n",
      "EPOCH 92\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.87247044  0.82394567]\n",
      "SOFTMAX_LAYER\n",
      "[0.51212881100046082, 0.48787118899953918]\n",
      "LOSS PER INSTANCE: 0.717704\n",
      "DERIVATIVE LOSS: -2.049721\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.717704\n",
      "EPOCH 93\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.87297326  0.82475724]\n",
      "SOFTMAX_LAYER\n",
      "[0.51205167096286297, 0.48794832903713692]\n",
      "LOSS PER INSTANCE: 0.717546\n",
      "DERIVATIVE LOSS: -2.049397\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.717546\n",
      "EPOCH 94\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.87347263  0.82556279]\n",
      "SOFTMAX_LAYER\n",
      "[0.51197517017962202, 0.48802482982037793]\n",
      "LOSS PER INSTANCE: 0.717389\n",
      "DERIVATIVE LOSS: -2.049076\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.717389\n",
      "EPOCH 95\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.87396856  0.82636236]\n",
      "SOFTMAX_LAYER\n",
      "[0.51189930320070232, 0.48810069679929763]\n",
      "LOSS PER INSTANCE: 0.717234\n",
      "DERIVATIVE LOSS: -2.048758\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.717234\n",
      "EPOCH 96\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.8744611   0.82715602]\n",
      "SOFTMAX_LAYER\n",
      "[0.51182406460253138, 0.48817593539746862]\n",
      "LOSS PER INSTANCE: 0.717079\n",
      "DERIVATIVE LOSS: -2.048442\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.717079\n",
      "EPOCH 97\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.87495027  0.82794382]\n",
      "SOFTMAX_LAYER\n",
      "[0.51174944898874353, 0.48825055101125636]\n",
      "LOSS PER INSTANCE: 0.716927\n",
      "DERIVATIVE LOSS: -2.048129\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.716927\n",
      "EPOCH 98\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.8754361  0.8287258]\n",
      "SOFTMAX_LAYER\n",
      "[0.51167545099088596, 0.48832454900911404]\n",
      "LOSS PER INSTANCE: 0.716775\n",
      "DERIVATIVE LOSS: -2.047818\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.716775\n",
      "EPOCH 99\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.87591862  0.82950203]\n",
      "SOFTMAX_LAYER\n",
      "[0.51160206526908414, 0.48839793473091592]\n",
      "LOSS PER INSTANCE: 0.716625\n",
      "DERIVATIVE LOSS: -2.047511\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.716625\n",
      "EPOCH 100\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.87639787  0.83027255]\n",
      "SOFTMAX_LAYER\n",
      "[0.51152928651267138, 0.48847071348732868]\n",
      "LOSS PER INSTANCE: 0.716476\n",
      "DERIVATIVE LOSS: -2.047206\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.716476\n",
      "EPOCH 101\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.87687387  0.83103741]\n",
      "SOFTMAX_LAYER\n",
      "[0.51145710944078271, 0.48854289055921729]\n",
      "LOSS PER INSTANCE: 0.716328\n",
      "DERIVATIVE LOSS: -2.046903\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.716328\n",
      "EPOCH 102\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.87734666  0.83179667]\n",
      "SOFTMAX_LAYER\n",
      "[0.51138552880291355, 0.48861447119708651]\n",
      "LOSS PER INSTANCE: 0.716182\n",
      "DERIVATIVE LOSS: -2.046603\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.716182\n",
      "EPOCH 103\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.87781626  0.83255037]\n",
      "SOFTMAX_LAYER\n",
      "[0.51131453937944471, 0.48868546062055523]\n",
      "LOSS PER INSTANCE: 0.716036\n",
      "DERIVATIVE LOSS: -2.046306\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.716036\n",
      "EPOCH 104\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.87828269  0.83329856]\n",
      "SOFTMAX_LAYER\n",
      "[0.51124413598213603, 0.48875586401786392]\n",
      "LOSS PER INSTANCE: 0.715892\n",
      "DERIVATIVE LOSS: -2.046011\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.715892\n",
      "EPOCH 105\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.878746   0.8340413]\n",
      "SOFTMAX_LAYER\n",
      "[0.51117431345458741, 0.48882568654541253]\n",
      "LOSS PER INSTANCE: 0.715749\n",
      "DERIVATIVE LOSS: -2.045719\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.715749\n",
      "EPOCH 106\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.8792062   0.83477863]\n",
      "SOFTMAX_LAYER\n",
      "[0.51110506667267086, 0.48889493332732914]\n",
      "LOSS PER INSTANCE: 0.715608\n",
      "DERIVATIVE LOSS: -2.045429\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.715608\n",
      "EPOCH 107\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.87966333  0.8355106 ]\n",
      "SOFTMAX_LAYER\n",
      "[0.51103639054493288, 0.48896360945506717]\n",
      "LOSS PER INSTANCE: 0.715467\n",
      "DERIVATIVE LOSS: -2.045142\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.715467\n",
      "EPOCH 108\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.88011741  0.83623725]\n",
      "SOFTMAX_LAYER\n",
      "[0.51096828001296857, 0.48903171998703154]\n",
      "LOSS PER INSTANCE: 0.715328\n",
      "DERIVATIVE LOSS: -2.044857\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.715328\n",
      "EPOCH 109\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.88056848  0.83695865]\n",
      "SOFTMAX_LAYER\n",
      "[0.51090073005176884, 0.48909926994823116]\n",
      "LOSS PER INSTANCE: 0.715190\n",
      "DERIVATIVE LOSS: -2.044575\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.715190\n",
      "EPOCH 110\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.88101655  0.83767482]\n",
      "SOFTMAX_LAYER\n",
      "[0.5108337356700422, 0.48916626432995791]\n",
      "LOSS PER INSTANCE: 0.715053\n",
      "DERIVATIVE LOSS: -2.044295\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.715053\n",
      "EPOCH 111\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.88146165  0.83838582]\n",
      "SOFTMAX_LAYER\n",
      "[0.5107672919105094, 0.48923270808949054]\n",
      "LOSS PER INSTANCE: 0.714917\n",
      "DERIVATIVE LOSS: -2.044017\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.714917\n",
      "EPOCH 112\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.88190382  0.8390917 ]\n",
      "SOFTMAX_LAYER\n",
      "[0.51070139385017599, 0.48929860614982396]\n",
      "LOSS PER INSTANCE: 0.714782\n",
      "DERIVATIVE LOSS: -2.043742\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.714782\n",
      "EPOCH 113\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.88234307  0.8397925 ]\n",
      "SOFTMAX_LAYER\n",
      "[0.5106360366005801, 0.4893639633994199]\n",
      "LOSS PER INSTANCE: 0.714649\n",
      "DERIVATIVE LOSS: -2.043469\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.714649\n",
      "EPOCH 114\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.88277943  0.84048827]\n",
      "SOFTMAX_LAYER\n",
      "[0.51057121530801763, 0.48942878469198237]\n",
      "LOSS PER INSTANCE: 0.714516\n",
      "DERIVATIVE LOSS: -2.043198\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.714516\n",
      "EPOCH 115\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.88321294  0.84117905]\n",
      "SOFTMAX_LAYER\n",
      "[0.51050692515374674, 0.48949307484625315]\n",
      "LOSS PER INSTANCE: 0.714385\n",
      "DERIVATIVE LOSS: -2.042930\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.714385\n",
      "EPOCH 116\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.8836436   0.84186488]\n",
      "SOFTMAX_LAYER\n",
      "[0.51044316135417056, 0.48955683864582938]\n",
      "LOSS PER INSTANCE: 0.714255\n",
      "DERIVATIVE LOSS: -2.042664\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.714255\n",
      "EPOCH 117\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.88407146  0.84254582]\n",
      "SOFTMAX_LAYER\n",
      "[0.51037991916099912, 0.48962008083900088]\n",
      "LOSS PER INSTANCE: 0.714126\n",
      "DERIVATIVE LOSS: -2.042400\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.714126\n",
      "EPOCH 118\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.88449653  0.84322189]\n",
      "SOFTMAX_LAYER\n",
      "[0.51031719386139396, 0.48968280613860604]\n",
      "LOSS PER INSTANCE: 0.713997\n",
      "DERIVATIVE LOSS: -2.042138\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.713997\n",
      "EPOCH 119\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.88491884  0.84389316]\n",
      "SOFTMAX_LAYER\n",
      "[0.51025498077809195, 0.489745019221908]\n",
      "LOSS PER INSTANCE: 0.713870\n",
      "DERIVATIVE LOSS: -2.041879\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.713870\n",
      "EPOCH 120\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.88533841  0.84455965]\n",
      "SOFTMAX_LAYER\n",
      "[0.51019327526951241, 0.48980672473048775]\n",
      "LOSS PER INSTANCE: 0.713744\n",
      "DERIVATIVE LOSS: -2.041622\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.713744\n",
      "EPOCH 121\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.88575526  0.84522142]\n",
      "SOFTMAX_LAYER\n",
      "[0.51013207272984629, 0.48986792727015371]\n",
      "LOSS PER INSTANCE: 0.713619\n",
      "DERIVATIVE LOSS: -2.041367\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.713619\n",
      "EPOCH 122\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.88616943  0.84587851]\n",
      "SOFTMAX_LAYER\n",
      "[0.51007136858912971, 0.48992863141087029]\n",
      "LOSS PER INSTANCE: 0.713496\n",
      "DERIVATIVE LOSS: -2.041114\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.713496\n",
      "EPOCH 123\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.88658093  0.84653095]\n",
      "SOFTMAX_LAYER\n",
      "[0.51001115831330091, 0.48998884168669915]\n",
      "LOSS PER INSTANCE: 0.713373\n",
      "DERIVATIVE LOSS: -2.040863\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.713373\n",
      "EPOCH 124\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.88698979  0.84717878]\n",
      "SOFTMAX_LAYER\n",
      "[0.5099514374042412, 0.49004856259575885]\n",
      "LOSS PER INSTANCE: 0.713251\n",
      "DERIVATIVE LOSS: -2.040614\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.713251\n",
      "EPOCH 125\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.88739603  0.84782206]\n",
      "SOFTMAX_LAYER\n",
      "[0.50989220139980329, 0.49010779860019671]\n",
      "LOSS PER INSTANCE: 0.713130\n",
      "DERIVATIVE LOSS: -2.040367\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.713130\n",
      "EPOCH 126\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.88779967  0.84846082]\n",
      "SOFTMAX_LAYER\n",
      "[0.50983344587382362, 0.49016655412617649]\n",
      "LOSS PER INSTANCE: 0.713010\n",
      "DERIVATIVE LOSS: -2.040123\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.713010\n",
      "EPOCH 127\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.88820074  0.84909509]\n",
      "SOFTMAX_LAYER\n",
      "[0.50977516643612153, 0.49022483356387847]\n",
      "LOSS PER INSTANCE: 0.712891\n",
      "DERIVATIVE LOSS: -2.039880\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.712891\n",
      "EPOCH 128\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.88859926  0.84972493]\n",
      "SOFTMAX_LAYER\n",
      "[0.50971735873248736, 0.4902826412675127]\n",
      "LOSS PER INSTANCE: 0.712773\n",
      "DERIVATIVE LOSS: -2.039640\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.712773\n",
      "EPOCH 129\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.88899524  0.85035036]\n",
      "SOFTMAX_LAYER\n",
      "[0.50966001844465458, 0.49033998155534542]\n",
      "LOSS PER INSTANCE: 0.712656\n",
      "DERIVATIVE LOSS: -2.039401\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.712656\n",
      "EPOCH 130\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.88938872  0.85097143]\n",
      "SOFTMAX_LAYER\n",
      "[0.50960314129026385, 0.49039685870973604]\n",
      "LOSS PER INSTANCE: 0.712540\n",
      "DERIVATIVE LOSS: -2.039165\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.712540\n",
      "EPOCH 131\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.88977971  0.85158818]\n",
      "SOFTMAX_LAYER\n",
      "[0.50954672302281345, 0.49045327697718666]\n",
      "LOSS PER INSTANCE: 0.712425\n",
      "DERIVATIVE LOSS: -2.038930\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.712425\n",
      "EPOCH 132\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.89016824  0.85220064]\n",
      "SOFTMAX_LAYER\n",
      "[0.50949075943159849, 0.49050924056840156]\n",
      "LOSS PER INSTANCE: 0.712311\n",
      "DERIVATIVE LOSS: -2.038698\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.712311\n",
      "EPOCH 133\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.89055432  0.85280886]\n",
      "SOFTMAX_LAYER\n",
      "[0.50943524634164217, 0.49056475365835794]\n",
      "LOSS PER INSTANCE: 0.712198\n",
      "DERIVATIVE LOSS: -2.038467\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.712198\n",
      "EPOCH 134\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.89093798  0.85341286]\n",
      "SOFTMAX_LAYER\n",
      "[0.50938017961361404, 0.49061982038638596]\n",
      "LOSS PER INSTANCE: 0.712086\n",
      "DERIVATIVE LOSS: -2.038238\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.712086\n",
      "EPOCH 135\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.89131924  0.8540127 ]\n",
      "SOFTMAX_LAYER\n",
      "[0.50932555514374134, 0.49067444485625877]\n",
      "LOSS PER INSTANCE: 0.711974\n",
      "DERIVATIVE LOSS: -2.038011\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.711974\n",
      "EPOCH 136\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.89169812  0.8546084 ]\n",
      "SOFTMAX_LAYER\n",
      "[0.50927136886370927, 0.49072863113629084]\n",
      "LOSS PER INSTANCE: 0.711864\n",
      "DERIVATIVE LOSS: -2.037786\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.711864\n",
      "EPOCH 137\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.89207464  0.85519999]\n",
      "SOFTMAX_LAYER\n",
      "[0.5092176167405541, 0.49078238325944579]\n",
      "LOSS PER INSTANCE: 0.711754\n",
      "DERIVATIVE LOSS: -2.037563\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.711754\n",
      "EPOCH 138\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.89244881  0.85578753]\n",
      "SOFTMAX_LAYER\n",
      "[0.50916429477654745, 0.4908357052234526]\n",
      "LOSS PER INSTANCE: 0.711646\n",
      "DERIVATIVE LOSS: -2.037342\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.711646\n",
      "EPOCH 139\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.89282067  0.85637104]\n",
      "SOFTMAX_LAYER\n",
      "[0.50911139900907187, 0.49088860099092807]\n",
      "LOSS PER INSTANCE: 0.711538\n",
      "DERIVATIVE LOSS: -2.037122\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.711538\n",
      "EPOCH 140\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.89319022  0.85695056]\n",
      "SOFTMAX_LAYER\n",
      "[0.50905892551049081, 0.4909410744895093]\n",
      "LOSS PER INSTANCE: 0.711431\n",
      "DERIVATIVE LOSS: -2.036904\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.711431\n",
      "EPOCH 141\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.8935575   0.85752612]\n",
      "SOFTMAX_LAYER\n",
      "[0.5090068703880094, 0.49099312961199065]\n",
      "LOSS PER INSTANCE: 0.711325\n",
      "DERIVATIVE LOSS: -2.036688\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.711325\n",
      "EPOCH 142\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.89392251  0.85809776]\n",
      "SOFTMAX_LAYER\n",
      "[0.50895522978353003, 0.49104477021646992]\n",
      "LOSS PER INSTANCE: 0.711220\n",
      "DERIVATIVE LOSS: -2.036474\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.711220\n",
      "EPOCH 143\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.89428527  0.85866551]\n",
      "SOFTMAX_LAYER\n",
      "[0.50890399987350077, 0.49109600012649912]\n",
      "LOSS PER INSTANCE: 0.711116\n",
      "DERIVATIVE LOSS: -2.036262\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.711116\n",
      "EPOCH 144\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.89464581  0.85922941]\n",
      "SOFTMAX_LAYER\n",
      "[0.50885317686875786, 0.49114682313124208]\n",
      "LOSS PER INSTANCE: 0.711012\n",
      "DERIVATIVE LOSS: -2.036051\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.711012\n",
      "EPOCH 145\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.89500415  0.85978948]\n",
      "SOFTMAX_LAYER\n",
      "[0.50880275701436217, 0.49119724298563794]\n",
      "LOSS PER INSTANCE: 0.710910\n",
      "DERIVATIVE LOSS: -2.035842\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.710910\n",
      "EPOCH 146\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.8953603   0.86034578]\n",
      "SOFTMAX_LAYER\n",
      "[0.50875273658943021, 0.49124726341056985]\n",
      "LOSS PER INSTANCE: 0.710808\n",
      "DERIVATIVE LOSS: -2.035635\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.710808\n",
      "EPOCH 147\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.89571428  0.86089832]\n",
      "SOFTMAX_LAYER\n",
      "[0.50870311190696038, 0.49129688809303956]\n",
      "LOSS PER INSTANCE: 0.710707\n",
      "DERIVATIVE LOSS: -2.035429\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.710707\n",
      "EPOCH 148\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.89606611  0.86144714]\n",
      "SOFTMAX_LAYER\n",
      "[0.50865387931365402, 0.49134612068634603]\n",
      "LOSS PER INSTANCE: 0.710606\n",
      "DERIVATIVE LOSS: -2.035225\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.710606\n",
      "EPOCH 149\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.89641581  0.86199227]\n",
      "SOFTMAX_LAYER\n",
      "[0.50860503518973177, 0.49139496481026823]\n",
      "LOSS PER INSTANCE: 0.710507\n",
      "DERIVATIVE LOSS: -2.035023\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.710507\n",
      "EPOCH 150\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.89676339  0.86253374]\n",
      "SOFTMAX_LAYER\n",
      "[0.50855657594874526, 0.49144342405125468]\n",
      "LOSS PER INSTANCE: 0.710408\n",
      "DERIVATIVE LOSS: -2.034822\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.710408\n",
      "EPOCH 151\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.89710887  0.8630716 ]\n",
      "SOFTMAX_LAYER\n",
      "[0.50850849803738563, 0.49149150196261432]\n",
      "LOSS PER INSTANCE: 0.710311\n",
      "DERIVATIVE LOSS: -2.034623\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.710311\n",
      "EPOCH 152\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.89745228  0.86360586]\n",
      "SOFTMAX_LAYER\n",
      "[0.50846079793528676, 0.4915392020647133]\n",
      "LOSS PER INSTANCE: 0.710214\n",
      "DERIVATIVE LOSS: -2.034426\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.710214\n",
      "EPOCH 153\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.89779362  0.86413656]\n",
      "SOFTMAX_LAYER\n",
      "[0.50841347215482668, 0.49158652784517326]\n",
      "LOSS PER INSTANCE: 0.710117\n",
      "DERIVATIVE LOSS: -2.034230\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.710117\n",
      "EPOCH 154\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.89813292  0.86466373]\n",
      "SOFTMAX_LAYER\n",
      "[0.50836651724092363, 0.49163348275907642]\n",
      "LOSS PER INSTANCE: 0.710022\n",
      "DERIVATIVE LOSS: -2.034036\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.710022\n",
      "EPOCH 155\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.89847019  0.8651874 ]\n",
      "SOFTMAX_LAYER\n",
      "[0.50831992977083029, 0.49168007022916965]\n",
      "LOSS PER INSTANCE: 0.709927\n",
      "DERIVATIVE LOSS: -2.033843\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.709927\n",
      "EPOCH 156\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.89880544  0.8657076 ]\n",
      "SOFTMAX_LAYER\n",
      "[0.5082737063539251, 0.49172629364607473]\n",
      "LOSS PER INSTANCE: 0.709833\n",
      "DERIVATIVE LOSS: -2.033652\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.709833\n",
      "EPOCH 157\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.8991387   0.86622436]\n",
      "SOFTMAX_LAYER\n",
      "[0.50822784363149953, 0.49177215636850036]\n",
      "LOSS PER INSTANCE: 0.709740\n",
      "DERIVATIVE LOSS: -2.033462\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.709740\n",
      "EPOCH 158\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.89946999  0.86673771]\n",
      "SOFTMAX_LAYER\n",
      "[0.50818233827654424, 0.49181766172345581]\n",
      "LOSS PER INSTANCE: 0.709647\n",
      "DERIVATIVE LOSS: -2.033274\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.709647\n",
      "EPOCH 159\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.8997993   0.86724768]\n",
      "SOFTMAX_LAYER\n",
      "[0.5081371869935315, 0.4918628130064685]\n",
      "LOSS PER INSTANCE: 0.709555\n",
      "DERIVATIVE LOSS: -2.033087\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.709555\n",
      "EPOCH 160\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.90012668  0.8677543 ]\n",
      "SOFTMAX_LAYER\n",
      "[0.50809238651819699, 0.49190761348180295]\n",
      "LOSS PER INSTANCE: 0.709464\n",
      "DERIVATIVE LOSS: -2.032902\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.709464\n",
      "EPOCH 161\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.90045212  0.8682576 ]\n",
      "SOFTMAX_LAYER\n",
      "[0.50804793361731837, 0.49195206638268157]\n",
      "LOSS PER INSTANCE: 0.709374\n",
      "DERIVATIVE LOSS: -2.032718\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.709374\n",
      "EPOCH 162\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.90077564  0.86875761]\n",
      "SOFTMAX_LAYER\n",
      "[0.50800382508849207, 0.49199617491150799]\n",
      "LOSS PER INSTANCE: 0.709284\n",
      "DERIVATIVE LOSS: -2.032536\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.709284\n",
      "EPOCH 163\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.90109727  0.86925435]\n",
      "SOFTMAX_LAYER\n",
      "[0.50796005775990938, 0.49203994224009062]\n",
      "LOSS PER INSTANCE: 0.709195\n",
      "DERIVATIVE LOSS: -2.032355\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.709195\n",
      "EPOCH 164\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.90141701  0.86974785]\n",
      "SOFTMAX_LAYER\n",
      "[0.50791662849012931, 0.49208337150987069]\n",
      "LOSS PER INSTANCE: 0.709107\n",
      "DERIVATIVE LOSS: -2.032176\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.709107\n",
      "EPOCH 165\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.90173489  0.87023814]\n",
      "SOFTMAX_LAYER\n",
      "[0.50787353416785241, 0.49212646583214759]\n",
      "LOSS PER INSTANCE: 0.709020\n",
      "DERIVATIVE LOSS: -2.031998\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.709020\n",
      "EPOCH 166\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.9020509   0.87072526]\n",
      "SOFTMAX_LAYER\n",
      "[0.50783077171169089, 0.49216922828830906]\n",
      "LOSS PER INSTANCE: 0.708933\n",
      "DERIVATIVE LOSS: -2.031821\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.708933\n",
      "EPOCH 167\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.90236509  0.87120921]\n",
      "SOFTMAX_LAYER\n",
      "[0.50778833806993895, 0.492211661930061]\n",
      "LOSS PER INSTANCE: 0.708846\n",
      "DERIVATIVE LOSS: -2.031646\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.708846\n",
      "EPOCH 168\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.90267744  0.87169004]\n",
      "SOFTMAX_LAYER\n",
      "[0.50774623022034315, 0.49225376977965679]\n",
      "LOSS PER INSTANCE: 0.708761\n",
      "DERIVATIVE LOSS: -2.031473\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.708761\n",
      "EPOCH 169\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.90298799  0.87216777]\n",
      "SOFTMAX_LAYER\n",
      "[0.50770444516986901, 0.49229555483013093]\n",
      "LOSS PER INSTANCE: 0.708676\n",
      "DERIVATIVE LOSS: -2.031300\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.708676\n",
      "EPOCH 170\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.90329674  0.87264242]\n",
      "SOFTMAX_LAYER\n",
      "[0.50766297995446996, 0.49233702004552998]\n",
      "LOSS PER INSTANCE: 0.708592\n",
      "DERIVATIVE LOSS: -2.031129\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.708592\n",
      "EPOCH 171\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.90360372  0.87311403]\n",
      "SOFTMAX_LAYER\n",
      "[0.50762183163885433, 0.49237816836114584]\n",
      "LOSS PER INSTANCE: 0.708508\n",
      "DERIVATIVE LOSS: -2.030959\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.708508\n",
      "EPOCH 172\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.90390892  0.87358261]\n",
      "SOFTMAX_LAYER\n",
      "[0.50758099731625073, 0.49241900268374944]\n",
      "LOSS PER INSTANCE: 0.708425\n",
      "DERIVATIVE LOSS: -2.030791\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.708425\n",
      "EPOCH 173\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.90421238  0.87404819]\n",
      "SOFTMAX_LAYER\n",
      "[0.50754047410817615, 0.49245952589182379]\n",
      "LOSS PER INSTANCE: 0.708343\n",
      "DERIVATIVE LOSS: -2.030624\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.708343\n",
      "EPOCH 174\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.90451409  0.87451081]\n",
      "SOFTMAX_LAYER\n",
      "[0.50750025916420061, 0.49249974083579934]\n",
      "LOSS PER INSTANCE: 0.708261\n",
      "DERIVATIVE LOSS: -2.030458\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.708261\n",
      "EPOCH 175\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.90481409  0.87497047]\n",
      "SOFTMAX_LAYER\n",
      "[0.50746034966171361, 0.49253965033828628]\n",
      "LOSS PER INSTANCE: 0.708180\n",
      "DERIVATIVE LOSS: -2.030293\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.708180\n",
      "EPOCH 176\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.90511237  0.87542722]\n",
      "SOFTMAX_LAYER\n",
      "[0.50742074280568938, 0.4925792571943105]\n",
      "LOSS PER INSTANCE: 0.708100\n",
      "DERIVATIVE LOSS: -2.030130\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.708100\n",
      "EPOCH 177\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.90540895  0.87588106]\n",
      "SOFTMAX_LAYER\n",
      "[0.5073814358284533, 0.49261856417154676]\n",
      "LOSS PER INSTANCE: 0.708020\n",
      "DERIVATIVE LOSS: -2.029968\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.708020\n",
      "EPOCH 178\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.90570385  0.87633204]\n",
      "SOFTMAX_LAYER\n",
      "[0.5073424259894469, 0.4926575740105531]\n",
      "LOSS PER INSTANCE: 0.707941\n",
      "DERIVATIVE LOSS: -2.029807\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.707941\n",
      "EPOCH 179\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.90599708  0.87678016]\n",
      "SOFTMAX_LAYER\n",
      "[0.50730371057499513, 0.49269628942500487]\n",
      "LOSS PER INSTANCE: 0.707862\n",
      "DERIVATIVE LOSS: -2.029648\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.707862\n",
      "EPOCH 180\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.90628866  0.87722546]\n",
      "SOFTMAX_LAYER\n",
      "[0.50726528689807149, 0.49273471310192846]\n",
      "LOSS PER INSTANCE: 0.707784\n",
      "DERIVATIVE LOSS: -2.029490\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.707784\n",
      "EPOCH 181\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.90657859  0.87766796]\n",
      "SOFTMAX_LAYER\n",
      "[0.50722715229806581, 0.4927728477019343]\n",
      "LOSS PER INSTANCE: 0.707707\n",
      "DERIVATIVE LOSS: -2.029333\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.707707\n",
      "EPOCH 182\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.90686688  0.87810768]\n",
      "SOFTMAX_LAYER\n",
      "[0.50718930414055041, 0.49281069585944959]\n",
      "LOSS PER INSTANCE: 0.707630\n",
      "DERIVATIVE LOSS: -2.029177\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.707630\n",
      "EPOCH 183\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.90715356  0.87854465]\n",
      "SOFTMAX_LAYER\n",
      "[0.50715173981704897, 0.49284826018295103]\n",
      "LOSS PER INSTANCE: 0.707554\n",
      "DERIVATIVE LOSS: -2.029022\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.707554\n",
      "EPOCH 184\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.90743864  0.87897889]\n",
      "SOFTMAX_LAYER\n",
      "[0.50711445674480327, 0.49288554325519662]\n",
      "LOSS PER INSTANCE: 0.707478\n",
      "DERIVATIVE LOSS: -2.028869\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.707478\n",
      "EPOCH 185\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.90772212  0.87941042]\n",
      "SOFTMAX_LAYER\n",
      "[0.50707745236654367, 0.49292254763345622]\n",
      "LOSS PER INSTANCE: 0.707403\n",
      "DERIVATIVE LOSS: -2.028716\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.707403\n",
      "EPOCH 186\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.90800402  0.87983926]\n",
      "SOFTMAX_LAYER\n",
      "[0.50704072415025725, 0.49295927584974275]\n",
      "LOSS PER INSTANCE: 0.707329\n",
      "DERIVATIVE LOSS: -2.028565\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.707329\n",
      "EPOCH 187\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.90828435  0.88026544]\n",
      "SOFTMAX_LAYER\n",
      "[0.5070042695889585, 0.49299573041104144]\n",
      "LOSS PER INSTANCE: 0.707255\n",
      "DERIVATIVE LOSS: -2.028415\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.707255\n",
      "EPOCH 188\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.90856312  0.88068897]\n",
      "SOFTMAX_LAYER\n",
      "[0.50696808620046108, 0.49303191379953903]\n",
      "LOSS PER INSTANCE: 0.707181\n",
      "DERIVATIVE LOSS: -2.028266\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.707181\n",
      "EPOCH 189\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.90884035  0.88110989]\n",
      "SOFTMAX_LAYER\n",
      "[0.50693217152714853, 0.49306782847285152]\n",
      "LOSS PER INSTANCE: 0.707109\n",
      "DERIVATIVE LOSS: -2.028119\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.707109\n",
      "EPOCH 190\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.90911605  0.88152821]\n",
      "SOFTMAX_LAYER\n",
      "[0.50689652313574862, 0.49310347686425138]\n",
      "LOSS PER INSTANCE: 0.707036\n",
      "DERIVATIVE LOSS: -2.027972\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.707036\n",
      "EPOCH 191\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.90939023  0.88194395]\n",
      "SOFTMAX_LAYER\n",
      "[0.50686113861710602, 0.49313886138289398]\n",
      "LOSS PER INSTANCE: 0.706964\n",
      "DERIVATIVE LOSS: -2.027826\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.706964\n",
      "EPOCH 192\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.90966289  0.88235714]\n",
      "SOFTMAX_LAYER\n",
      "[0.5068260155859573, 0.49317398441404281]\n",
      "LOSS PER INSTANCE: 0.706893\n",
      "DERIVATIVE LOSS: -2.027682\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.706893\n",
      "EPOCH 193\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.90993406  0.88276779]\n",
      "SOFTMAX_LAYER\n",
      "[0.50679115168070688, 0.49320884831929307]\n",
      "LOSS PER INSTANCE: 0.706823\n",
      "DERIVATIVE LOSS: -2.027539\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.706823\n",
      "EPOCH 194\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.91020375  0.88317593]\n",
      "SOFTMAX_LAYER\n",
      "[0.50675654456320418, 0.49324345543679582]\n",
      "LOSS PER INSTANCE: 0.706752\n",
      "DERIVATIVE LOSS: -2.027396\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.706752\n",
      "EPOCH 195\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.91047196  0.88358157]\n",
      "SOFTMAX_LAYER\n",
      "[0.50672219191852164, 0.49327780808147836]\n",
      "LOSS PER INSTANCE: 0.706683\n",
      "DERIVATIVE LOSS: -2.027255\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.706683\n",
      "EPOCH 196\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.91073871  0.88398475]\n",
      "SOFTMAX_LAYER\n",
      "[0.50668809145473348, 0.49331190854526658]\n",
      "LOSS PER INSTANCE: 0.706614\n",
      "DERIVATIVE LOSS: -2.027115\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.706614\n",
      "EPOCH 197\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.911004    0.88438547]\n",
      "SOFTMAX_LAYER\n",
      "[0.50665424090269617, 0.49334575909730377]\n",
      "LOSS PER INSTANCE: 0.706545\n",
      "DERIVATIVE LOSS: -2.026976\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.706545\n",
      "EPOCH 198\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.91126786  0.88478376]\n",
      "SOFTMAX_LAYER\n",
      "[0.5066206380158309, 0.4933793619841691]\n",
      "LOSS PER INSTANCE: 0.706477\n",
      "DERIVATIVE LOSS: -2.026838\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.706477\n",
      "EPOCH 199\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.91153028  0.88517963]\n",
      "SOFTMAX_LAYER\n",
      "[0.5065872805699051, 0.4934127194300949]\n",
      "LOSS PER INSTANCE: 0.706409\n",
      "DERIVATIVE LOSS: -2.026701\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.706409\n",
      "EPOCH 200\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.91179129  0.88557312]\n",
      "SOFTMAX_LAYER\n",
      "[0.50655416636281758, 0.49344583363718242]\n",
      "LOSS PER INSTANCE: 0.706342\n",
      "DERIVATIVE LOSS: -2.026565\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.706342\n",
      "EPOCH 201\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.91205088  0.88596423]\n",
      "SOFTMAX_LAYER\n",
      "[0.50652129321438377, 0.49347870678561623]\n",
      "LOSS PER INSTANCE: 0.706276\n",
      "DERIVATIVE LOSS: -2.026430\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.706276\n",
      "EPOCH 202\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.91230908  0.88635299]\n",
      "SOFTMAX_LAYER\n",
      "[0.50648865896612205, 0.49351134103387789]\n",
      "LOSS PER INSTANCE: 0.706209\n",
      "DERIVATIVE LOSS: -2.026296\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.706209\n",
      "EPOCH 203\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.91256589  0.88673941]\n",
      "SOFTMAX_LAYER\n",
      "[0.50645626148104272, 0.49354373851895722]\n",
      "LOSS PER INSTANCE: 0.706144\n",
      "DERIVATIVE LOSS: -2.026163\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.706144\n",
      "EPOCH 204\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.91282133  0.88712352]\n",
      "SOFTMAX_LAYER\n",
      "[0.50642409864343685, 0.4935759013565631]\n",
      "LOSS PER INSTANCE: 0.706079\n",
      "DERIVATIVE LOSS: -2.026031\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.706079\n",
      "EPOCH 205\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.91307539  0.88750533]\n",
      "SOFTMAX_LAYER\n",
      "[0.50639216835866729, 0.49360783164133276]\n",
      "LOSS PER INSTANCE: 0.706014\n",
      "DERIVATIVE LOSS: -2.025900\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.706014\n",
      "EPOCH 206\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.91332811  0.88788486]\n",
      "SOFTMAX_LAYER\n",
      "[0.50636046855296113, 0.49363953144703893]\n",
      "LOSS PER INSTANCE: 0.705950\n",
      "DERIVATIVE LOSS: -2.025770\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.705950\n",
      "EPOCH 207\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.91357947  0.88826213]\n",
      "SOFTMAX_LAYER\n",
      "[0.50632899717320357, 0.49367100282679643]\n",
      "LOSS PER INSTANCE: 0.705886\n",
      "DERIVATIVE LOSS: -2.025641\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.705886\n",
      "EPOCH 208\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.9138295   0.88863716]\n",
      "SOFTMAX_LAYER\n",
      "[0.50629775218673312, 0.49370224781326688]\n",
      "LOSS PER INSTANCE: 0.705823\n",
      "DERIVATIVE LOSS: -2.025512\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.705823\n",
      "EPOCH 209\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.9140782   0.88900996]\n",
      "SOFTMAX_LAYER\n",
      "[0.50626673158113822, 0.49373326841886195]\n",
      "LOSS PER INSTANCE: 0.705760\n",
      "DERIVATIVE LOSS: -2.025385\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.705760\n",
      "EPOCH 210\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.91432559  0.88938056]\n",
      "SOFTMAX_LAYER\n",
      "[0.50623593336405504, 0.49376406663594491]\n",
      "LOSS PER INSTANCE: 0.705697\n",
      "DERIVATIVE LOSS: -2.025259\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.705697\n",
      "EPOCH 211\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.91457167  0.88974897]\n",
      "SOFTMAX_LAYER\n",
      "[0.5062053555629682, 0.49379464443703186]\n",
      "LOSS PER INSTANCE: 0.705636\n",
      "DERIVATIVE LOSS: -2.025133\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.705636\n",
      "EPOCH 212\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.91481645  0.89011521]\n",
      "SOFTMAX_LAYER\n",
      "[0.50617499622501061, 0.49382500377498939]\n",
      "LOSS PER INSTANCE: 0.705574\n",
      "DERIVATIVE LOSS: -2.025009\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.705574\n",
      "EPOCH 213\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.91505995  0.8904793 ]\n",
      "SOFTMAX_LAYER\n",
      "[0.50614485341676718, 0.49385514658323287]\n",
      "LOSS PER INSTANCE: 0.705513\n",
      "DERIVATIVE LOSS: -2.024885\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.705513\n",
      "EPOCH 214\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.91530217  0.89084125]\n",
      "SOFTMAX_LAYER\n",
      "[0.50611492522407864, 0.49388507477592147]\n",
      "LOSS PER INSTANCE: 0.705452\n",
      "DERIVATIVE LOSS: -2.024763\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.705452\n",
      "EPOCH 215\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.91554312  0.89120108]\n",
      "SOFTMAX_LAYER\n",
      "[0.5060852097518469, 0.49391479024815305]\n",
      "LOSS PER INSTANCE: 0.705392\n",
      "DERIVATIVE LOSS: -2.024641\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.705392\n",
      "EPOCH 216\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.91578281  0.89155881]\n",
      "SOFTMAX_LAYER\n",
      "[0.50605570512384346, 0.49394429487615654]\n",
      "LOSS PER INSTANCE: 0.705333\n",
      "DERIVATIVE LOSS: -2.024520\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.705333\n",
      "EPOCH 217\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.91602125  0.89191445]\n",
      "SOFTMAX_LAYER\n",
      "[0.50602640948251698, 0.49397359051748302]\n",
      "LOSS PER INSTANCE: 0.705273\n",
      "DERIVATIVE LOSS: -2.024400\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.705273\n",
      "EPOCH 218\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.91625845  0.89226802]\n",
      "SOFTMAX_LAYER\n",
      "[0.50599732098880446, 0.49400267901119554]\n",
      "LOSS PER INSTANCE: 0.705214\n",
      "DERIVATIVE LOSS: -2.024281\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.705214\n",
      "EPOCH 219\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.91649442  0.89261954]\n",
      "SOFTMAX_LAYER\n",
      "[0.50596843782194278, 0.4940315621780571]\n",
      "LOSS PER INSTANCE: 0.705156\n",
      "DERIVATIVE LOSS: -2.024162\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.705156\n",
      "EPOCH 220\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.91672917  0.89296902]\n",
      "SOFTMAX_LAYER\n",
      "[0.50593975817928261, 0.49406024182071745]\n",
      "LOSS PER INSTANCE: 0.705098\n",
      "DERIVATIVE LOSS: -2.024045\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.705098\n",
      "EPOCH 221\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.9169627   0.89331648]\n",
      "SOFTMAX_LAYER\n",
      "[0.50591128027610288, 0.49408871972389723]\n",
      "LOSS PER INSTANCE: 0.705040\n",
      "DERIVATIVE LOSS: -2.023928\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.705040\n",
      "EPOCH 222\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.91719503  0.89366194]\n",
      "SOFTMAX_LAYER\n",
      "[0.50588300234542793, 0.49411699765457218]\n",
      "LOSS PER INSTANCE: 0.704983\n",
      "DERIVATIVE LOSS: -2.023812\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.704983\n",
      "EPOCH 223\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.91742617  0.8940054 ]\n",
      "SOFTMAX_LAYER\n",
      "[0.50585492263784559, 0.49414507736215446]\n",
      "LOSS PER INSTANCE: 0.704926\n",
      "DERIVATIVE LOSS: -2.023697\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.704926\n",
      "EPOCH 224\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.91765611  0.8943469 ]\n",
      "SOFTMAX_LAYER\n",
      "[0.5058270394213269, 0.49417296057867316]\n",
      "LOSS PER INSTANCE: 0.704870\n",
      "DERIVATIVE LOSS: -2.023583\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.704870\n",
      "EPOCH 225\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.91788488  0.89468643]\n",
      "SOFTMAX_LAYER\n",
      "[0.50579935098104722, 0.49420064901895283]\n",
      "LOSS PER INSTANCE: 0.704814\n",
      "DERIVATIVE LOSS: -2.023470\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.704814\n",
      "EPOCH 226\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.91811247  0.89502403]\n",
      "SOFTMAX_LAYER\n",
      "[0.50577185561920979, 0.49422814438079027]\n",
      "LOSS PER INSTANCE: 0.704758\n",
      "DERIVATIVE LOSS: -2.023357\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.704758\n",
      "EPOCH 227\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.91833891  0.89535969]\n",
      "SOFTMAX_LAYER\n",
      "[0.50574455165486953, 0.49425544834513058]\n",
      "LOSS PER INSTANCE: 0.704703\n",
      "DERIVATIVE LOSS: -2.023245\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.704703\n",
      "EPOCH 228\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.91856419  0.89569344]\n",
      "SOFTMAX_LAYER\n",
      "[0.50571743742375919, 0.49428256257624087]\n",
      "LOSS PER INSTANCE: 0.704648\n",
      "DERIVATIVE LOSS: -2.023134\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.704648\n",
      "EPOCH 229\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.91878832  0.8960253 ]\n",
      "SOFTMAX_LAYER\n",
      "[0.50569051127811726, 0.49430948872188268]\n",
      "LOSS PER INSTANCE: 0.704593\n",
      "DERIVATIVE LOSS: -2.023024\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.704593\n",
      "EPOCH 230\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.91901132  0.89635527]\n",
      "SOFTMAX_LAYER\n",
      "[0.50566377158651721, 0.49433622841348274]\n",
      "LOSS PER INSTANCE: 0.704539\n",
      "DERIVATIVE LOSS: -2.022915\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.704539\n",
      "EPOCH 231\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.91923319  0.89668337]\n",
      "SOFTMAX_LAYER\n",
      "[0.50563721673369766, 0.49436278326630223]\n",
      "LOSS PER INSTANCE: 0.704486\n",
      "DERIVATIVE LOSS: -2.022806\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.704486\n",
      "EPOCH 232\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.91945394  0.89700962]\n",
      "SOFTMAX_LAYER\n",
      "[0.50561084512039522, 0.49438915487960472]\n",
      "LOSS PER INSTANCE: 0.704432\n",
      "DERIVATIVE LOSS: -2.022698\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.704432\n",
      "EPOCH 233\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.91967358  0.89733403]\n",
      "SOFTMAX_LAYER\n",
      "[0.50558465516317774, 0.4944153448368222]\n",
      "LOSS PER INSTANCE: 0.704379\n",
      "DERIVATIVE LOSS: -2.022591\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.704379\n",
      "EPOCH 234\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.91989211  0.89765661]\n",
      "SOFTMAX_LAYER\n",
      "[0.50555864529428074, 0.49444135470571926]\n",
      "LOSS PER INSTANCE: 0.704327\n",
      "DERIVATIVE LOSS: -2.022485\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.704327\n",
      "EPOCH 235\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.92010954  0.89797738]\n",
      "SOFTMAX_LAYER\n",
      "[0.5055328139614429, 0.4944671860385571]\n",
      "LOSS PER INSTANCE: 0.704274\n",
      "DERIVATIVE LOSS: -2.022379\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.704274\n",
      "EPOCH 236\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.92032589  0.89829636]\n",
      "SOFTMAX_LAYER\n",
      "[0.50550715962774551, 0.49449284037225438]\n",
      "LOSS PER INSTANCE: 0.704223\n",
      "DERIVATIVE LOSS: -2.022274\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.704223\n",
      "EPOCH 237\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.92054115  0.89861355]\n",
      "SOFTMAX_LAYER\n",
      "[0.5054816807714525, 0.49451831922854739]\n",
      "LOSS PER INSTANCE: 0.704171\n",
      "DERIVATIVE LOSS: -2.022170\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.704171\n",
      "EPOCH 238\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.92075534  0.89892897]\n",
      "SOFTMAX_LAYER\n",
      "[0.50545637588585146, 0.49454362411414865]\n",
      "LOSS PER INSTANCE: 0.704120\n",
      "DERIVATIVE LOSS: -2.022066\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.704120\n",
      "EPOCH 239\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.92096846  0.89924263]\n",
      "SOFTMAX_LAYER\n",
      "[0.50543124347909651, 0.49456875652090343]\n",
      "LOSS PER INSTANCE: 0.704069\n",
      "DERIVATIVE LOSS: -2.021964\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.704069\n",
      "EPOCH 240\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.92118053  0.89955455]\n",
      "SOFTMAX_LAYER\n",
      "[0.50540628207405391, 0.4945937179259462]\n",
      "LOSS PER INSTANCE: 0.704019\n",
      "DERIVATIVE LOSS: -2.021862\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.704019\n",
      "EPOCH 241\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.92139154  0.89986475]\n",
      "SOFTMAX_LAYER\n",
      "[0.50538149020814693, 0.49461850979185312]\n",
      "LOSS PER INSTANCE: 0.703969\n",
      "DERIVATIVE LOSS: -2.021760\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.703969\n",
      "EPOCH 242\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.92160151  0.90017322]\n",
      "SOFTMAX_LAYER\n",
      "[0.50535686643320399, 0.4946431335667959]\n",
      "LOSS PER INSTANCE: 0.703919\n",
      "DERIVATIVE LOSS: -2.021660\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.703919\n",
      "EPOCH 243\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.92181044  0.90047999]\n",
      "SOFTMAX_LAYER\n",
      "[0.50533240931530765, 0.49466759068469235]\n",
      "LOSS PER INSTANCE: 0.703869\n",
      "DERIVATIVE LOSS: -2.021560\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.703869\n",
      "EPOCH 244\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.92201834  0.90078507]\n",
      "SOFTMAX_LAYER\n",
      "[0.50530811743464499, 0.49469188256535507]\n",
      "LOSS PER INSTANCE: 0.703820\n",
      "DERIVATIVE LOSS: -2.021460\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.703820\n",
      "EPOCH 245\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.92222522  0.90108847]\n",
      "SOFTMAX_LAYER\n",
      "[0.50528398938535957, 0.49471601061464043]\n",
      "LOSS PER INSTANCE: 0.703771\n",
      "DERIVATIVE LOSS: -2.021362\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.703771\n",
      "EPOCH 246\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.92243108  0.90139021]\n",
      "SOFTMAX_LAYER\n",
      "[0.50526002377540513, 0.49473997622459481]\n",
      "LOSS PER INSTANCE: 0.703723\n",
      "DERIVATIVE LOSS: -2.021264\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.703723\n",
      "EPOCH 247\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.92263594  0.90169029]\n",
      "SOFTMAX_LAYER\n",
      "[0.5052362192264005, 0.49476378077359962]\n",
      "LOSS PER INSTANCE: 0.703675\n",
      "DERIVATIVE LOSS: -2.021167\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.703675\n",
      "EPOCH 248\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.92283979  0.90198874]\n",
      "SOFTMAX_LAYER\n",
      "[0.50521257437348532, 0.49478742562651473]\n",
      "LOSS PER INSTANCE: 0.703627\n",
      "DERIVATIVE LOSS: -2.021070\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.703627\n",
      "EPOCH 249\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.92304265  0.90228556]\n",
      "SOFTMAX_LAYER\n",
      "[0.50518908786517891, 0.49481091213482109]\n",
      "LOSS PER INSTANCE: 0.703580\n",
      "DERIVATIVE LOSS: -2.020974\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.703580\n",
      "EPOCH 250\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.92324452  0.90258076]\n",
      "SOFTMAX_LAYER\n",
      "[0.50516575836323852, 0.49483424163676143]\n",
      "LOSS PER INSTANCE: 0.703532\n",
      "DERIVATIVE LOSS: -2.020879\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.703532\n",
      "EPOCH 251\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.92344542  0.90287435]\n",
      "SOFTMAX_LAYER\n",
      "[0.50514258454252092, 0.49485741545747919]\n",
      "LOSS PER INSTANCE: 0.703486\n",
      "DERIVATIVE LOSS: -2.020784\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.703486\n",
      "EPOCH 252\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.92364533  0.90316636]\n",
      "SOFTMAX_LAYER\n",
      "[0.50511956509084321, 0.49488043490915684]\n",
      "LOSS PER INSTANCE: 0.703439\n",
      "DERIVATIVE LOSS: -2.020690\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.703439\n",
      "EPOCH 253\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.92384428  0.90345678]\n",
      "SOFTMAX_LAYER\n",
      "[0.50509669870884755, 0.4949033012911524]\n",
      "LOSS PER INSTANCE: 0.703393\n",
      "DERIVATIVE LOSS: -2.020597\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.703393\n",
      "EPOCH 254\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.92404227  0.90374564]\n",
      "SOFTMAX_LAYER\n",
      "[0.50507398410986548, 0.49492601589013457]\n",
      "LOSS PER INSTANCE: 0.703347\n",
      "DERIVATIVE LOSS: -2.020504\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.703347\n",
      "EPOCH 255\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.92423931  0.90403294]\n",
      "SOFTMAX_LAYER\n",
      "[0.50505142001978398, 0.49494857998021596]\n",
      "LOSS PER INSTANCE: 0.703301\n",
      "DERIVATIVE LOSS: -2.020412\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.703301\n",
      "EPOCH 256\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.9244354  0.9043187]\n",
      "SOFTMAX_LAYER\n",
      "[0.50502900517691351, 0.49497099482308643]\n",
      "LOSS PER INSTANCE: 0.703256\n",
      "DERIVATIVE LOSS: -2.020320\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.703256\n",
      "EPOCH 257\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.92463054  0.90460292]\n",
      "SOFTMAX_LAYER\n",
      "[0.50500673833185661, 0.49499326166814339]\n",
      "LOSS PER INSTANCE: 0.703211\n",
      "DERIVATIVE LOSS: -2.020230\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.703211\n",
      "EPOCH 258\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.92482476  0.90488562]\n",
      "SOFTMAX_LAYER\n",
      "[0.50498461824737828, 0.49501538175262177]\n",
      "LOSS PER INSTANCE: 0.703166\n",
      "DERIVATIVE LOSS: -2.020139\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.703166\n",
      "EPOCH 259\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.92501804  0.90516681]\n",
      "SOFTMAX_LAYER\n",
      "[0.50496264369827781, 0.49503735630172202]\n",
      "LOSS PER INSTANCE: 0.703122\n",
      "DERIVATIVE LOSS: -2.020050\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.703122\n",
      "EPOCH 260\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.9252104   0.90544651]\n",
      "SOFTMAX_LAYER\n",
      "[0.5049408134712623, 0.49505918652873765]\n",
      "LOSS PER INSTANCE: 0.703078\n",
      "DERIVATIVE LOSS: -2.019960\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.703078\n",
      "EPOCH 261\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.92540185  0.90572471]\n",
      "SOFTMAX_LAYER\n",
      "[0.50491912636481984, 0.49508087363518022]\n",
      "LOSS PER INSTANCE: 0.703034\n",
      "DERIVATIVE LOSS: -2.019872\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.703034\n",
      "EPOCH 262\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.92559239  0.90600143]\n",
      "SOFTMAX_LAYER\n",
      "[0.50489758118909556, 0.49510241881090439]\n",
      "LOSS PER INSTANCE: 0.702991\n",
      "DERIVATIVE LOSS: -2.019784\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.702991\n",
      "EPOCH 263\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.92578202  0.90627669]\n",
      "SOFTMAX_LAYER\n",
      "[0.50487617676576935, 0.4951238232342306]\n",
      "LOSS PER INSTANCE: 0.702947\n",
      "DERIVATIVE LOSS: -2.019697\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.702947\n",
      "EPOCH 264\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.92597075  0.9065505 ]\n",
      "SOFTMAX_LAYER\n",
      "[0.50485491192793341, 0.49514508807206647]\n",
      "LOSS PER INSTANCE: 0.702904\n",
      "DERIVATIVE LOSS: -2.019610\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.702904\n",
      "EPOCH 265\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.9261586   0.90682285]\n",
      "SOFTMAX_LAYER\n",
      "[0.50483378551997149, 0.49516621448002845]\n",
      "LOSS PER INSTANCE: 0.702862\n",
      "DERIVATIVE LOSS: -2.019524\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.702862\n",
      "EPOCH 266\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.92634556  0.90709378]\n",
      "SOFTMAX_LAYER\n",
      "[0.50481279639744048, 0.49518720360255952]\n",
      "LOSS PER INSTANCE: 0.702819\n",
      "DERIVATIVE LOSS: -2.019438\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.702819\n",
      "EPOCH 267\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.92653164  0.90736327]\n",
      "SOFTMAX_LAYER\n",
      "[0.50479194342695155, 0.49520805657304845]\n",
      "LOSS PER INSTANCE: 0.702777\n",
      "DERIVATIVE LOSS: -2.019353\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.702777\n",
      "EPOCH 268\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.92671684  0.90763136]\n",
      "SOFTMAX_LAYER\n",
      "[0.50477122548605424, 0.49522877451394587]\n",
      "LOSS PER INSTANCE: 0.702735\n",
      "DERIVATIVE LOSS: -2.019269\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.702735\n",
      "EPOCH 269\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.92690118  0.90789804]\n",
      "SOFTMAX_LAYER\n",
      "[0.50475064146312043, 0.49524935853687962]\n",
      "LOSS PER INSTANCE: 0.702694\n",
      "DERIVATIVE LOSS: -2.019185\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.702694\n",
      "EPOCH 270\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.92708465  0.90816333]\n",
      "SOFTMAX_LAYER\n",
      "[0.50473019025723065, 0.49526980974276946]\n",
      "LOSS PER INSTANCE: 0.702653\n",
      "DERIVATIVE LOSS: -2.019101\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.702653\n",
      "EPOCH 271\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.92726727  0.90842723]\n",
      "SOFTMAX_LAYER\n",
      "[0.50470987077806029, 0.49529012922193971]\n",
      "LOSS PER INSTANCE: 0.702612\n",
      "DERIVATIVE LOSS: -2.019019\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.702612\n",
      "EPOCH 272\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.92744904  0.90868976]\n",
      "SOFTMAX_LAYER\n",
      "[0.50468968194576846, 0.49531031805423142]\n",
      "LOSS PER INSTANCE: 0.702571\n",
      "DERIVATIVE LOSS: -2.018936\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.702571\n",
      "EPOCH 273\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.92762996  0.90895093]\n",
      "SOFTMAX_LAYER\n",
      "[0.50466962269088733, 0.49533037730911261]\n",
      "LOSS PER INSTANCE: 0.702530\n",
      "DERIVATIVE LOSS: -2.018855\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.702530\n",
      "EPOCH 274\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.92781005  0.90921074]\n",
      "SOFTMAX_LAYER\n",
      "[0.50464969195421172, 0.49535030804578828]\n",
      "LOSS PER INSTANCE: 0.702490\n",
      "DERIVATIVE LOSS: -2.018773\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.702490\n",
      "EPOCH 275\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.9279893   0.90946921]\n",
      "SOFTMAX_LAYER\n",
      "[0.50462988868669223, 0.49537011131330783]\n",
      "LOSS PER INSTANCE: 0.702450\n",
      "DERIVATIVE LOSS: -2.018693\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.702450\n",
      "EPOCH 276\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.92816772  0.90972635]\n",
      "SOFTMAX_LAYER\n",
      "[0.50461021184932708, 0.49538978815067297]\n",
      "LOSS PER INSTANCE: 0.702410\n",
      "DERIVATIVE LOSS: -2.018612\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.702410\n",
      "EPOCH 277\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.92834532  0.90998216]\n",
      "SOFTMAX_LAYER\n",
      "[0.50459066041305678, 0.49540933958694328]\n",
      "LOSS PER INSTANCE: 0.702371\n",
      "DERIVATIVE LOSS: -2.018533\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.702371\n",
      "EPOCH 278\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.9285221   0.91023666]\n",
      "SOFTMAX_LAYER\n",
      "[0.50457123335865883, 0.49542876664134122]\n",
      "LOSS PER INSTANCE: 0.702332\n",
      "DERIVATIVE LOSS: -2.018454\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.702332\n",
      "EPOCH 279\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.92869807  0.91048985]\n",
      "SOFTMAX_LAYER\n",
      "[0.5045519296766442, 0.49544807032335592]\n",
      "LOSS PER INSTANCE: 0.702293\n",
      "DERIVATIVE LOSS: -2.018375\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.702293\n",
      "EPOCH 280\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.92887323  0.91074174]\n",
      "SOFTMAX_LAYER\n",
      "[0.50453274836715511, 0.49546725163284489]\n",
      "LOSS PER INSTANCE: 0.702254\n",
      "DERIVATIVE LOSS: -2.018297\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.702254\n",
      "EPOCH 281\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.92904759  0.91099235]\n",
      "SOFTMAX_LAYER\n",
      "[0.504513688439863, 0.49548631156013706]\n",
      "LOSS PER INSTANCE: 0.702216\n",
      "DERIVATIVE LOSS: -2.018219\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.702216\n",
      "EPOCH 282\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.92922115  0.91124167]\n",
      "SOFTMAX_LAYER\n",
      "[0.50449474891386858, 0.49550525108613142]\n",
      "LOSS PER INSTANCE: 0.702177\n",
      "DERIVATIVE LOSS: -2.018142\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.702177\n",
      "EPOCH 283\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.92939393  0.91148973]\n",
      "SOFTMAX_LAYER\n",
      "[0.50447592881760217, 0.49552407118239783]\n",
      "LOSS PER INSTANCE: 0.702139\n",
      "DERIVATIVE LOSS: -2.018065\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.702139\n",
      "EPOCH 284\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.92956591  0.91173653]\n",
      "SOFTMAX_LAYER\n",
      "[0.50445722718872599, 0.49554277281127407]\n",
      "LOSS PER INSTANCE: 0.702102\n",
      "DERIVATIVE LOSS: -2.017989\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.702102\n",
      "EPOCH 285\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.92973712  0.91198208]\n",
      "SOFTMAX_LAYER\n",
      "[0.50443864307403663, 0.49556135692596337]\n",
      "LOSS PER INSTANCE: 0.702064\n",
      "DERIVATIVE LOSS: -2.017914\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.702064\n",
      "EPOCH 286\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.92990755  0.91222638]\n",
      "SOFTMAX_LAYER\n",
      "[0.50442017552936924, 0.49557982447063087]\n",
      "LOSS PER INSTANCE: 0.702027\n",
      "DERIVATIVE LOSS: -2.017838\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.702027\n",
      "EPOCH 287\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.93007721  0.91246946]\n",
      "SOFTMAX_LAYER\n",
      "[0.50440182361950203, 0.49559817638049791]\n",
      "LOSS PER INSTANCE: 0.701990\n",
      "DERIVATIVE LOSS: -2.017764\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.701990\n",
      "EPOCH 288\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.9302461  0.9127113]\n",
      "SOFTMAX_LAYER\n",
      "[0.50438358641806325, 0.49561641358193659]\n",
      "LOSS PER INSTANCE: 0.701953\n",
      "DERIVATIVE LOSS: -2.017689\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.701953\n",
      "EPOCH 289\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.93041423  0.91295193]\n",
      "SOFTMAX_LAYER\n",
      "[0.50436546300743701, 0.49563453699256294]\n",
      "LOSS PER INSTANCE: 0.701916\n",
      "DERIVATIVE LOSS: -2.017616\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.701916\n",
      "EPOCH 290\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.9305816   0.91319136]\n",
      "SOFTMAX_LAYER\n",
      "[0.50434745247867208, 0.49565254752132781]\n",
      "LOSS PER INSTANCE: 0.701880\n",
      "DERIVATIVE LOSS: -2.017542\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.701880\n",
      "EPOCH 291\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.93074823  0.91342958]\n",
      "SOFTMAX_LAYER\n",
      "[0.50432955393139089, 0.49567044606860916]\n",
      "LOSS PER INSTANCE: 0.701844\n",
      "DERIVATIVE LOSS: -2.017469\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.701844\n",
      "EPOCH 292\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.9309141   0.91366661]\n",
      "SOFTMAX_LAYER\n",
      "[0.50431176647369913, 0.49568823352630098]\n",
      "LOSS PER INSTANCE: 0.701808\n",
      "DERIVATIVE LOSS: -2.017397\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.701808\n",
      "EPOCH 293\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.93107924  0.91390246]\n",
      "SOFTMAX_LAYER\n",
      "[0.50429408922209729, 0.4957059107779026]\n",
      "LOSS PER INSTANCE: 0.701772\n",
      "DERIVATIVE LOSS: -2.017325\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.701772\n",
      "EPOCH 294\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.93124364  0.91413714]\n",
      "SOFTMAX_LAYER\n",
      "[0.50427652130139278, 0.49572347869860728]\n",
      "LOSS PER INSTANCE: 0.701737\n",
      "DERIVATIVE LOSS: -2.017254\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.701737\n",
      "EPOCH 295\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.9314073   0.91437064]\n",
      "SOFTMAX_LAYER\n",
      "[0.50425906184461189, 0.49574093815538806]\n",
      "LOSS PER INSTANCE: 0.701702\n",
      "DERIVATIVE LOSS: -2.017183\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.701702\n",
      "EPOCH 296\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.93157024  0.91460299]\n",
      "SOFTMAX_LAYER\n",
      "[0.50424170999291507, 0.49575829000708482]\n",
      "LOSS PER INSTANCE: 0.701667\n",
      "DERIVATIVE LOSS: -2.017112\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.701667\n",
      "EPOCH 297\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.93173246  0.91483419]\n",
      "SOFTMAX_LAYER\n",
      "[0.50422446489551098, 0.49577553510448913]\n",
      "LOSS PER INSTANCE: 0.701632\n",
      "DERIVATIVE LOSS: -2.017042\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.701632\n",
      "EPOCH 298\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.93189395  0.91506425]\n",
      "SOFTMAX_LAYER\n",
      "[0.50420732570957194, 0.49579267429042817]\n",
      "LOSS PER INSTANCE: 0.701597\n",
      "DERIVATIVE LOSS: -2.016972\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.701597\n",
      "EPOCH 299\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.93205474  0.91529318]\n",
      "SOFTMAX_LAYER\n",
      "[0.50419029160015183, 0.49580970839984823]\n",
      "LOSS PER INSTANCE: 0.701563\n",
      "DERIVATIVE LOSS: -2.016903\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.701563\n",
      "EPOCH 300\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.93221481  0.91552097]\n",
      "SOFTMAX_LAYER\n",
      "[0.50417336174010241, 0.49582663825989753]\n",
      "LOSS PER INSTANCE: 0.701529\n",
      "DERIVATIVE LOSS: -2.016834\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.701529\n",
      "EPOCH 301\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.93237418  0.91574765]\n",
      "SOFTMAX_LAYER\n",
      "[0.50415653530999338, 0.49584346469000656]\n",
      "LOSS PER INSTANCE: 0.701495\n",
      "DERIVATIVE LOSS: -2.016766\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.701495\n",
      "EPOCH 302\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.93253284  0.91597322]\n",
      "SOFTMAX_LAYER\n",
      "[0.50413981149803033, 0.49586018850196961]\n",
      "LOSS PER INSTANCE: 0.701461\n",
      "DERIVATIVE LOSS: -2.016697\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.701461\n",
      "EPOCH 303\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.93269081  0.91619768]\n",
      "SOFTMAX_LAYER\n",
      "[0.50412318949997559, 0.49587681050002447]\n",
      "LOSS PER INSTANCE: 0.701428\n",
      "DERIVATIVE LOSS: -2.016630\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.701428\n",
      "EPOCH 304\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.93284809  0.91642105]\n",
      "SOFTMAX_LAYER\n",
      "[0.50410666851907016, 0.4958933314809299]\n",
      "LOSS PER INSTANCE: 0.701394\n",
      "DERIVATIVE LOSS: -2.016563\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.701394\n",
      "EPOCH 305\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.93300469  0.91664333]\n",
      "SOFTMAX_LAYER\n",
      "[0.50409024776595479, 0.49590975223404521]\n",
      "LOSS PER INSTANCE: 0.701361\n",
      "DERIVATIVE LOSS: -2.016496\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.701361\n",
      "EPOCH 306\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.93316059  0.91686453]\n",
      "SOFTMAX_LAYER\n",
      "[0.50407392645859328, 0.49592607354140666]\n",
      "LOSS PER INSTANCE: 0.701328\n",
      "DERIVATIVE LOSS: -2.016430\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.701328\n",
      "EPOCH 307\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.93331582  0.91708465]\n",
      "SOFTMAX_LAYER\n",
      "[0.50405770382219672, 0.49594229617780328]\n",
      "LOSS PER INSTANCE: 0.701296\n",
      "DERIVATIVE LOSS: -2.016364\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.701296\n",
      "EPOCH 308\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.93347038  0.91730371]\n",
      "SOFTMAX_LAYER\n",
      "[0.50404157908914726, 0.49595842091085268]\n",
      "LOSS PER INSTANCE: 0.701263\n",
      "DERIVATIVE LOSS: -2.016298\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.701263\n",
      "EPOCH 309\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.93362426  0.91752171]\n",
      "SOFTMAX_LAYER\n",
      "[0.50402555149892392, 0.49597444850107597]\n",
      "LOSS PER INSTANCE: 0.701231\n",
      "DERIVATIVE LOSS: -2.016233\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.701231\n",
      "EPOCH 310\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.93377748  0.91773865]\n",
      "SOFTMAX_LAYER\n",
      "[0.50400962029802987, 0.49599037970197024]\n",
      "LOSS PER INSTANCE: 0.701199\n",
      "DERIVATIVE LOSS: -2.016168\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.701199\n",
      "EPOCH 311\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.93393004  0.91795456]\n",
      "SOFTMAX_LAYER\n",
      "[0.50399378473991752, 0.49600621526008243]\n",
      "LOSS PER INSTANCE: 0.701167\n",
      "DERIVATIVE LOSS: -2.016104\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.701167\n",
      "EPOCH 312\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.93408193  0.91816942]\n",
      "SOFTMAX_LAYER\n",
      "[0.50397804408491831, 0.49602195591508175]\n",
      "LOSS PER INSTANCE: 0.701135\n",
      "DERIVATIVE LOSS: -2.016040\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.701135\n",
      "EPOCH 313\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.93423318  0.91838325]\n",
      "SOFTMAX_LAYER\n",
      "[0.50396239760017003, 0.49603760239983002]\n",
      "LOSS PER INSTANCE: 0.701104\n",
      "DERIVATIVE LOSS: -2.015976\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.701104\n",
      "EPOCH 314\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.93438377  0.91859606]\n",
      "SOFTMAX_LAYER\n",
      "[0.50394684455954741, 0.49605315544045259]\n",
      "LOSS PER INSTANCE: 0.701072\n",
      "DERIVATIVE LOSS: -2.015913\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.701072\n",
      "EPOCH 315\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.93453372  0.91880785]\n",
      "SOFTMAX_LAYER\n",
      "[0.50393138424359174, 0.49606861575640826]\n",
      "LOSS PER INSTANCE: 0.701041\n",
      "DERIVATIVE LOSS: -2.015850\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.701041\n",
      "EPOCH 316\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.93468302  0.91901864]\n",
      "SOFTMAX_LAYER\n",
      "[0.50391601593944202, 0.49608398406055809]\n",
      "LOSS PER INSTANCE: 0.701010\n",
      "DERIVATIVE LOSS: -2.015788\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.701010\n",
      "EPOCH 317\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.93483169  0.91922841]\n",
      "SOFTMAX_LAYER\n",
      "[0.5039007389407667, 0.49609926105923341]\n",
      "LOSS PER INSTANCE: 0.700979\n",
      "DERIVATIVE LOSS: -2.015726\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.700979\n",
      "EPOCH 318\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.93497972  0.9194372 ]\n",
      "SOFTMAX_LAYER\n",
      "[0.5038855525476964, 0.49611444745230365]\n",
      "LOSS PER INSTANCE: 0.700949\n",
      "DERIVATIVE LOSS: -2.015664\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.700949\n",
      "EPOCH 319\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.93512712  0.91964499]\n",
      "SOFTMAX_LAYER\n",
      "[0.50387045606675751, 0.4961295439332426]\n",
      "LOSS PER INSTANCE: 0.700918\n",
      "DERIVATIVE LOSS: -2.015603\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.700918\n",
      "EPOCH 320\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.9352739  0.9198518]\n",
      "SOFTMAX_LAYER\n",
      "[0.50385544881080513, 0.49614455118919482]\n",
      "LOSS PER INSTANCE: 0.700888\n",
      "DERIVATIVE LOSS: -2.015542\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.700888\n",
      "EPOCH 321\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.93542005  0.92005763]\n",
      "SOFTMAX_LAYER\n",
      "[0.50384053009895924, 0.49615946990104065]\n",
      "LOSS PER INSTANCE: 0.700858\n",
      "DERIVATIVE LOSS: -2.015481\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.700858\n",
      "EPOCH 322\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.93556558  0.92026249]\n",
      "SOFTMAX_LAYER\n",
      "[0.50382569925653931, 0.49617430074346064]\n",
      "LOSS PER INSTANCE: 0.700828\n",
      "DERIVATIVE LOSS: -2.015421\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.700828\n",
      "EPOCH 323\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.9357105   0.92046638]\n",
      "SOFTMAX_LAYER\n",
      "[0.50381095561500056, 0.49618904438499944]\n",
      "LOSS PER INSTANCE: 0.700798\n",
      "DERIVATIVE LOSS: -2.015361\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.700798\n",
      "EPOCH 324\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.93585481  0.92066932]\n",
      "SOFTMAX_LAYER\n",
      "[0.50379629851187091, 0.49620370148812915]\n",
      "LOSS PER INSTANCE: 0.700769\n",
      "DERIVATIVE LOSS: -2.015301\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.700769\n",
      "EPOCH 325\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.93599851  0.92087131]\n",
      "SOFTMAX_LAYER\n",
      "[0.50378172729068926, 0.49621827270931085]\n",
      "LOSS PER INSTANCE: 0.700739\n",
      "DERIVATIVE LOSS: -2.015242\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.700739\n",
      "EPOCH 326\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.9361416   0.92107235]\n",
      "SOFTMAX_LAYER\n",
      "[0.50376724130094253, 0.49623275869905759]\n",
      "LOSS PER INSTANCE: 0.700710\n",
      "DERIVATIVE LOSS: -2.015183\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.700710\n",
      "EPOCH 327\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.93628409  0.92127245]\n",
      "SOFTMAX_LAYER\n",
      "[0.5037528398980059, 0.49624716010199416]\n",
      "LOSS PER INSTANCE: 0.700681\n",
      "DERIVATIVE LOSS: -2.015125\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.700681\n",
      "EPOCH 328\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.93642599  0.92147162]\n",
      "SOFTMAX_LAYER\n",
      "[0.50373852244308137, 0.49626147755691857]\n",
      "LOSS PER INSTANCE: 0.700652\n",
      "DERIVATIVE LOSS: -2.015067\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.700652\n",
      "EPOCH 329\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.93656729  0.92166987]\n",
      "SOFTMAX_LAYER\n",
      "[0.50372428830313909, 0.49627571169686091]\n",
      "LOSS PER INSTANCE: 0.700624\n",
      "DERIVATIVE LOSS: -2.015009\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.700624\n",
      "EPOCH 330\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.93670801  0.92186719]\n",
      "SOFTMAX_LAYER\n",
      "[0.50371013685085753, 0.49628986314914247]\n",
      "LOSS PER INSTANCE: 0.700595\n",
      "DERIVATIVE LOSS: -2.014951\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.700595\n",
      "EPOCH 331\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.93684814  0.9220636 ]\n",
      "SOFTMAX_LAYER\n",
      "[0.50369606746456563, 0.49630393253543431]\n",
      "LOSS PER INSTANCE: 0.700567\n",
      "DERIVATIVE LOSS: -2.014894\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.700567\n",
      "EPOCH 332\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.93698768  0.9222591 ]\n",
      "SOFTMAX_LAYER\n",
      "[0.50368207952818456, 0.49631792047181533]\n",
      "LOSS PER INSTANCE: 0.700539\n",
      "DERIVATIVE LOSS: -2.014838\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.700539\n",
      "EPOCH 333\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.93712665  0.92245369]\n",
      "SOFTMAX_LAYER\n",
      "[0.50366817243117135, 0.4963318275688286]\n",
      "LOSS PER INSTANCE: 0.700511\n",
      "DERIVATIVE LOSS: -2.014781\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.700511\n",
      "EPOCH 334\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.93726504  0.92264739]\n",
      "SOFTMAX_LAYER\n",
      "[0.50365434556846178, 0.49634565443153822]\n",
      "LOSS PER INSTANCE: 0.700483\n",
      "DERIVATIVE LOSS: -2.014725\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.700483\n",
      "EPOCH 335\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.93740285  0.9228402 ]\n",
      "SOFTMAX_LAYER\n",
      "[0.50364059834041497, 0.49635940165958514]\n",
      "LOSS PER INSTANCE: 0.700455\n",
      "DERIVATIVE LOSS: -2.014669\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.700455\n",
      "EPOCH 336\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.9375401   0.92303213]\n",
      "SOFTMAX_LAYER\n",
      "[0.5036269301527575, 0.49637306984724261]\n",
      "LOSS PER INSTANCE: 0.700427\n",
      "DERIVATIVE LOSS: -2.014614\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.700427\n",
      "EPOCH 337\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.93767678  0.92322317]\n",
      "SOFTMAX_LAYER\n",
      "[0.50361334041652983, 0.49638665958347022]\n",
      "LOSS PER INSTANCE: 0.700400\n",
      "DERIVATIVE LOSS: -2.014559\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.700400\n",
      "EPOCH 338\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.9378129   0.92341334]\n",
      "SOFTMAX_LAYER\n",
      "[0.50359982854803176, 0.4964001714519683]\n",
      "LOSS PER INSTANCE: 0.700373\n",
      "DERIVATIVE LOSS: -2.014504\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.700373\n",
      "EPOCH 339\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.93794846  0.92360264]\n",
      "SOFTMAX_LAYER\n",
      "[0.5035863939687687, 0.49641360603123125]\n",
      "LOSS PER INSTANCE: 0.700346\n",
      "DERIVATIVE LOSS: -2.014449\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.700346\n",
      "EPOCH 340\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.93808347  0.92379108]\n",
      "SOFTMAX_LAYER\n",
      "[0.50357303610539939, 0.4964269638946005]\n",
      "LOSS PER INSTANCE: 0.700319\n",
      "DERIVATIVE LOSS: -2.014395\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.700319\n",
      "EPOCH 341\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.93821792  0.92397866]\n",
      "SOFTMAX_LAYER\n",
      "[0.50355975438968348, 0.49644024561031641]\n",
      "LOSS PER INSTANCE: 0.700292\n",
      "DERIVATIVE LOSS: -2.014341\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.700292\n",
      "EPOCH 342\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.93835183  0.92416539]\n",
      "SOFTMAX_LAYER\n",
      "[0.50354654825842993, 0.49645345174157018]\n",
      "LOSS PER INSTANCE: 0.700266\n",
      "DERIVATIVE LOSS: -2.014288\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.700266\n",
      "EPOCH 343\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.93848518  0.92435128]\n",
      "SOFTMAX_LAYER\n",
      "[0.50353341715344502, 0.49646658284655493]\n",
      "LOSS PER INSTANCE: 0.700239\n",
      "DERIVATIVE LOSS: -2.014234\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.700239\n",
      "EPOCH 344\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.938618    0.92453632]\n",
      "SOFTMAX_LAYER\n",
      "[0.50352036052148386, 0.49647963947851609]\n",
      "LOSS PER INSTANCE: 0.700213\n",
      "DERIVATIVE LOSS: -2.014181\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.700213\n",
      "EPOCH 345\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.93875027  0.92472053]\n",
      "SOFTMAX_LAYER\n",
      "[0.5035073778141983, 0.4964926221858017]\n",
      "LOSS PER INSTANCE: 0.700187\n",
      "DERIVATIVE LOSS: -2.014129\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.700187\n",
      "EPOCH 346\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.93888201  0.92490391]\n",
      "SOFTMAX_LAYER\n",
      "[0.50349446848808888, 0.49650553151191118]\n",
      "LOSS PER INSTANCE: 0.700161\n",
      "DERIVATIVE LOSS: -2.014076\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.700161\n",
      "EPOCH 347\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.93901322  0.92508646]\n",
      "SOFTMAX_LAYER\n",
      "[0.50348163200445495, 0.496518367995545]\n",
      "LOSS PER INSTANCE: 0.700135\n",
      "DERIVATIVE LOSS: -2.014024\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.700135\n",
      "EPOCH 348\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.93914389  0.9252682 ]\n",
      "SOFTMAX_LAYER\n",
      "[0.50346886782934752, 0.49653113217065248]\n",
      "LOSS PER INSTANCE: 0.700109\n",
      "DERIVATIVE LOSS: -2.013972\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.700109\n",
      "EPOCH 349\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.93927404  0.92544912]\n",
      "SOFTMAX_LAYER\n",
      "[0.50345617543352028, 0.49654382456647983]\n",
      "LOSS PER INSTANCE: 0.700084\n",
      "DERIVATIVE LOSS: -2.013921\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.700084\n",
      "EPOCH 350\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.93940366  0.92562923]\n",
      "SOFTMAX_LAYER\n",
      "[0.50344355429238274, 0.49655644570761726]\n",
      "LOSS PER INSTANCE: 0.700058\n",
      "DERIVATIVE LOSS: -2.013870\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.700058\n",
      "EPOCH 351\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.93953276  0.92580853]\n",
      "SOFTMAX_LAYER\n",
      "[0.50343100388595385, 0.49656899611404615]\n",
      "LOSS PER INSTANCE: 0.700033\n",
      "DERIVATIVE LOSS: -2.013819\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.700033\n",
      "EPOCH 352\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.93966135  0.92598704]\n",
      "SOFTMAX_LAYER\n",
      "[0.50341852369881523, 0.49658147630118482]\n",
      "LOSS PER INSTANCE: 0.700008\n",
      "DERIVATIVE LOSS: -2.013768\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.700008\n",
      "EPOCH 353\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.93978942  0.92616475]\n",
      "SOFTMAX_LAYER\n",
      "[0.50340611322006601, 0.49659388677993399]\n",
      "LOSS PER INSTANCE: 0.699983\n",
      "DERIVATIVE LOSS: -2.013718\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.699983\n",
      "EPOCH 354\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.93991698  0.92634168]\n",
      "SOFTMAX_LAYER\n",
      "[0.50339377194327672, 0.49660622805672333]\n",
      "LOSS PER INSTANCE: 0.699958\n",
      "DERIVATIVE LOSS: -2.013668\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.699958\n",
      "EPOCH 355\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.94004402  0.92651782]\n",
      "SOFTMAX_LAYER\n",
      "[0.50338149936644505, 0.49661850063355489]\n",
      "LOSS PER INSTANCE: 0.699933\n",
      "DERIVATIVE LOSS: -2.013618\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.699933\n",
      "EPOCH 356\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.94017056  0.92669318]\n",
      "SOFTMAX_LAYER\n",
      "[0.50336929499195193, 0.49663070500804807]\n",
      "LOSS PER INSTANCE: 0.699909\n",
      "DERIVATIVE LOSS: -2.013569\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.699909\n",
      "EPOCH 357\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.9402966   0.92686777]\n",
      "SOFTMAX_LAYER\n",
      "[0.50335715832651717, 0.49664284167348283]\n",
      "LOSS PER INSTANCE: 0.699884\n",
      "DERIVATIVE LOSS: -2.013519\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.699884\n",
      "EPOCH 358\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.94042214  0.92704158]\n",
      "SOFTMAX_LAYER\n",
      "[0.50334508888115637, 0.49665491111884352]\n",
      "LOSS PER INSTANCE: 0.699860\n",
      "DERIVATIVE LOSS: -2.013470\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.699860\n",
      "EPOCH 359\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.94054718  0.92721464]\n",
      "SOFTMAX_LAYER\n",
      "[0.50333308617113837, 0.49666691382886158]\n",
      "LOSS PER INSTANCE: 0.699836\n",
      "DERIVATIVE LOSS: -2.013422\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.699836\n",
      "EPOCH 360\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.94067172  0.92738693]\n",
      "SOFTMAX_LAYER\n",
      "[0.50332114971594222, 0.49667885028405789]\n",
      "LOSS PER INSTANCE: 0.699812\n",
      "DERIVATIVE LOSS: -2.013373\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.699812\n",
      "EPOCH 361\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.94079578  0.92755847]\n",
      "SOFTMAX_LAYER\n",
      "[0.50330927903921618, 0.49669072096078382]\n",
      "LOSS PER INSTANCE: 0.699788\n",
      "DERIVATIVE LOSS: -2.013325\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.699788\n",
      "EPOCH 362\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.94091934  0.92772926]\n",
      "SOFTMAX_LAYER\n",
      "[0.5032974736687359, 0.49670252633126422]\n",
      "LOSS PER INSTANCE: 0.699764\n",
      "DERIVATIVE LOSS: -2.013277\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.699764\n",
      "EPOCH 363\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.94104242  0.9278993 ]\n",
      "SOFTMAX_LAYER\n",
      "[0.50328573313636271, 0.49671426686363723]\n",
      "LOSS PER INSTANCE: 0.699740\n",
      "DERIVATIVE LOSS: -2.013230\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.699740\n",
      "EPOCH 364\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.94116501  0.9280686 ]\n",
      "SOFTMAX_LAYER\n",
      "[0.50327405697800454, 0.49672594302199535]\n",
      "LOSS PER INSTANCE: 0.699717\n",
      "DERIVATIVE LOSS: -2.013183\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.699717\n",
      "EPOCH 365\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.94128712  0.92823716]\n",
      "SOFTMAX_LAYER\n",
      "[0.50326244473357484, 0.49673755526642505]\n",
      "LOSS PER INSTANCE: 0.699693\n",
      "DERIVATIVE LOSS: -2.013135\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.699693\n",
      "EPOCH 366\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.94140876  0.92840499]\n",
      "SOFTMAX_LAYER\n",
      "[0.50325089594695327, 0.49674910405304679]\n",
      "LOSS PER INSTANCE: 0.699670\n",
      "DERIVATIVE LOSS: -2.013089\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.699670\n",
      "EPOCH 367\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.94152992  0.92857209]\n",
      "SOFTMAX_LAYER\n",
      "[0.50323941016594564, 0.49676058983405441]\n",
      "LOSS PER INSTANCE: 0.699647\n",
      "DERIVATIVE LOSS: -2.013042\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.699647\n",
      "EPOCH 368\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.9416506   0.92873848]\n",
      "SOFTMAX_LAYER\n",
      "[0.5032279869422468, 0.49677201305775326]\n",
      "LOSS PER INSTANCE: 0.699624\n",
      "DERIVATIVE LOSS: -2.012996\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.699624\n",
      "EPOCH 369\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.94177082  0.92890414]\n",
      "SOFTMAX_LAYER\n",
      "[0.5032166258314007, 0.49678337416859936]\n",
      "LOSS PER INSTANCE: 0.699601\n",
      "DERIVATIVE LOSS: -2.012950\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.699601\n",
      "EPOCH 370\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.94189057  0.92906908]\n",
      "SOFTMAX_LAYER\n",
      "[0.50320532639276327, 0.49679467360723673]\n",
      "LOSS PER INSTANCE: 0.699578\n",
      "DERIVATIVE LOSS: -2.012904\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.699578\n",
      "EPOCH 371\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.94200985  0.92923332]\n",
      "SOFTMAX_LAYER\n",
      "[0.50319408818946498, 0.49680591181053507]\n",
      "LOSS PER INSTANCE: 0.699556\n",
      "DERIVATIVE LOSS: -2.012858\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.699556\n",
      "EPOCH 372\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.94212867  0.92939685]\n",
      "SOFTMAX_LAYER\n",
      "[0.50318291078837296, 0.49681708921162704]\n",
      "LOSS PER INSTANCE: 0.699533\n",
      "DERIVATIVE LOSS: -2.012813\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.699533\n",
      "EPOCH 373\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.94224703  0.92955968]\n",
      "SOFTMAX_LAYER\n",
      "[0.50317179376005461, 0.49682820623994539]\n",
      "LOSS PER INSTANCE: 0.699511\n",
      "DERIVATIVE LOSS: -2.012768\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.699511\n",
      "EPOCH 374\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.94236493  0.92972182]\n",
      "SOFTMAX_LAYER\n",
      "[0.50316073667874184, 0.49683926332125811]\n",
      "LOSS PER INSTANCE: 0.699489\n",
      "DERIVATIVE LOSS: -2.012723\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.699489\n",
      "EPOCH 375\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.94248238  0.92988326]\n",
      "SOFTMAX_LAYER\n",
      "[0.50314973912229444, 0.49685026087770551]\n",
      "LOSS PER INSTANCE: 0.699467\n",
      "DERIVATIVE LOSS: -2.012679\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.699467\n",
      "EPOCH 376\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.94259938  0.93004401]\n",
      "SOFTMAX_LAYER\n",
      "[0.50313880067216477, 0.49686119932783523]\n",
      "LOSS PER INSTANCE: 0.699445\n",
      "DERIVATIVE LOSS: -2.012635\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.699445\n",
      "EPOCH 377\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.94271593  0.93020408]\n",
      "SOFTMAX_LAYER\n",
      "[0.50312792091336234, 0.49687207908663766]\n",
      "LOSS PER INSTANCE: 0.699423\n",
      "DERIVATIVE LOSS: -2.012590\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.699423\n",
      "EPOCH 378\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.94283202  0.93036347]\n",
      "SOFTMAX_LAYER\n",
      "[0.50311709943441962, 0.49688290056558032]\n",
      "LOSS PER INSTANCE: 0.699401\n",
      "DERIVATIVE LOSS: -2.012547\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.699401\n",
      "EPOCH 379\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.94294768  0.93052218]\n",
      "SOFTMAX_LAYER\n",
      "[0.50310633582735731, 0.49689366417264275]\n",
      "LOSS PER INSTANCE: 0.699379\n",
      "DERIVATIVE LOSS: -2.012503\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.699379\n",
      "EPOCH 380\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.94306289  0.93068022]\n",
      "SOFTMAX_LAYER\n",
      "[0.50309562968764976, 0.49690437031235013]\n",
      "LOSS PER INSTANCE: 0.699358\n",
      "DERIVATIVE LOSS: -2.012460\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.699358\n",
      "EPOCH 381\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.94317767  0.93083759]\n",
      "SOFTMAX_LAYER\n",
      "[0.5030849806141926, 0.49691501938580723]\n",
      "LOSS PER INSTANCE: 0.699336\n",
      "DERIVATIVE LOSS: -2.012417\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.699336\n",
      "EPOCH 382\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.943292    0.93099429]\n",
      "SOFTMAX_LAYER\n",
      "[0.50307438820926809, 0.4969256117907318]\n",
      "LOSS PER INSTANCE: 0.699315\n",
      "DERIVATIVE LOSS: -2.012374\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.699315\n",
      "EPOCH 383\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.9434059   0.93115034]\n",
      "SOFTMAX_LAYER\n",
      "[0.5030638520785129, 0.4969361479214871]\n",
      "LOSS PER INSTANCE: 0.699294\n",
      "DERIVATIVE LOSS: -2.012331\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.699294\n",
      "EPOCH 384\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.94351937  0.93130573]\n",
      "SOFTMAX_LAYER\n",
      "[0.50305337183088572, 0.49694662816911439]\n",
      "LOSS PER INSTANCE: 0.699273\n",
      "DERIVATIVE LOSS: -2.012289\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.699273\n",
      "EPOCH 385\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.94363241  0.93146047]\n",
      "SOFTMAX_LAYER\n",
      "[0.50304294707863384, 0.4969570529213661]\n",
      "LOSS PER INSTANCE: 0.699252\n",
      "DERIVATIVE LOSS: -2.012246\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.699252\n",
      "EPOCH 386\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.94374502  0.93161456]\n",
      "SOFTMAX_LAYER\n",
      "[0.50303257743726304, 0.49696742256273702]\n",
      "LOSS PER INSTANCE: 0.699231\n",
      "DERIVATIVE LOSS: -2.012204\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.699231\n",
      "EPOCH 387\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.9438572  0.931768 ]\n",
      "SOFTMAX_LAYER\n",
      "[0.50302226252550464, 0.49697773747449531]\n",
      "LOSS PER INSTANCE: 0.699210\n",
      "DERIVATIVE LOSS: -2.012163\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.699210\n",
      "EPOCH 388\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.94396896  0.93192081]\n",
      "SOFTMAX_LAYER\n",
      "[0.50301200196528473, 0.49698799803471527]\n",
      "LOSS PER INSTANCE: 0.699189\n",
      "DERIVATIVE LOSS: -2.012121\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.699189\n",
      "EPOCH 389\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.9440803   0.93207297]\n",
      "SOFTMAX_LAYER\n",
      "[0.50300179538169321, 0.49699820461830674]\n",
      "LOSS PER INSTANCE: 0.699169\n",
      "DERIVATIVE LOSS: -2.012080\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.699169\n",
      "EPOCH 390\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.94419122  0.93222451]\n",
      "SOFTMAX_LAYER\n",
      "[0.50299164240295369, 0.49700835759704626]\n",
      "LOSS PER INSTANCE: 0.699148\n",
      "DERIVATIVE LOSS: -2.012039\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.699148\n",
      "EPOCH 391\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.94430172  0.93237541]\n",
      "SOFTMAX_LAYER\n",
      "[0.50298154266039274, 0.4970184573396072]\n",
      "LOSS PER INSTANCE: 0.699128\n",
      "DERIVATIVE LOSS: -2.011998\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.699128\n",
      "EPOCH 392\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.94441182  0.93252569]\n",
      "SOFTMAX_LAYER\n",
      "[0.50297149578841027, 0.49702850421158978]\n",
      "LOSS PER INSTANCE: 0.699108\n",
      "DERIVATIVE LOSS: -2.011957\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.699108\n",
      "EPOCH 393\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.94452149  0.93267535]\n",
      "SOFTMAX_LAYER\n",
      "[0.50296150142444973, 0.49703849857555038]\n",
      "LOSS PER INSTANCE: 0.699088\n",
      "DERIVATIVE LOSS: -2.011917\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.699088\n",
      "EPOCH 394\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.94463076  0.93282439]\n",
      "SOFTMAX_LAYER\n",
      "[0.50295155920896895, 0.497048440791031]\n",
      "LOSS PER INSTANCE: 0.699068\n",
      "DERIVATIVE LOSS: -2.011876\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.699068\n",
      "EPOCH 395\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.94473962  0.93297281]\n",
      "SOFTMAX_LAYER\n",
      "[0.50294166878541169, 0.49705833121458826]\n",
      "LOSS PER INSTANCE: 0.699048\n",
      "DERIVATIVE LOSS: -2.011836\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.699048\n",
      "EPOCH 396\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.94484808  0.93312063]\n",
      "SOFTMAX_LAYER\n",
      "[0.50293182980017814, 0.4970681701998218]\n",
      "LOSS PER INSTANCE: 0.699028\n",
      "DERIVATIVE LOSS: -2.011796\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.699028\n",
      "EPOCH 397\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.94495613  0.93326783]\n",
      "SOFTMAX_LAYER\n",
      "[0.50292204190259715, 0.49707795809740279]\n",
      "LOSS PER INSTANCE: 0.699008\n",
      "DERIVATIVE LOSS: -2.011757\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.699008\n",
      "EPOCH 398\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.94506378  0.93341443]\n",
      "SOFTMAX_LAYER\n",
      "[0.50291230474489823, 0.49708769525510171]\n",
      "LOSS PER INSTANCE: 0.698989\n",
      "DERIVATIVE LOSS: -2.011717\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.698989\n",
      "EPOCH 399\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.94517104  0.93356043]\n",
      "SOFTMAX_LAYER\n",
      "[0.50290261798218328, 0.49709738201781656]\n",
      "LOSS PER INSTANCE: 0.698969\n",
      "DERIVATIVE LOSS: -2.011678\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.698969\n"
     ]
    }
   ],
   "source": [
    "class SigmoidNN(NN):\n",
    "    def _activate(self, x):\n",
    "        \"\"\"\n",
    "        override RelU with sigmoid\n",
    "        \"\"\"\n",
    "        return self._sigmoid(x)\n",
    "    \n",
    "    def _derivative_activation(self, x):\n",
    "        \"\"\"\n",
    "        Override RelU' with Sigmoid'\n",
    "        \"\"\"\n",
    "        return self._derivative_sigmoid(x)\n",
    "    \n",
    "\"\"\"\n",
    "Run the same test with sigmoid\n",
    "\"\"\"\n",
    "MLP = SigmoidNN(2, 1, 2, 2)\n",
    "xor_inputs = [[1, 1], [-1, 1], [-1, -1], [1, -1]]\n",
    "xor_labels = ([1, 0, 1, 0])\n",
    "MLP.train(xor_inputs, xor_labels, epochs=400, lr=.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 0.49273336 -1.13956867]\n",
      "SOFTMAX_LAYER\n",
      "[0.83648474974254705, 0.16351525025745295]\n",
      "LOSS PER INSTANCE: 1.810849\n",
      "DERIVATIVE LOSS: -6.115638\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 1.810849\n",
      "EPOCH 1\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 1.12391059 -1.04140685]\n",
      "SOFTMAX_LAYER\n",
      "[0.89709148395556404, 0.10290851604443597]\n",
      "LOSS PER INSTANCE: 2.273915\n",
      "DERIVATIVE LOSS: -9.717369\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.273915\n",
      "EPOCH 2\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 1.24505699 -1.02890931]\n",
      "SOFTMAX_LAYER\n",
      "[0.90669786592101975, 0.09330213407898022]\n",
      "LOSS PER INSTANCE: 2.371912\n",
      "DERIVATIVE LOSS: -10.717868\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.371912\n",
      "EPOCH 3\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 1.82899921 -1.02227216]\n",
      "SOFTMAX_LAYER\n",
      "[0.94538436409538695, 0.05461563590461313]\n",
      "LOSS PER INSTANCE: 2.907435\n",
      "DERIVATIVE LOSS: -18.309775\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.907435\n",
      "EPOCH 4\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ 19.95614357  -1.01558627]\n",
      "SOFTMAX_LAYER\n",
      "[0.99999999922000216, 7.7999794088111808e-10]\n",
      "LOSS PER INSTANCE: 20.971730\n",
      "DERIVATIVE LOSS: -1282054666.542271\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 20.971730\n",
      "EPOCH 5\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[  3.64167980e+13   2.27752993e+05]\n",
      "SOFTMAX_LAYER\n",
      "[nan, nan]\n",
      "LOSS PER INSTANCE: nan\n",
      "DERIVATIVE LOSS: nan\n",
      "UPDATING WEIGHTS\n",
      "LOSS: nan\n",
      "EPOCH 6\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ nan  nan]\n",
      "SOFTMAX_LAYER\n",
      "[nan, nan]\n",
      "LOSS PER INSTANCE: nan\n",
      "DERIVATIVE LOSS: nan\n",
      "UPDATING WEIGHTS\n",
      "LOSS: nan\n",
      "EPOCH 7\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ nan  nan]\n",
      "SOFTMAX_LAYER\n",
      "[nan, nan]\n",
      "LOSS PER INSTANCE: nan\n",
      "DERIVATIVE LOSS: nan\n",
      "UPDATING WEIGHTS\n",
      "LOSS: nan\n",
      "EPOCH 8\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ nan  nan]\n",
      "SOFTMAX_LAYER\n",
      "[nan, nan]\n",
      "LOSS PER INSTANCE: nan\n",
      "DERIVATIVE LOSS: nan\n",
      "UPDATING WEIGHTS\n",
      "LOSS: nan\n",
      "EPOCH 9\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ nan  nan]\n",
      "SOFTMAX_LAYER\n",
      "[nan, nan]\n",
      "LOSS PER INSTANCE: nan\n",
      "DERIVATIVE LOSS: nan\n",
      "UPDATING WEIGHTS\n",
      "LOSS: nan\n",
      "EPOCH 10\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ nan  nan]\n",
      "SOFTMAX_LAYER\n",
      "[nan, nan]\n",
      "LOSS PER INSTANCE: nan\n",
      "DERIVATIVE LOSS: nan\n",
      "UPDATING WEIGHTS\n",
      "LOSS: nan\n",
      "EPOCH 11\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ nan  nan]\n",
      "SOFTMAX_LAYER\n",
      "[nan, nan]\n",
      "LOSS PER INSTANCE: nan\n",
      "DERIVATIVE LOSS: nan\n",
      "UPDATING WEIGHTS\n",
      "LOSS: nan\n",
      "EPOCH 12\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ nan  nan]\n",
      "SOFTMAX_LAYER\n",
      "[nan, nan]\n",
      "LOSS PER INSTANCE: nan\n",
      "DERIVATIVE LOSS: nan\n",
      "UPDATING WEIGHTS\n",
      "LOSS: nan\n",
      "EPOCH 13\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ nan  nan]\n",
      "SOFTMAX_LAYER\n",
      "[nan, nan]\n",
      "LOSS PER INSTANCE: nan\n",
      "DERIVATIVE LOSS: nan\n",
      "UPDATING WEIGHTS\n",
      "LOSS: nan\n",
      "EPOCH 14\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ nan  nan]\n",
      "SOFTMAX_LAYER\n",
      "[nan, nan]\n",
      "LOSS PER INSTANCE: nan\n",
      "DERIVATIVE LOSS: nan\n",
      "UPDATING WEIGHTS\n",
      "LOSS: nan\n",
      "EPOCH 15\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ nan  nan]\n",
      "SOFTMAX_LAYER\n",
      "[nan, nan]\n",
      "LOSS PER INSTANCE: nan\n",
      "DERIVATIVE LOSS: nan\n",
      "UPDATING WEIGHTS\n",
      "LOSS: nan\n",
      "EPOCH 16\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ nan  nan]\n",
      "SOFTMAX_LAYER\n",
      "[nan, nan]\n",
      "LOSS PER INSTANCE: nan\n",
      "DERIVATIVE LOSS: nan\n",
      "UPDATING WEIGHTS\n",
      "LOSS: nan\n",
      "EPOCH 17\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ nan  nan]\n",
      "SOFTMAX_LAYER\n",
      "[nan, nan]\n",
      "LOSS PER INSTANCE: nan\n",
      "DERIVATIVE LOSS: nan\n",
      "UPDATING WEIGHTS\n",
      "LOSS: nan\n",
      "EPOCH 18\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ nan  nan]\n",
      "SOFTMAX_LAYER\n",
      "[nan, nan]\n",
      "LOSS PER INSTANCE: nan\n",
      "DERIVATIVE LOSS: nan\n",
      "UPDATING WEIGHTS\n",
      "LOSS: nan\n",
      "EPOCH 19\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ nan  nan]\n",
      "SOFTMAX_LAYER\n",
      "[nan, nan]\n",
      "LOSS PER INSTANCE: nan\n",
      "DERIVATIVE LOSS: nan\n",
      "UPDATING WEIGHTS\n",
      "LOSS: nan\n",
      "EPOCH 20\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ nan  nan]\n",
      "SOFTMAX_LAYER\n",
      "[nan, nan]\n",
      "LOSS PER INSTANCE: nan\n",
      "DERIVATIVE LOSS: nan\n",
      "UPDATING WEIGHTS\n",
      "LOSS: nan\n",
      "EPOCH 21\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ nan  nan]\n",
      "SOFTMAX_LAYER\n",
      "[nan, nan]\n",
      "LOSS PER INSTANCE: nan\n",
      "DERIVATIVE LOSS: nan\n",
      "UPDATING WEIGHTS\n",
      "LOSS: nan\n",
      "EPOCH 22\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ nan  nan]\n",
      "SOFTMAX_LAYER\n",
      "[nan, nan]\n",
      "LOSS PER INSTANCE: nan\n",
      "DERIVATIVE LOSS: nan\n",
      "UPDATING WEIGHTS\n",
      "LOSS: nan\n",
      "EPOCH 23\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ nan  nan]\n",
      "SOFTMAX_LAYER\n",
      "[nan, nan]\n",
      "LOSS PER INSTANCE: nan\n",
      "DERIVATIVE LOSS: nan\n",
      "UPDATING WEIGHTS\n",
      "LOSS: nan\n",
      "EPOCH 24\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ nan  nan]\n",
      "SOFTMAX_LAYER\n",
      "[nan, nan]\n",
      "LOSS PER INSTANCE: nan\n",
      "DERIVATIVE LOSS: nan\n",
      "UPDATING WEIGHTS\n",
      "LOSS: nan\n",
      "EPOCH 25\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ nan  nan]\n",
      "SOFTMAX_LAYER\n",
      "[nan, nan]\n",
      "LOSS PER INSTANCE: nan\n",
      "DERIVATIVE LOSS: nan\n",
      "UPDATING WEIGHTS\n",
      "LOSS: nan\n",
      "EPOCH 26\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ nan  nan]\n",
      "SOFTMAX_LAYER\n",
      "[nan, nan]\n",
      "LOSS PER INSTANCE: nan\n",
      "DERIVATIVE LOSS: nan\n",
      "UPDATING WEIGHTS\n",
      "LOSS: nan\n",
      "EPOCH 27\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ nan  nan]\n",
      "SOFTMAX_LAYER\n",
      "[nan, nan]\n",
      "LOSS PER INSTANCE: nan\n",
      "DERIVATIVE LOSS: nan\n",
      "UPDATING WEIGHTS\n",
      "LOSS: nan\n",
      "EPOCH 28\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ nan  nan]\n",
      "SOFTMAX_LAYER\n",
      "[nan, nan]\n",
      "LOSS PER INSTANCE: nan\n",
      "DERIVATIVE LOSS: nan\n",
      "UPDATING WEIGHTS\n",
      "LOSS: nan\n",
      "EPOCH 29\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ nan  nan]\n",
      "SOFTMAX_LAYER\n",
      "[nan, nan]\n",
      "LOSS PER INSTANCE: nan\n",
      "DERIVATIVE LOSS: nan\n",
      "UPDATING WEIGHTS\n",
      "LOSS: nan\n",
      "EPOCH 30\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ nan  nan]\n",
      "SOFTMAX_LAYER\n",
      "[nan, nan]\n",
      "LOSS PER INSTANCE: nan\n",
      "DERIVATIVE LOSS: nan\n",
      "UPDATING WEIGHTS\n",
      "LOSS: nan\n",
      "EPOCH 31\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ nan  nan]\n",
      "SOFTMAX_LAYER\n",
      "[nan, nan]\n",
      "LOSS PER INSTANCE: nan\n",
      "DERIVATIVE LOSS: nan\n",
      "UPDATING WEIGHTS\n",
      "LOSS: nan\n",
      "EPOCH 32\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ nan  nan]\n",
      "SOFTMAX_LAYER\n",
      "[nan, nan]\n",
      "LOSS PER INSTANCE: nan\n",
      "DERIVATIVE LOSS: nan\n",
      "UPDATING WEIGHTS\n",
      "LOSS: nan\n",
      "EPOCH 33\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ nan  nan]\n",
      "SOFTMAX_LAYER\n",
      "[nan, nan]\n",
      "LOSS PER INSTANCE: nan\n",
      "DERIVATIVE LOSS: nan\n",
      "UPDATING WEIGHTS\n",
      "LOSS: nan\n",
      "EPOCH 34\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ nan  nan]\n",
      "SOFTMAX_LAYER\n",
      "[nan, nan]\n",
      "LOSS PER INSTANCE: nan\n",
      "DERIVATIVE LOSS: nan\n",
      "UPDATING WEIGHTS\n",
      "LOSS: nan\n",
      "EPOCH 35\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ nan  nan]\n",
      "SOFTMAX_LAYER\n",
      "[nan, nan]\n",
      "LOSS PER INSTANCE: nan\n",
      "DERIVATIVE LOSS: nan\n",
      "UPDATING WEIGHTS\n",
      "LOSS: nan\n",
      "EPOCH 36\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ nan  nan]\n",
      "SOFTMAX_LAYER\n",
      "[nan, nan]\n",
      "LOSS PER INSTANCE: nan\n",
      "DERIVATIVE LOSS: nan\n",
      "UPDATING WEIGHTS\n",
      "LOSS: nan\n",
      "EPOCH 37\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ nan  nan]\n",
      "SOFTMAX_LAYER\n",
      "[nan, nan]\n",
      "LOSS PER INSTANCE: nan\n",
      "DERIVATIVE LOSS: nan\n",
      "UPDATING WEIGHTS\n",
      "LOSS: nan\n",
      "EPOCH 38\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ nan  nan]\n",
      "SOFTMAX_LAYER\n",
      "[nan, nan]\n",
      "LOSS PER INSTANCE: nan\n",
      "DERIVATIVE LOSS: nan\n",
      "UPDATING WEIGHTS\n",
      "LOSS: nan\n",
      "EPOCH 39\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ nan  nan]\n",
      "SOFTMAX_LAYER\n",
      "[nan, nan]\n",
      "LOSS PER INSTANCE: nan\n",
      "DERIVATIVE LOSS: nan\n",
      "UPDATING WEIGHTS\n",
      "LOSS: nan\n",
      "EPOCH 40\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ nan  nan]\n",
      "SOFTMAX_LAYER\n",
      "[nan, nan]\n",
      "LOSS PER INSTANCE: nan\n",
      "DERIVATIVE LOSS: nan\n",
      "UPDATING WEIGHTS\n",
      "LOSS: nan\n",
      "EPOCH 41\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ nan  nan]\n",
      "SOFTMAX_LAYER\n",
      "[nan, nan]\n",
      "LOSS PER INSTANCE: nan\n",
      "DERIVATIVE LOSS: nan\n",
      "UPDATING WEIGHTS\n",
      "LOSS: nan\n",
      "EPOCH 42\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ nan  nan]\n",
      "SOFTMAX_LAYER\n",
      "[nan, nan]\n",
      "LOSS PER INSTANCE: nan\n",
      "DERIVATIVE LOSS: nan\n",
      "UPDATING WEIGHTS\n",
      "LOSS: nan\n",
      "EPOCH 43\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ nan  nan]\n",
      "SOFTMAX_LAYER\n",
      "[nan, nan]\n",
      "LOSS PER INSTANCE: nan\n",
      "DERIVATIVE LOSS: nan\n",
      "UPDATING WEIGHTS\n",
      "LOSS: nan\n",
      "EPOCH 44\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ nan  nan]\n",
      "SOFTMAX_LAYER\n",
      "[nan, nan]\n",
      "LOSS PER INSTANCE: nan\n",
      "DERIVATIVE LOSS: nan\n",
      "UPDATING WEIGHTS\n",
      "LOSS: nan\n",
      "EPOCH 45\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ nan  nan]\n",
      "SOFTMAX_LAYER\n",
      "[nan, nan]\n",
      "LOSS PER INSTANCE: nan\n",
      "DERIVATIVE LOSS: nan\n",
      "UPDATING WEIGHTS\n",
      "LOSS: nan\n",
      "EPOCH 46\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ nan  nan]\n",
      "SOFTMAX_LAYER\n",
      "[nan, nan]\n",
      "LOSS PER INSTANCE: nan\n",
      "DERIVATIVE LOSS: nan\n",
      "UPDATING WEIGHTS\n",
      "LOSS: nan\n",
      "EPOCH 47\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ nan  nan]\n",
      "SOFTMAX_LAYER\n",
      "[nan, nan]\n",
      "LOSS PER INSTANCE: nan\n",
      "DERIVATIVE LOSS: nan\n",
      "UPDATING WEIGHTS\n",
      "LOSS: nan\n",
      "EPOCH 48\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ nan  nan]\n",
      "SOFTMAX_LAYER\n",
      "[nan, nan]\n",
      "LOSS PER INSTANCE: nan\n",
      "DERIVATIVE LOSS: nan\n",
      "UPDATING WEIGHTS\n",
      "LOSS: nan\n",
      "EPOCH 49\n",
      "INPUT: \n",
      "[-1, -1]\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "ACTIVATIONS OUT\n",
      "[ nan  nan]\n",
      "SOFTMAX_LAYER\n",
      "[nan, nan]\n",
      "LOSS PER INSTANCE: nan\n",
      "DERIVATIVE LOSS: nan\n",
      "UPDATING WEIGHTS\n",
      "LOSS: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel_launcher.py:61: RuntimeWarning: overflow encountered in exp\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel_launcher.py:63: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "class TanHNN(NN):\n",
    "    \n",
    "    def _activate(self, x):\n",
    "        \"\"\"\n",
    "        Override with TanH\n",
    "        \"\"\"\n",
    "        return np.tanh(x)\n",
    "    \n",
    "    def _derivative_activation(self, x):\n",
    "        \"\"\"\n",
    "        Override with Derivative TanH (1 - tanH squared)\n",
    "        \"\"\"\n",
    "        return 1 - x*x\n",
    "    \n",
    "\"\"\"\n",
    "Run the same test with sigmoid\n",
    "\"\"\"\n",
    "MLP = TanHNN(2, 2, 2, 2)\n",
    "xor_inputs = [[1, 1], [-1, 1], [-1, -1], [1, -1]]\n",
    "xor_labels = ([1, 0, 1, 0])\n",
    "MLP.train(xor_inputs, xor_labels, epochs=50, lr=.06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "def neighborhood2int(n):\n",
    "    \"\"\"\n",
    "    For mapping neighborhoods into integer labels\n",
    "    \"\"\"\n",
    "    return 1 if n == \"Blmngtn\" else 0\n",
    "\n",
    "df = pd.DataFrame.from_csv(\"./data/housing_date_train_2_features.csv\")\n",
    "housing_df = df.loc[df['Neighborhood'].isin([\"BrDale\", \"Blmngtn\"])]\n",
    "\n",
    "# Grab X and its labels as a single matrix\n",
    "dataset = housing_df[[\"LotArea\", \"SalePrice\", \"Neighborhood\"]].as_matrix()\n",
    "\n",
    "# 'shuffle' the matrix to randomize the position of each sample in it\n",
    "np.random.shuffle(dataset)\n",
    "\n",
    "# Not sure why shuffling changed the type, but need to \n",
    "# change the type of each scalar in X for some numpy methods to work\n",
    "X = dataset[:, :2].astype('int64')\n",
    "# Encode the labels\n",
    "y = [neighborhood2int(s) for s in dataset[:, 2]]\n",
    "\n",
    "# Find the length of 80% of the dataset for training data\n",
    "train_length = int(X.shape[0] * 0.8)\n",
    "\n",
    "# split 80%/20% for train and test\n",
    "train_X = X[:train_length]\n",
    "test_X = X[train_length:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
