{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.19460627 -1.30933239  0.        ]\n",
      " [ 0.02253486 -0.0919106   0.        ]\n",
      " [-0.59018916 -0.27899367  0.        ]]\n",
      "[]\n",
      "[[-0.28058584  0.00466762]\n",
      " [-0.61509392  0.70718596]\n",
      " [-1.16977482  0.47363445]]\n",
      "SOFTMAX_LAYER\n",
      "[0.035801034170245064, 0.96419896582975495]\n",
      "LOSS PER INSTANCE: 0.036458\n",
      "DERIVATIVE LOSS: -1.037130\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.036458\n",
      "EPOCH 1\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.19465468 -1.31666683  0.        ]\n",
      " [ 0.02248645 -0.09924504  0.        ]\n",
      " [-0.59014075 -0.27165923  0.        ]]\n",
      "[]\n",
      "[[-0.28058584  0.0107025 ]\n",
      " [-0.61509392  0.71882515]\n",
      " [-1.16977482  0.48400575]]\n",
      "SOFTMAX_LAYER\n",
      "[0.033906338854587229, 0.96609366114541284]\n",
      "LOSS PER INSTANCE: 0.034494\n",
      "DERIVATIVE LOSS: -1.035096\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.034494\n",
      "EPOCH 2\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.19476546 -1.32410736  0.        ]\n",
      " [ 0.02237567 -0.10668557  0.        ]\n",
      " [-0.59002997 -0.2642187   0.        ]]\n",
      "[]\n",
      "[[-0.28058584  0.01672704]\n",
      " [-0.61509392  0.73066927]\n",
      " [-1.16977482  0.49435672]]\n",
      "SOFTMAX_LAYER\n",
      "[0.032070977265155412, 0.9679290227348446]\n",
      "LOSS PER INSTANCE: 0.032597\n",
      "DERIVATIVE LOSS: -1.033134\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.032597\n",
      "EPOCH 3\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.19493827 -1.33165615  0.        ]\n",
      " [ 0.02220286 -0.11423436  0.        ]\n",
      " [-0.58985716 -0.25666991  0.        ]]\n",
      "[]\n",
      "[[-0.28058584  0.0227436 ]\n",
      " [-0.61509392  0.74272154]\n",
      " [-1.16977482  0.50468805]]\n",
      "SOFTMAX_LAYER\n",
      "[0.030295002711982731, 0.96970499728801729]\n",
      "LOSS PER INSTANCE: 0.030763\n",
      "DERIVATIVE LOSS: -1.031241\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.030763\n",
      "EPOCH 4\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.19517282 -1.3393154   0.        ]\n",
      " [ 0.02196832 -0.12189361  0.        ]\n",
      " [-0.58962262 -0.24901065  0.        ]]\n",
      "[]\n",
      "[[-0.28058584  0.02875448]\n",
      " [-0.61509392  0.75498527]\n",
      " [-1.16977482  0.51500047]]\n",
      "SOFTMAX_LAYER\n",
      "[0.028578425807024251, 0.97142157419297581]\n",
      "LOSS PER INSTANCE: 0.028995\n",
      "DERIVATIVE LOSS: -1.029419\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.028995\n",
      "EPOCH 5\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.19546882 -1.34708737  0.        ]\n",
      " [ 0.02167231 -0.12966558  0.        ]\n",
      " [-0.58932661 -0.24123869  0.        ]]\n",
      "[]\n",
      "[[-0.28058584  0.03476198]\n",
      " [-0.61509392  0.76746388]\n",
      " [-1.16977482  0.52529466]]\n",
      "SOFTMAX_LAYER\n",
      "[0.026921208786805879, 0.97307879121319407]\n",
      "LOSS PER INSTANCE: 0.027290\n",
      "DERIVATIVE LOSS: -1.027666\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.027290\n",
      "EPOCH 6\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.19582606 -1.35497433  0.        ]\n",
      " [ 0.02131508 -0.13755254  0.        ]\n",
      " [-0.58896938 -0.23335172  0.        ]]\n",
      "[]\n",
      "[[-0.28058584  0.04076838]\n",
      " [-0.61509392  0.78016084]\n",
      " [-1.16977482  0.53557132]]\n",
      "SOFTMAX_LAYER\n",
      "[0.025323260128409426, 0.97467673987159054]\n",
      "LOSS PER INSTANCE: 0.025649\n",
      "DERIVATIVE LOSS: -1.025981\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.025649\n",
      "EPOCH 7\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.19624433 -1.36297864  0.        ]\n",
      " [ 0.0208968  -0.14555684  0.        ]\n",
      " [-0.5885511  -0.22534742  0.        ]]\n",
      "[]\n",
      "[[-0.28058584  0.04677593]\n",
      " [-0.61509392  0.79307974]\n",
      " [-1.16977482  0.54583113]]\n",
      "SOFTMAX_LAYER\n",
      "[0.023784429488920813, 0.97621557051107921]\n",
      "LOSS PER INSTANCE: 0.024072\n",
      "DERIVATIVE LOSS: -1.024364\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.024072\n",
      "EPOCH 8\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.19672349 -1.37110266  0.        ]\n",
      " [ 0.02041765 -0.15368087  0.        ]\n",
      " [-0.58807194 -0.2172234   0.        ]]\n",
      "[]\n",
      "[[-0.28058584  0.05278686]\n",
      " [-0.61509392  0.80622425]\n",
      " [-1.16977482  0.55607477]]\n",
      "SOFTMAX_LAYER\n",
      "[0.022304502999875332, 0.9776954970001247]\n",
      "LOSS PER INSTANCE: 0.022557\n",
      "DERIVATIVE LOSS: -1.022813\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.022557\n",
      "EPOCH 9\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.1972634  -1.37934883  0.        ]\n",
      " [ 0.01987773 -0.16192704  0.        ]\n",
      " [-0.58753203 -0.20897723  0.        ]]\n",
      "[]\n",
      "[[-0.28058584  0.05880339]\n",
      " [-0.61509392  0.81959815]\n",
      " [-1.16977482  0.5663029 ]]\n",
      "SOFTMAX_LAYER\n",
      "[0.020883198949262029, 0.97911680105073806]\n",
      "LOSS PER INSTANCE: 0.021104\n",
      "DERIVATIVE LOSS: -1.021329\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.021104\n",
      "EPOCH 10\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.19786398 -1.38771962  0.        ]\n",
      " [ 0.01927716 -0.17029783  0.        ]\n",
      " [-0.58693146 -0.20060644  0.        ]]\n",
      "[]\n",
      "[[-0.28058584  0.06482774]\n",
      " [-0.61509392  0.8332053 ]\n",
      " [-1.16977482  0.57651619]]\n",
      "SOFTMAX_LAYER\n",
      "[0.019520163884257483, 0.98047983611574241]\n",
      "LOSS PER INSTANCE: 0.019713\n",
      "DERIVATIVE LOSS: -1.019909\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.019713\n",
      "EPOCH 11\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.19852516 -1.39621755  0.        ]\n",
      " [ 0.01861598 -0.17879576  0.        ]\n",
      " [-0.58627027 -0.19210851  0.        ]]\n",
      "[]\n",
      "[[-0.28058584  0.07086208]\n",
      " [-0.61509392  0.84704965]\n",
      " [-1.16977482  0.58671528]]\n",
      "SOFTMAX_LAYER\n",
      "[0.018214969168011651, 0.98178503083198831]\n",
      "LOSS PER INSTANCE: 0.018383\n",
      "DERIVATIVE LOSS: -1.018553\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.018383\n",
      "EPOCH 12\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.19924693 -1.4048452   0.        ]\n",
      " [ 0.01789421 -0.18742341  0.        ]\n",
      " [-0.58554851 -0.18348086  0.        ]]\n",
      "[]\n",
      "[[-0.28058584  0.07690861]\n",
      " [-0.61509392  0.86113527]\n",
      " [-1.16977482  0.59690081]]\n",
      "SOFTMAX_LAYER\n",
      "[0.016967108023464714, 0.98303289197653521]\n",
      "LOSS PER INSTANCE: 0.017113\n",
      "DERIVATIVE LOSS: -1.017260\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.017113\n",
      "EPOCH 13\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.20002929 -1.41360519  0.        ]\n",
      " [ 0.01711185 -0.19618339  0.        ]\n",
      " [-0.58476614 -0.17472087  0.        ]]\n",
      "[]\n",
      "[[-0.28058584  0.08296948]\n",
      " [-0.61509392  0.8754663 ]\n",
      " [-1.16977482  0.60707341]]\n",
      "SOFTMAX_LAYER\n",
      "[0.015775993096300459, 0.98422400690369949]\n",
      "LOSS PER INSTANCE: 0.015902\n",
      "DERIVATIVE LOSS: -1.016029\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.015902\n",
      "EPOCH 14\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.20087228 -1.42250018  0.        ]\n",
      " [ 0.01626885 -0.20507838  0.        ]\n",
      " [-0.58392315 -0.16582588  0.        ]]\n",
      "[]\n",
      "[[-0.28058584  0.08904687]\n",
      " [-0.61509392  0.89004701]\n",
      " [-1.16977482  0.6172337 ]]\n",
      "SOFTMAX_LAYER\n",
      "[0.014640954567703536, 0.98535904543229647]\n",
      "LOSS PER INSTANCE: 0.014749\n",
      "DERIVATIVE LOSS: -1.014858\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.014749\n",
      "EPOCH 15\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.20177598 -1.43153289  0.        ]\n",
      " [ 0.01536515 -0.2141111   0.        ]\n",
      " [-0.58301945 -0.15679316  0.        ]]\n",
      "[]\n",
      "[[-0.28058584  0.09514293]\n",
      " [-0.61509392  0.90488173]\n",
      " [-1.16977482  0.62738228]]\n",
      "SOFTMAX_LAYER\n",
      "[0.013561238845556265, 0.98643876115444373]\n",
      "LOSS PER INSTANCE: 0.013654\n",
      "DERIVATIVE LOSS: -1.013748\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.013654\n",
      "EPOCH 16\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.20274049 -1.44070611  0.        ]\n",
      " [ 0.01440064 -0.22328432  0.        ]\n",
      " [-0.58205494 -0.14761995  0.        ]]\n",
      "[]\n",
      "[[-0.28058584  0.1012598 ]\n",
      " [-0.61509392  0.91997492]\n",
      " [-1.16977482  0.63751976]]\n",
      "SOFTMAX_LAYER\n",
      "[0.012536007860062315, 0.98746399213993763]\n",
      "LOSS PER INSTANCE: 0.012615\n",
      "DERIVATIVE LOSS: -1.012695\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.012615\n",
      "EPOCH 17\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.20376594 -1.45002265  0.        ]\n",
      " [ 0.01337519 -0.23260086  0.        ]\n",
      " [-0.58102949 -0.1383034   0.        ]]\n",
      "[]\n",
      "[[-0.28058584  0.10739961]\n",
      " [-0.61509392  0.93533113]\n",
      " [-1.16977482  0.64764671]]\n",
      "SOFTMAX_LAYER\n",
      "[0.011564338986501414, 0.98843566101349867]\n",
      "LOSS PER INSTANCE: 0.011632\n",
      "DERIVATIVE LOSS: -1.011700\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.011632\n",
      "EPOCH 18\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.2048525  -1.4594854   0.        ]\n",
      " [ 0.01228863 -0.2420636   0.        ]\n",
      " [-0.57994293 -0.12884066  0.        ]]\n",
      "[]\n",
      "[[-0.28058584  0.11356452]\n",
      " [-0.61509392  0.95095501]\n",
      " [-1.16977482  0.65776371]]\n",
      "SOFTMAX_LAYER\n",
      "[0.010645225613892721, 0.98935477438610731]\n",
      "LOSS PER INSTANCE: 0.010702\n",
      "DERIVATIVE LOSS: -1.010760\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.010702\n",
      "EPOCH 19\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.20600037 -1.46909727  0.        ]\n",
      " [ 0.01114077 -0.25167547  0.        ]\n",
      " [-0.57879506 -0.11922879  0.        ]]\n",
      "[]\n",
      "[[-0.28058584  0.11975665]\n",
      " [-0.61509392  0.96685131]\n",
      " [-1.16977482  0.6678713 ]]\n",
      "SOFTMAX_LAYER\n",
      "[0.009777578373775039, 0.99022242162622487]\n",
      "LOSS PER INSTANCE: 0.009826\n",
      "DERIVATIVE LOSS: -1.009874\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.009826\n",
      "EPOCH 20\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.20720976 -1.47886125  0.        ]\n",
      " [ 0.00993137 -0.26143945  0.        ]\n",
      " [-0.57758567 -0.10946481  0.        ]]\n",
      "[]\n",
      "[[-0.28058584  0.12597812]\n",
      " [-0.61509392  0.98302489]\n",
      " [-1.16977482  0.67797004]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0089602270381124328, 0.99103977296188761]\n",
      "LOSS PER INSTANCE: 0.009001\n",
      "DERIVATIVE LOSS: -1.009041\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.009001\n",
      "EPOCH 21\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.20848093 -1.48878037  0.        ]\n",
      " [ 0.0086602  -0.27135858  0.        ]\n",
      " [-0.5763145  -0.09954568  0.        ]]\n",
      "[]\n",
      "[[-0.28058584  0.13223108]\n",
      " [-0.61509392  0.9994807 ]\n",
      " [-1.16977482  0.68806046]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0081919230895270024, 0.99180807691047301]\n",
      "LOSS PER INSTANCE: 0.008226\n",
      "DERIVATIVE LOSS: -1.008260\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.008226\n",
      "EPOCH 22\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.20981416 -1.49885773  0.        ]\n",
      " [ 0.00732697 -0.28143594  0.        ]\n",
      " [-0.57498127 -0.08946833  0.        ]]\n",
      "[]\n",
      "[[-0.28058584  0.13851764]\n",
      " [-0.61509392  1.01622379]\n",
      " [-1.16977482  0.69814305]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0074713429606867105, 0.99252865703931326]\n",
      "LOSS PER INSTANCE: 0.007499\n",
      "DERIVATIVE LOSS: -1.007528\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.007499\n",
      "EPOCH 23\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.21120977 -1.50909647  0.        ]\n",
      " [ 0.00593137 -0.29167468  0.        ]\n",
      " [-0.57358566 -0.07922959  0.        ]]\n",
      "[]\n",
      "[[-0.28058584  0.14483993]\n",
      " [-0.61509392  1.03325932]\n",
      " [-1.16977482  0.70821833]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0067970919327879466, 0.99320290806721201]\n",
      "LOSS PER INSTANCE: 0.006820\n",
      "DERIVATIVE LOSS: -1.006844\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.006820\n",
      "EPOCH 24\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.21266808 -1.51949977  0.        ]\n",
      " [ 0.00447305 -0.30207798  0.        ]\n",
      " [-0.57212735 -0.06882628  0.        ]]\n",
      "[]\n",
      "[[-0.28058584  0.15120009]\n",
      " [-0.61509392  1.05059255]\n",
      " [-1.16977482  0.71828676]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0061677086757398669, 0.9938322913242601]\n",
      "LOSS PER INSTANCE: 0.006187\n",
      "DERIVATIVE LOSS: -1.006206\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.006187\n",
      "EPOCH 25\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.21418946 -1.5300709   0.        ]\n",
      " [ 0.00295167 -0.31264911  0.        ]\n",
      " [-0.57060597 -0.05825516  0.        ]]\n",
      "[]\n",
      "[[-0.28058584  0.15760024]\n",
      " [-0.61509392  1.06822884]\n",
      " [-1.16977482  0.72834882]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0055816704049680534, 0.99441832959503185]\n",
      "LOSS PER INSTANCE: 0.005597\n",
      "DERIVATIVE LOSS: -1.005613\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.005597\n",
      "EPOCH 26\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ -1.21577431e+00  -1.54081315e+00   0.00000000e+00]\n",
      " [  1.36682205e-03  -3.23391354e-01   0.00000000e+00]\n",
      " [ -5.69021120e-01  -4.75129114e-02   0.00000000e+00]]\n",
      "[]\n",
      "[[-0.28058584  0.16404252]\n",
      " [-0.61509392  1.08617365]\n",
      " [-1.16977482  0.73840495]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0050373986218110621, 0.99496260137818904]\n",
      "LOSS PER INSTANCE: 0.005050\n",
      "DERIVATIVE LOSS: -1.005063\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.005050\n",
      "EPOCH 27\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ -1.21742304e+00  -1.55172988e+00   0.00000000e+00]\n",
      " [ -2.81908458e-04  -3.34308083e-01   0.00000000e+00]\n",
      " [ -5.67372389e-01  -3.65961829e-02   0.00000000e+00]]\n",
      "[]\n",
      "[[-0.28058584  0.17052906]\n",
      " [-0.61509392  1.10443254]\n",
      " [-1.16977482  0.74845558]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0045332653964074475, 0.99546673460359258]\n",
      "LOSS PER INSTANCE: 0.004544\n",
      "DERIVATIVE LOSS: -1.004554\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.004544\n",
      "EPOCH 28\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.2191361  -1.5628245   0.        ]\n",
      " [-0.00199496 -0.3454027   0.        ]\n",
      " [-0.56565933 -0.02550156  0.        ]]\n",
      "[]\n",
      "[[-0.28058584  0.177062  ]\n",
      " [-0.61509392  1.12301118]\n",
      " [-1.16977482  0.75850112]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0040676001438988132, 0.99593239985610116]\n",
      "LOSS PER INSTANCE: 0.004076\n",
      "DERIVATIVE LOSS: -1.004084\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.004076\n",
      "EPOCH 29\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.22091395 -1.57410047  0.        ]\n",
      " [-0.00377282 -0.35667868  0.        ]\n",
      " [-0.56388148 -0.01422558  0.        ]]\n",
      "[]\n",
      "[[-0.28058584  0.18364349]\n",
      " [-0.61509392  1.14191534]\n",
      " [-1.16977482  0.76854196]]\n",
      "SOFTMAX_LAYER\n",
      "[0.003638696836859199, 0.99636130316314075]\n",
      "LOSS PER INSTANCE: 0.003645\n",
      "DERIVATIVE LOSS: -1.003652\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.003645\n",
      "EPOCH 30\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.22275709 -1.58556133  0.        ]\n",
      " [-0.00561596 -0.36813954  0.        ]\n",
      " [-0.56203834 -0.00276473  0.        ]]\n",
      "[]\n",
      "[[-0.28058584  0.19027567]\n",
      " [-0.61509392  1.16115086]\n",
      " [-1.16977482  0.77857848]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0032448215892676314, 0.99675517841073236]\n",
      "LOSS PER INSTANCE: 0.003250\n",
      "DERIVATIVE LOSS: -1.003255\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.003250\n",
      "EPOCH 31\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.22466604 -1.59721064  0.        ]\n",
      " [-0.00752491 -0.37978885  0.        ]\n",
      " [-0.56012939  0.00888458  0.        ]]\n",
      "[]\n",
      "[[-0.28058584  0.19696071]\n",
      " [-0.61509392  1.18072374]\n",
      " [-1.16977482  0.78861104]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0028842205402450803, 0.99711577945975494]\n",
      "LOSS PER INSTANCE: 0.002888\n",
      "DERIVATIVE LOSS: -1.002893\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.002888\n",
      "EPOCH 32\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.22664135 -1.60905203  0.        ]\n",
      " [-0.00950021 -0.39163024  0.        ]\n",
      " [-0.55815408  0.02072597  0.        ]]\n",
      "[]\n",
      "[[-0.28058584  0.20370077]\n",
      " [-0.61509392  1.20064002]\n",
      " [-1.16977482  0.79863996]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0025551279593611985, 0.99744487204063881]\n",
      "LOSS PER INSTANCE: 0.002558\n",
      "DERIVATIVE LOSS: -1.002562\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.002558\n",
      "EPOCH 33\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.22868357 -1.62108919  0.        ]\n",
      " [-0.01154244 -0.40366739  0.        ]\n",
      " [-0.55611186  0.03276313  0.        ]]\n",
      "[]\n",
      "[[-0.28058584  0.21049801]\n",
      " [-0.61509392  1.22090588]\n",
      " [-1.16977482  0.80866558]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0022557744897664113, 0.99774422551023367]\n",
      "LOSS PER INSTANCE: 0.002258\n",
      "DERIVATIVE LOSS: -1.002261\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.002258\n",
      "EPOCH 34\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.23079331 -1.63332585  0.        ]\n",
      " [-0.01365218 -0.41590405  0.        ]\n",
      " [-0.55400212  0.04499979  0.        ]]\n",
      "[]\n",
      "[[-0.28058584  0.21735462]\n",
      " [-0.61509392  1.2415276 ]\n",
      " [-1.16977482  0.81868819]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0019843954409036672, 0.99801560455909633]\n",
      "LOSS PER INSTANCE: 0.001986\n",
      "DERIVATIVE LOSS: -1.001988\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.001986\n",
      "EPOCH 35\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.23297118 -1.64576581  0.        ]\n",
      " [-0.01583005 -0.42834402  0.        ]\n",
      " [-0.55182425  0.05743975  0.        ]]\n",
      "[]\n",
      "[[-0.28058584  0.22427278]\n",
      " [-0.61509392  1.26251154]\n",
      " [-1.16977482  0.82870807]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0017392390392775541, 0.99826076096072258]\n",
      "LOSS PER INSTANCE: 0.001741\n",
      "DERIVATIVE LOSS: -1.001742\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.001741\n",
      "EPOCH 36\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.23521782 -1.65841292  0.        ]\n",
      " [-0.01807668 -0.44099113  0.        ]\n",
      " [-0.54957762  0.07008686  0.        ]]\n",
      "[]\n",
      "[[-0.28058584  0.23125469]\n",
      " [-0.61509392  1.28386417]\n",
      " [-1.16977482  0.8387255 ]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0015185745438678771, 0.99848142545613217]\n",
      "LOSS PER INSTANCE: 0.001520\n",
      "DERIVATIVE LOSS: -1.001521\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.001520\n",
      "EPOCH 37\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.23753388 -1.67127109  0.        ]\n",
      " [-0.02039275 -0.4538493   0.        ]\n",
      " [-0.54726155  0.08294503  0.        ]]\n",
      "[]\n",
      "[[-0.28058584  0.23830256]\n",
      " [-0.61509392  1.30559207]\n",
      " [-1.16977482  0.8487407 ]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0013207001324119939, 0.99867929986758797]\n",
      "LOSS PER INSTANCE: 0.001322\n",
      "DERIVATIVE LOSS: -1.001322\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.001322\n",
      "EPOCH 38\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.23992006 -1.68434428  0.        ]\n",
      " [-0.02277892 -0.46692248  0.        ]\n",
      " [-0.54487538  0.09601822  0.        ]]\n",
      "[]\n",
      "[[-0.28058584  0.24541861]\n",
      " [-0.61509392  1.32770193]\n",
      " [-1.16977482  0.85875393]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0011439504660595153, 0.99885604953394047]\n",
      "LOSS PER INSTANCE: 0.001145\n",
      "DERIVATIVE LOSS: -1.001145\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.001145\n",
      "EPOCH 39\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.24237705 -1.6976365   0.        ]\n",
      " [-0.02523592 -0.48021471  0.        ]\n",
      " [-0.54241838  0.10931044  0.        ]]\n",
      "[]\n",
      "[[-0.28058584  0.25260507]\n",
      " [-0.61509392  1.35020051]\n",
      " [-1.16977482  0.86876538]]\n",
      "SOFTMAX_LAYER\n",
      "[0.00098670384290543514, 0.99901329615709455]\n",
      "LOSS PER INSTANCE: 0.000987\n",
      "DERIVATIVE LOSS: -1.000988\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000987\n",
      "EPOCH 40\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.2449056  -1.71115184  0.        ]\n",
      " [-0.02776446 -0.49373005  0.        ]\n",
      " [-0.53988983  0.12282578  0.        ]]\n",
      "[]\n",
      "[[-0.28058584  0.25986418]\n",
      " [-0.61509392  1.37309472]\n",
      " [-1.16977482  0.87877526]]\n",
      "SOFTMAX_LAYER\n",
      "[0.00084738885567457083, 0.99915261114432541]\n",
      "LOSS PER INSTANCE: 0.000848\n",
      "DERIVATIVE LOSS: -1.000848\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000848\n",
      "EPOCH 41\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.24750644 -1.72489443  0.        ]\n",
      " [-0.03036531 -0.50747264  0.        ]\n",
      " [-0.53728899  0.13656838  0.        ]]\n",
      "[]\n",
      "[[-0.28058584  0.2671982 ]\n",
      " [-0.61509392  1.39639154]\n",
      " [-1.16977482  0.88878374]]\n",
      "SOFTMAX_LAYER\n",
      "[0.00072449047535740963, 0.99927550952464261]\n",
      "LOSS PER INSTANCE: 0.000725\n",
      "DERIVATIVE LOSS: -1.000725\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000725\n",
      "EPOCH 42\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.25018036 -1.73886847  0.        ]\n",
      " [-0.03303923 -0.52144668  0.        ]\n",
      " [-0.53461507  0.15054241  0.        ]]\n",
      "[]\n",
      "[[-0.28058584  0.27460939]\n",
      " [-0.61509392  1.42009807]\n",
      " [-1.16977482  0.89879099]]\n",
      "SOFTMAX_LAYER\n",
      "[0.00061655549083112625, 0.99938344450916894]\n",
      "LOSS PER INSTANCE: 0.000617\n",
      "DERIVATIVE LOSS: -1.000617\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000617\n",
      "EPOCH 43\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.25292815 -1.75307821  0.        ]\n",
      " [-0.03578702 -0.53565642  0.        ]\n",
      " [-0.53186728  0.16475216  0.        ]]\n",
      "[]\n",
      "[[-0.28058584  0.28210006]\n",
      " [-0.61509392  1.44422152]\n",
      " [-1.16977482  0.90879716]]\n",
      "SOFTMAX_LAYER\n",
      "[0.00052219724433323384, 0.99947780275566678]\n",
      "LOSS PER INSTANCE: 0.000522\n",
      "DERIVATIVE LOSS: -1.000522\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000522\n",
      "EPOCH 44\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.25575063 -1.76752798  0.        ]\n",
      " [-0.03860949 -0.55010618  0.        ]\n",
      " [-0.52904481  0.17920192  0.        ]]\n",
      "[]\n",
      "[[-0.28058584  0.28967249]\n",
      " [-0.61509392  1.4687692 ]\n",
      " [-1.16977482  0.91880238]]\n",
      "SOFTMAX_LAYER\n",
      "[0.00044009961392823383, 0.99955990038607179]\n",
      "LOSS PER INSTANCE: 0.000440\n",
      "DERIVATIVE LOSS: -1.000440\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000440\n",
      "EPOCH 45\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.25864863 -1.78222213  0.        ]\n",
      " [-0.04150749 -0.56480034  0.        ]\n",
      " [-0.52614681  0.19389608  0.        ]]\n",
      "[]\n",
      "[[-0.28058584  0.29732901]\n",
      " [-0.61509392  1.49374856]\n",
      " [-1.16977482  0.92880679]]\n",
      "SOFTMAX_LAYER\n",
      "[0.00036902020660570684, 0.99963097979339421]\n",
      "LOSS PER INSTANCE: 0.000369\n",
      "DERIVATIVE LOSS: -1.000369\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000369\n",
      "EPOCH 46\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.26162301 -1.79716513  0.        ]\n",
      " [-0.04448188 -0.57974334  0.        ]\n",
      " [-0.52317242  0.20883908  0.        ]]\n",
      "[]\n",
      "[[-0.28058584  0.30507196]\n",
      " [-0.61509392  1.51916712]\n",
      " [-1.16977482  0.93881048]]\n",
      "SOFTMAX_LAYER\n",
      "[0.00030779273910692663, 0.99969220726089314]\n",
      "LOSS PER INSTANCE: 0.000308\n",
      "DERIVATIVE LOSS: -1.000308\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000308\n",
      "EPOCH 47\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.26467467 -1.81236148  0.        ]\n",
      " [-0.04753354 -0.59493969  0.        ]\n",
      " [-0.52012076  0.22403542  0.        ]]\n",
      "[]\n",
      "[[-0.28058584  0.3129037 ]\n",
      " [-0.61509392  1.54503256]\n",
      " [-1.16977482  0.94881356]]\n",
      "SOFTMAX_LAYER\n",
      "[0.00025532859768665584, 0.99974467140231338]\n",
      "LOSS PER INSTANCE: 0.000255\n",
      "DERIVATIVE LOSS: -1.000255\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000255\n",
      "EPOCH 48\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.26780451 -1.82781575  0.        ]\n",
      " [-0.05066338 -0.61039396  0.        ]\n",
      " [-0.51699092  0.2394897   0.        ]]\n",
      "[]\n",
      "[[-0.28058584  0.3208266 ]\n",
      " [-0.61509392  1.57135265]\n",
      " [-1.16977482  0.95881611]]\n",
      "SOFTMAX_LAYER\n",
      "[0.00021061758243067191, 0.99978938241756932]\n",
      "LOSS PER INSTANCE: 0.000211\n",
      "DERIVATIVE LOSS: -1.000211\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000211\n",
      "EPOCH 49\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.27101345 -1.84353259  0.        ]\n",
      " [-0.05387232 -0.6261108   0.        ]\n",
      " [-0.51378198  0.25520653  0.        ]]\n",
      "[]\n",
      "[[-0.28058584  0.32884305]\n",
      " [-0.61509392  1.59813528]\n",
      " [-1.16977482  0.96881822]]\n",
      "SOFTMAX_LAYER\n",
      "[0.00017272785609390721, 0.9998272721439061]\n",
      "LOSS PER INSTANCE: 0.000173\n",
      "DERIVATIVE LOSS: -1.000173\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000173\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nclass Node(Object):\\n    def __init__(self):\\n        \\n    def \\n'"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class NN():\n",
    "    \"\"\"\n",
    "    Class for a neural network. Requires input/output sizes, number of hidden layers, and number of neurons\n",
    "    at each layer (we assume all hidden layers are of the same size)\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, num_HL, hidden_size, output_size):\n",
    "        # Initialize by setting random \n",
    "        self.input_size = input_size\n",
    "        self.hidden_layers = num_HL\n",
    "        # NOTE we are assuming all hidden layers are the same size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        # Activations for each neuron\n",
    "        # + 1 for bias neuron\n",
    "        self.activations_in = np.ones(self.input_size + 1)\n",
    "        # Hidden can comprise multiple layers, so we have a matrix\n",
    "        # + 1 for bias neuron\n",
    "        self.activations_hidden = np.ones((self.hidden_layers, self.hidden_size + 1))\n",
    "        self.activations_out = np.ones(self.output_size)\n",
    "        # Weights of all the edges, randomized for good results\n",
    "        # PLUS ONE FOR BIASES\n",
    "        self.weights_in = np.random.randn(self.input_size + 1, self.hidden_size)\n",
    "        self.weights_in = np.column_stack((self.weights_in, np.zeros(self.input_size + 1)))\n",
    "        # We will only have hidden weights if there are multiple hidden layers\n",
    "        if self.hidden_layers > 1:\n",
    "            self.weights_hidden = np.random.randn(self.hidden_layers - 1, self.hidden_size + 1, self.hidden_size + 1)\n",
    "            # Set the weights corresponding with next layers biases to 0\n",
    "            for weights in self.weights_hidden:\n",
    "                weights[-1] = 0.0\n",
    "        else:\n",
    "            self.weights_hidden = []\n",
    "        # No plus one for output, as it should not have a bias parameter\n",
    "        self.weights_out = np.random.randn(self.hidden_size + 1, self.output_size)\n",
    "        # To be valued when train() is called\n",
    "        self.learning_rate = 0.0\n",
    "\n",
    "        # Instantiate deltas for holding gradients\n",
    "        self.Deltas_hidden = []\n",
    "        self.deltas_out = []\n",
    "    \n",
    "    def _sigmoid(self, x):\n",
    "        \"\"\"\n",
    "        Sigmoid function for calculating a distribution over 2 classes\n",
    "        \"\"\"\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def _derivative_sigmoid(self, x):\n",
    "        \"\"\"\n",
    "        Derivative of the sigmoid function where x = the output of the sigmoid\n",
    "        \n",
    "        This can be used in backpropogation, wherein we would have \n",
    "        already computed the sigmoid in the forward pass, and we can draw upon its cached value\n",
    "        \"\"\"\n",
    "        return self._sigmoid(x) * (1.0 - self._sigmoid(x))\n",
    "    \n",
    "    def _softmax(self, x):\n",
    "        exponentials = [np.exp(p) for p in x]\n",
    "        denominator = sum(exponentials)\n",
    "        return [p / denominator for p in exponentials]\n",
    "    \n",
    "    def _relu(self, x):\n",
    "        \"\"\"\n",
    "        relu function used for activation\n",
    "        \"\"\"\n",
    "        return max(x, 0.0)\n",
    "    \n",
    "    def _derivative_relu(self, x):\n",
    "        \"\"\"\n",
    "        Derivative of the relu function, the input will be the output of the relu function.\n",
    "        This is because in practice we will have already performed this computation in the forward pass\n",
    "        so in the backward pass, we need to find its derivative drawing upon the cached relu(x).\n",
    "        \"\"\"\n",
    "        return 1 if x > 0.0 else 0.0\n",
    "    \n",
    "    def _binary_cross_ent(self, y_hat, y):\n",
    "        \"\"\"\n",
    "        This basically finds the negative of the log probability of class1 - its inverse\n",
    "        \"\"\"\n",
    "        return (-y * np.log(y_hat)) - ((1 - y) * np.log(1 - y_hat))\n",
    "    \n",
    "    def _negative_log_likelihood(self, y_hat):\n",
    "        return -np.log(y_hat)\n",
    "    \n",
    "    def _derivative_negative_log_likelihood(self, y_hat):\n",
    "        return -1/y_hat\n",
    "    \n",
    "    def _derivative_binary_cross_ent(self, y_hat, y):\n",
    "        \"\"\"\n",
    "        Derivative of binary cross-entropy\n",
    "        \n",
    "        This description is misleading. \n",
    "        This is the part of the partial derivative of binary cross-entropy \n",
    "        w.r.t the parameters of our function. In practice, the other part is \n",
    "        the dot product of this and the activations (activate(w, x))\n",
    "        \"\"\"\n",
    "        #return -(y / y_hat) - ((1 - y) / (1 - y_hat))\n",
    "        return (y_hat - y)\n",
    "\n",
    "    def _activate(self, x):\n",
    "        \"\"\"\n",
    "        RELU for non-linear activation function\n",
    "        \"\"\"\n",
    "        return self._relu(x)\n",
    "    \n",
    "    def _activate_vector(self, X):\n",
    "        \"\"\"\n",
    "        Run on a numpy vector\n",
    "        \"\"\"\n",
    "        activations = np.vectorize(self._activate)\n",
    "        return activations(X)\n",
    "    \n",
    "    def _derivative_activation(self, x):\n",
    "        \"\"\"\n",
    "        Compute the derivative of the activation function given the activation output\n",
    "        \n",
    "        x: activate(node)\n",
    "        \"\"\"\n",
    "        return self._derivative_relu(x)\n",
    "    \n",
    "    def _derivative_vector_activation(self, X):\n",
    "        \"\"\"\n",
    "        Derivative for each scalar in a numpy vector\n",
    "        \"\"\"\n",
    "        derivative_activations = np.vectorize(self._derivative_activation)\n",
    "        return derivative_activations(X)\n",
    "\n",
    "    def _loss(self, y_hat, y):\n",
    "        \"\"\"\n",
    "        y_hat: sofmax vector\n",
    "        y:     one-hot vector for the target\n",
    "        \n",
    "        Here we will plug in the negative_log_likelihood\n",
    "        in order to be able to compare the proability of our output at\n",
    "        the correct class, to 1.\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        Get the index of the correct class \n",
    "        (numpy will return a tuple of the index in each dimension)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Get the first (and only) dim, and the first (and only) index\n",
    "        i = np.where(y==1)[0][0]\n",
    "        return self._negative_log_likelihood(y_hat[i])\n",
    "    \n",
    "    def _derivative_loss(self, y_hat, y):\n",
    "        \"\"\"\n",
    "        This will be used in backprop for finding L'(output_layer_node)\n",
    "        \"\"\"\n",
    "        # Get the first (and only) dim, and the first (and only) index\n",
    "        i = np.where(y==1)[0][0]\n",
    "        return self._derivative_negative_log_likelihood(y_hat[i])\n",
    "    \n",
    "    def _targets_to_one_hots(self, targets):\n",
    "        \"\"\"\n",
    "        Interpret a vector of targets into a matrix\n",
    "        of one-hot representations\n",
    "        \"\"\"\n",
    "        # Get the number of unique target classes\n",
    "        num_classes = len(set(targets))\n",
    "        # Instantiate a matrix of one-hot vectors\n",
    "        # with one row per target, and one col per class\n",
    "        one_hots = np.zeros((len(targets), num_classes))\n",
    "        for i, one_hot in enumerate(one_hots):\n",
    "            # Set the one-hot vector to hae a 1 at its corresponding target slot\n",
    "            t = targets[i]\n",
    "            one_hot[t] = 1\n",
    "            \n",
    "        return one_hots\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Forward pass: Calculate the activations of each neuron\n",
    "        \"\"\"\n",
    "        if len(inputs) != self.input_size:\n",
    "          raise Exception(\"That is not the size of the input layer... try %i\" % self.input_size)\n",
    "        \n",
    "        # Set input activations, no need to actually calculate anything\n",
    "        for i, input in enumerate(inputs):\n",
    "            self.activations_in[i] = input\n",
    "        \n",
    "        # calculate the activations for each hidden layer\n",
    "        for h_layer_i in range(self.hidden_layers):\n",
    "            # Need to take previous layer activation value * weights for a given layer\n",
    "            # Starting with input layer X first hidden layer\n",
    "            if h_layer_i == 0:\n",
    "                # multiply the previous layer's activations by its weight vector for this layer's activations\n",
    "                self.activations_hidden[h_layer_i] = self.activations_in.T.dot(self.weights_in)\n",
    "                # Reset bias activation to 1.0\n",
    "                self.activations_hidden[h_layer_i][-1] = 1.0\n",
    "            else:\n",
    "                # multiply the previous layer's activations by its weight vector for this layer's activations\n",
    "                self.activations_hidden[h_layer_i] = self._activate_vector(self.activations_hidden[h_layer_i - 1]).T.dot(self.weights_hidden[h_layer_i - 1])\n",
    "                # Reset bias activation to 1.0\n",
    "                self.activations_hidden[h_layer_i][-1] = 1.0\n",
    "\n",
    "                \n",
    "        # Output activations will be the dot product of the final hidden layer, and the output weights\n",
    "        # Activate the vector before, but do not activate the activations_out\n",
    "        self.activations_out = self._activate_vector(self.activations_hidden[-1]).T.dot(self.weights_out)\n",
    "        \n",
    "        #Print all of the weights, to see updates\n",
    "        \"\"\"\n",
    "        print(\"ACTIVATIONS\")\n",
    "        print(self.activations_in)\n",
    "        print(self.activations_hidden)\n",
    "        print(self.activations_out)\n",
    "        \"\"\"\n",
    "        print(\"WEIGHTS:\")\n",
    "        print(self.weights_in)\n",
    "        print(self.weights_hidden)\n",
    "        print(self.weights_out)\n",
    "\n",
    "    def backward(self, targets):\n",
    "        \"\"\"\n",
    "        Backpropogation for finding the partial derivative of the each node w.r.t the loss function,\n",
    "        and updating weights based on those gradients\n",
    "        \"\"\"\n",
    "        if len(targets) != len(self.activations_out):\n",
    "            raise Exception(\"Your labels are not the same size as your output layer!\")\n",
    "        # Calculate loss - there will be a value for each node in the output layer\n",
    "        # Take the simoid of the activations of the output layer, because we are doing 2 class classification\n",
    "        # ***If we have >2 classes, we would use softmax***\n",
    "        \"\"\"\n",
    "        print(\"ACTIVATIONS IN\")\n",
    "        print(self.activations_in)\n",
    "        \n",
    "        print(\"ACTIVATIONS HIDDEN\")\n",
    "        print(self.activations_hidden)\n",
    "        \n",
    "        print(\"ACTIVATIONS OUT\")\n",
    "        print(self.activations_out)\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"SOFTMAX_LAYER\")\n",
    "        print(self._softmax(self.activations_out))\n",
    "        \"\"\"\n",
    "        print(\"TARGETS\")\n",
    "        print(targets)\n",
    "        \"\"\"\n",
    "        loss = self._loss(self._softmax(self.activations_out), targets)\n",
    "        \n",
    "        \"\"\"\n",
    "        Now we need to calculate the partial derivative of the loss w.r.t each weight.\n",
    "        Think of this as finding the amount that each node contributes to a change in the final loss.\n",
    "        \n",
    "        Each node has a value \"delta\", which represents the partial derivative of the loss w.r.t. its value:\n",
    "        Use the partial derivative of the loss function, in our case binary cross-entropy\n",
    "        \"\"\"\n",
    "        self.deltas_out = np.zeros([self.output_size])\n",
    "        derivative_loss = self._derivative_loss(self._softmax(self.activations_out), targets)\n",
    "        print(\"LOSS PER INSTANCE: %2f\" % loss)\n",
    "        print(\"DERIVATIVE LOSS: %2f\" % derivative_loss)\n",
    "        for i, activation_out in enumerate(self.activations_out):\n",
    "            self.deltas_out[i] = derivative_loss * self._derivative_activation(activation_out)\n",
    "        \n",
    "        \"\"\"\n",
    "        Find derivative of activation (activation was found in the forward pass) * derivative of the inner function,\n",
    "        which is the parameter w\n",
    "        \"\"\"\n",
    "        self.Deltas_hidden = np.zeros([self.hidden_layers, self.hidden_size + 1])\n",
    "        ##############\n",
    "        #####TODO Needs to go in reverse if we have multiple hidden\n",
    "        for h_layer_i in range(self.hidden_layers):\n",
    "            # If it is the last hidden layer, then we look at the activations and deltas\n",
    "            # of the output layer, not the next hidden layer\n",
    "            if h_layer_i == self.hidden_layers - 1:\n",
    "                # Loop over each in hidden activation, +1 for bias\n",
    "                for h_dim_j in range(self.hidden_size + 1):\n",
    "                    for k, delta_out in enumerate(self.deltas_out):\n",
    "                        self.Deltas_hidden[h_layer_i][h_dim_j] += delta_out * self._derivative_activation(self.activations_out[k]) * self.weights_out[h_dim_j][k]\n",
    "            else:\n",
    "                # Do the same to find the hidden deltas\n",
    "                for h_dim_j in range(self.hidden_size + 1):\n",
    "                    for k, delta_h in enumerate(self.Deltas_hidden[h_layer_i + 1]):\n",
    "                        self.Deltas_hidden[h_layer_i][h_dim_j] += delta_h * self._derivative_activation(self.activations_hidden[h_layer_i + 1][k]) * self.weights_hidden[h_layer_i][h_dim_j][k]        \n",
    "        \n",
    "        self.update_weights()\n",
    "        return loss\n",
    "        \n",
    "    def update_weights(self):\n",
    "        print(\"UPDATING WEIGHTS\")\n",
    "        # Now we can use the deltas to adjust each weight by L'(w_i_j)\n",
    "        # These weights are the edges shared between last hidden layer, and output layer\n",
    "        # Rows of weights_out correponds with length of last hidden layer\n",
    "        for i in range(len(self.weights_out)):\n",
    "            # Cols of weights_out correspinds with length of output layer\n",
    "            for j in range(len(self.weights_out[i])):\n",
    "                self.weights_out[i][j] -= self._activate(self.activations_hidden[-1][i])\\\n",
    "                * self._derivative_activation(self.activations_out[j])\\\n",
    "                * self.deltas_out[j]\\\n",
    "                * self.learning_rate\n",
    "                    \n",
    "        # Loop over each hidden layer\n",
    "        for w_i in reversed(range(len(self.weights_hidden))):\n",
    "            # Rows (i) in the weights for this layer will correspond to the size of the layer BEFORE (hidden or input)\n",
    "            for i in range(len(self.weights_hidden[w_i])):\n",
    "                # Cols (j) in these weights will correspond to the size of hidden layer w_i\n",
    "                for j in range(len(self.weights_hidden[w_i][i])):\n",
    "                    # We do not want to update the dummy 0 weight going TO the extra bias dimension\n",
    "                    if j == len(self.weights_hidden[w_i][i]) - 1:\n",
    "                        continue\n",
    "                    else:\n",
    "                        # + 1 for layer before, because we are looping in reverse\n",
    "                        self.weights_hidden[w_i][i][j] -= self._activate(self.activations_hidden[w_i + 1][i])\\\n",
    "                        * self._derivative_activation(self.activations_hidden[w_i][j])\\\n",
    "                        * self.Deltas_hidden[w_i][j]\\\n",
    "                        * self.learning_rate\n",
    "                        \n",
    "        # Rows (i) of weights_in corresponds to size of the input layer\n",
    "        for i in range(len(self.weights_in)):\n",
    "            # Cols (j) corresponds to size of the first hidden layer (layer above input layer)\n",
    "            for j in range(len(self.weights_in[i])):\n",
    "                # We do not want to update the dummy 0 weight going TO the extra bias dimension\n",
    "                if j == len(self.weights_in[i]) - 1:\n",
    "                    continue\n",
    "                else:\n",
    "                    self.weights_in[i][j] -= self.activations_in[i]\\\n",
    "                    * self._derivative_activation(self.activations_hidden[0][j])\\\n",
    "                    * self.Deltas_hidden[0][j]\\\n",
    "                    * self.learning_rate\n",
    "    \n",
    "    def train(self, inputs, targets, epochs=50, lr=.01):\n",
    "        self.learning_rate = lr\n",
    "        one_hot_targets = self._targets_to_one_hots(targets)\n",
    "        for e in range(epochs):\n",
    "            print(\"EPOCH %i\" % e)\n",
    "            \"\"\"\n",
    "            SGD - randomize the order of the training samples, and \n",
    "            \"\"\"\n",
    "            in_out = list(zip(inputs, one_hot_targets))\n",
    "            random.shuffle(in_out)\n",
    "            # For tracking average loss over SGD, just for logging\n",
    "            losses = []\n",
    "            \n",
    "            for inp, target in in_out:\n",
    "                if inp == [-1, -1]:\n",
    "                    print(\"TARGET: \")\n",
    "                    print(target)\n",
    "                    self.forward(inp)\n",
    "                    losses.append(self.backward(target))\n",
    "\n",
    "            print(\"LOSS: %2f\" % (sum(losses)/len(losses)))\n",
    "            \n",
    "\"\"\"\n",
    "Note that the 4th param, the size of the output layer, should be the\n",
    "number of classes\n",
    "\"\"\"\n",
    "MLP = NN(2, 1, 2, 2)\n",
    "xor_inputs = [[1, 1], [-1, 1], [-1, -1], [1, -1]]\n",
    "xor_labels = ([1, 0, 1, 0])\n",
    "MLP.train(xor_inputs, xor_labels)\n",
    "\"\"\"\n",
    "class Node(Object):\n",
    "    def __init__(self):\n",
    "        \n",
    "    def \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.32645138  0.4758586   0.        ]\n",
      " [ 0.64297348 -0.59992355  0.        ]\n",
      " [-0.18379199 -0.93250136  0.        ]]\n",
      "[]\n",
      "[[ 1.13560919  0.83145231]\n",
      " [-0.36422178  0.9998308 ]\n",
      " [ 0.59865681 -0.45240728]]\n",
      "SOFTMAX_LAYER\n",
      "[0.63117451519525447, 0.36882548480474553]\n",
      "LOSS PER INSTANCE: 0.997432\n",
      "DERIVATIVE LOSS: -2.711309\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.997432\n",
      "EPOCH 1\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.34339378  0.46862765  0.        ]\n",
      " [ 0.62603108 -0.60715449  0.        ]\n",
      " [-0.16684959 -0.92527041  0.        ]]\n",
      "[]\n",
      "[[ 1.15459756  0.85947984]\n",
      " [-0.35481818  1.01371086]\n",
      " [ 0.62096068 -0.41948594]]\n",
      "SOFTMAX_LAYER\n",
      "[0.62706307633503766, 0.37293692366496245]\n",
      "LOSS PER INSTANCE: 0.986346\n",
      "DERIVATIVE LOSS: -2.681419\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.986346\n",
      "EPOCH 2\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.35975284  0.46142755  0.        ]\n",
      " [ 0.60967202 -0.6143546   0.        ]\n",
      " [-0.15049052 -0.91807031  0.        ]]\n",
      "[]\n",
      "[[ 1.17295476  0.88686016]\n",
      " [-0.34576285  1.02721717]\n",
      " [ 0.64211967 -0.38792665]]\n",
      "SOFTMAX_LAYER\n",
      "[0.62287118669867003, 0.37712881330132997]\n",
      "LOSS PER INSTANCE: 0.975168\n",
      "DERIVATIVE LOSS: -2.651614\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.975168\n",
      "EPOCH 3\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.37549634  0.45429841  0.        ]\n",
      " [ 0.59392852 -0.62148374  0.        ]\n",
      " [-0.13474702 -0.91094117  0.        ]]\n",
      "[]\n",
      "[[ 1.19068019  0.91350151]\n",
      " [-0.3370443   1.04032115]\n",
      " [ 0.66219259 -0.35775702]]\n",
      "SOFTMAX_LAYER\n",
      "[0.61864225291440744, 0.38135774708559261]\n",
      "LOSS PER INSTANCE: 0.964017\n",
      "DERIVATIVE LOSS: -2.622210\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.964017\n",
      "EPOCH 4\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.39060548  0.44727379  0.        ]\n",
      " [ 0.57881938 -0.62850836  0.        ]\n",
      " [-0.11963789 -0.90391655  0.        ]]\n",
      "[]\n",
      "[[ 1.20778058  0.93933434]\n",
      " [-0.32864949  1.05300284]\n",
      " [ 0.68124106 -0.32898132]]\n",
      "SOFTMAX_LAYER\n",
      "[0.61441492688649679, 0.38558507311350321]\n",
      "LOSS PER INSTANCE: 0.952993\n",
      "DERIVATIVE LOSS: -2.593461\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.952993\n",
      "EPOCH 5\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.40507326  0.44038072  0.        ]\n",
      " [ 0.5643516  -0.63540143  0.        ]\n",
      " [-0.1051701  -0.89702348  0.        ]]\n",
      "[]\n",
      "[[ 1.22426851  0.96431019]\n",
      " [-0.32056435  1.06525018]\n",
      " [ 0.69932755 -0.30158398]]\n",
      "SOFTMAX_LAYER\n",
      "[0.61022248926509948, 0.38977751073490052]\n",
      "LOSS PER INSTANCE: 0.942179\n",
      "DERIVATIVE LOSS: -2.565566\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.942179\n",
      "EPOCH 6\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.4189027   0.43364008  0.        ]\n",
      " [ 0.55052216 -0.64214207  0.        ]\n",
      " [-0.09134067 -0.89028284  0.        ]]\n",
      "[]\n",
      "[[ 1.24016102  0.9883996 ]\n",
      " [-0.31277426  1.07705817]\n",
      " [ 0.7165139  -0.2755334 ]]\n",
      "SOFTMAX_LAYER\n",
      "[0.60609265854071859, 0.39390734145928141]\n",
      "LOSS PER INSTANCE: 0.931640\n",
      "DERIVATIVE LOSS: -2.538668\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.931640\n",
      "EPOCH 7\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.43210479  0.4270672   0.        ]\n",
      " [ 0.53732007 -0.64871495  0.        ]\n",
      " [-0.07813857 -0.88370996  0.        ]]\n",
      "[]\n",
      "[[ 1.25547838  1.0115896 ]\n",
      " [-0.30526442  1.08842782]\n",
      " [ 0.73286018 -0.25078565]]\n",
      "SOFTMAX_LAYER\n",
      "[0.60204773854755833, 0.39795226145244167]\n",
      "LOSS PER INSTANCE: 0.921423\n",
      "DERIVATIVE LOSS: -2.512864\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.921423\n",
      "EPOCH 8\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.44469676  0.42067255  0.        ]\n",
      " [ 0.5247281  -0.6551096   0.        ]\n",
      " [-0.06554661 -0.87731531  0.        ]]\n",
      "[]\n",
      "[[ 1.27024302  1.03388088]\n",
      " [-0.29802018  1.09936501]\n",
      " [ 0.7484239  -0.22728792]]\n",
      "SOFTMAX_LAYER\n",
      "[0.59810500579065062, 0.40189499420934949]\n",
      "LOSS PER INSTANCE: 0.911564\n",
      "DERIVATIVE LOSS: -2.488212\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.911564\n",
      "EPOCH 9\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.45670031  0.41446249  0.        ]\n",
      " [ 0.51272455 -0.66131966  0.        ]\n",
      " [-0.05354306 -0.87110525  0.        ]]\n",
      "[]\n",
      "[[ 1.28447861  1.05528511]\n",
      " [-0.2910272   1.10987945]\n",
      " [ 0.76325945 -0.20498161]]\n",
      "SOFTMAX_LAYER\n",
      "[0.59427724350501987, 0.40572275649498013]\n",
      "LOSS PER INSTANCE: 0.902085\n",
      "DERIVATIVE LOSS: -2.464737\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.902085\n",
      "EPOCH 10\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.46814022  0.40844001  0.        ]\n",
      " [ 0.50128464 -0.66734213  0.        ]\n",
      " [-0.04210315 -0.86508277  0.        ]]\n",
      "[]\n",
      "[[ 1.29820941  1.0758224 ]\n",
      " [-0.28427169  1.11998374]\n",
      " [ 0.77741786 -0.18380474]]\n",
      "SOFTMAX_LAYER\n",
      "[0.59057334474021628, 0.40942665525978372]\n",
      "LOSS PER INSTANCE: 0.892997\n",
      "DERIVATIVE LOSS: -2.442440\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.892997\n",
      "EPOCH 11\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.47904313  0.40260538  0.        ]\n",
      " [ 0.49038173 -0.67317677  0.        ]\n",
      " [-0.03120024 -0.85924814  0.        ]]\n",
      "[]\n",
      "[[ 1.31145971  1.09551909]\n",
      " [-0.27774043  1.12969251]\n",
      " [ 0.79094666 -0.16369407]]\n",
      "SOFTMAX_LAYER\n",
      "[0.58699892593947633, 0.41300107406052361]\n",
      "LOSS PER INSTANCE: 0.884305\n",
      "DERIVATIVE LOSS: -2.421301\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.884305\n",
      "EPOCH 12\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.4894366   0.39695675  0.        ]\n",
      " [ 0.47998826 -0.6788254   0.        ]\n",
      " [-0.02080677 -0.85359951  0.        ]]\n",
      "[]\n",
      "[[ 1.3242534   1.11440587]\n",
      " [-0.27142092  1.13902173]\n",
      " [ 0.80388988 -0.14458656]]\n",
      "SOFTMAX_LAYER\n",
      "[0.58355691119544939, 0.41644308880455067]\n",
      "LOSS PER INSTANCE: 0.876005\n",
      "DERIVATIVE LOSS: -2.401288\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.876005\n",
      "EPOCH 13\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.49934838  0.39149066  0.        ]\n",
      " [ 0.47007648 -0.68429148  0.        ]\n",
      " [-0.01089499 -0.84813343  0.        ]]\n",
      "[]\n",
      "[[ 1.33661373  1.13251622]\n",
      " [-0.26530134  1.14798814]\n",
      " [ 0.81628817 -0.12642057]]\n",
      "SOFTMAX_LAYER\n",
      "[0.58024806326241329, 0.41975193673758665]\n",
      "LOSS PER INSTANCE: 0.868091\n",
      "DERIVATIVE LOSS: -2.382359\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.868091\n",
      "EPOCH 14\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ -1.50880583e+00   3.86202483e-01   0.00000000e+00]\n",
      " [  4.60619031e-01  -6.89579664e-01   0.00000000e+00]\n",
      " [ -1.43754004e-03  -8.42845244e-01   0.00000000e+00]]\n",
      "[]\n",
      "[[ 1.34856305  1.14988519]\n",
      " [-0.2593706   1.15660879]\n",
      " [ 0.82817898 -0.10913666]]\n",
      "SOFTMAX_LAYER\n",
      "[0.57707144961951684, 0.42292855038048316]\n",
      "LOSS PER INSTANCE: 0.860552\n",
      "DERIVATIVE LOSS: -2.364466\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.860552\n",
      "EPOCH 15\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.51783556  0.38108674  0.        ]\n",
      " [ 0.4515893  -0.69469541  0.        ]\n",
      " [ 0.00759219 -0.8377295   0.        ]]\n",
      "[]\n",
      "[[ 1.36012275  1.16654844]\n",
      " [-0.2536183   1.1649007 ]\n",
      " [ 0.83959668 -0.09267809]]\n",
      "SOFTMAX_LAYER\n",
      "[0.57402484048397695, 0.42597515951602316]\n",
      "LOSS PER INSTANCE: 0.853374\n",
      "DERIVATIVE LOSS: -2.347555\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.853374\n",
      "EPOCH 16\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.52646314  0.3761374   0.        ]\n",
      " [ 0.44296172 -0.69964475  0.        ]\n",
      " [ 0.01621977 -0.83278016  0.        ]]\n",
      "[]\n",
      "[[ 1.37131313  1.1825415 ]\n",
      " [-0.24803472  1.17288063]\n",
      " [ 0.85057285 -0.07699118]]\n",
      "SOFTMAX_LAYER\n",
      "[0.57110504121775496, 0.42889495878224509]\n",
      "LOSS PER INSTANCE: 0.846543\n",
      "DERIVATIVE LOSS: -2.331573\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.846543\n",
      "EPOCH 17\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.53471293  0.37134811  0.        ]\n",
      " [ 0.43471193 -0.70443404  0.        ]\n",
      " [ 0.02446956 -0.82799087  0.        ]]\n",
      "[]\n",
      "[[ 1.38215343  1.19789924]\n",
      " [-0.24261081  1.18056482]\n",
      " [ 0.86113645 -0.06202545]]\n",
      "SOFTMAX_LAYER\n",
      "[0.56830816476272583, 0.43169183523727428]\n",
      "LOSS PER INSTANCE: 0.840043\n",
      "DERIVATIVE LOSS: -2.316467\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.840043\n",
      "EPOCH 18\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.54260798  0.36671235  0.        ]\n",
      " [ 0.42681688 -0.7090698   0.        ]\n",
      " [ 0.03236461 -0.82335511  0.        ]]\n",
      "[]\n",
      "[[ 1.39266178  1.2126555 ]\n",
      " [-0.23733812  1.18796896]\n",
      " [ 0.87131404 -0.04773365]]\n",
      "SOFTMAX_LAYER\n",
      "[0.56562985125611087, 0.43437014874388913]\n",
      "LOSS PER INSTANCE: 0.833858\n",
      "DERIVATIVE LOSS: -2.302184\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.833858\n",
      "EPOCH 19\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.55017     0.36222357  0.        ]\n",
      " [ 0.41925486 -0.71355857  0.        ]\n",
      " [ 0.03992664 -0.81886633  0.        ]]\n",
      "[]\n",
      "[[ 1.40285523  1.22684281]\n",
      " [-0.23220877  1.19510802]\n",
      " [ 0.88112999 -0.03407176]]\n",
      "SOFTMAX_LAYER\n",
      "[0.56306544238580014, 0.43693455761419986]\n",
      "LOSS PER INSTANCE: 0.827972\n",
      "DERIVATIVE LOSS: -2.288672\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.827972\n",
      "EPOCH 20\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.55741936  0.35787529  0.        ]\n",
      " [ 0.4120055  -0.71790686  0.        ]\n",
      " [ 0.04717599 -0.81451805  0.        ]]\n",
      "[]\n",
      "[[ 1.41274983  1.24049224]\n",
      " [-0.22721543  1.20199625]\n",
      " [ 0.89060668 -0.02099883]]\n",
      "SOFTMAX_LAYER\n",
      "[0.56061011777524306, 0.439389882224757]\n",
      "LOSS PER INSTANCE: 0.822368\n",
      "DERIVATIVE LOSS: -2.275883\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.822368\n",
      "EPOCH 21\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.56437508  0.35366115  0.        ]\n",
      " [ 0.40504978 -0.72212099  0.        ]\n",
      " [ 0.05413171 -0.81030391  0.        ]]\n",
      "[]\n",
      "[[ 1.42236061  1.25363332]\n",
      " [-0.22235125  1.20864717]\n",
      " [ 0.89976466 -0.00847687]]\n",
      "SOFTMAX_LAYER\n",
      "[0.55825900004639561, 0.44174099995360444]\n",
      "LOSS PER INSTANCE: 0.817032\n",
      "DERIVATIVE LOSS: -2.263770\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.817032\n",
      "EPOCH 22\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.57105492  0.349575    0.        ]\n",
      " [ 0.39836994 -0.72620715  0.        ]\n",
      " [ 0.06081155 -0.80621776  0.        ]]\n",
      "[]\n",
      "[[ 1.43170166  1.26629397]\n",
      " [-0.21760988  1.21507351]\n",
      " [ 0.90862284  0.00352931]]\n",
      "SOFTMAX_LAYER\n",
      "[0.55600723440182187, 0.44399276559817819]\n",
      "LOSS PER INSTANCE: 0.811947\n",
      "DERIVATIVE LOSS: -2.252289\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.811947\n",
      "EPOCH 23\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.57747543  0.34561089  0.        ]\n",
      " [ 0.39194943 -0.73017126  0.        ]\n",
      " [ 0.06723206 -0.80225365  0.        ]]\n",
      "[]\n",
      "[[ 1.44078622  1.27850055]\n",
      " [-0.21298537  1.2212873 ]\n",
      " [ 0.91719862  0.01505227]]\n",
      "SOFTMAX_LAYER\n",
      "[0.55385004772234292, 0.44614995227765708]\n",
      "LOSS PER INSTANCE: 0.807100\n",
      "DERIVATIVE LOSS: -2.241399\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.807100\n",
      "EPOCH 24\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.583652    0.34176313  0.        ]\n",
      " [ 0.38577286 -0.73401902  0.        ]\n",
      " [ 0.07340863 -0.79840589  0.        ]]\n",
      "[]\n",
      "[[ 1.44962665  1.29027784]\n",
      " [-0.20847217  1.22729981]\n",
      " [ 0.92550804  0.02612214]]\n",
      "SOFTMAX_LAYER\n",
      "[0.55178279136963759, 0.44821720863036241]\n",
      "LOSS PER INSTANCE: 0.802477\n",
      "DERIVATIVE LOSS: -2.231061\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.802477\n",
      "EPOCH 25\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.58959894  0.33802627  0.        ]\n",
      " [ 0.37982592 -0.73775588  0.        ]\n",
      " [ 0.07935557 -0.79466903  0.        ]]\n",
      "[]\n",
      "[[ 1.45823457  1.30164912]\n",
      " [-0.20406511  1.23312166]\n",
      " [ 0.93356591  0.03676678]]\n",
      "SOFTMAX_LAYER\n",
      "[0.5498009711528643, 0.45019902884713575]\n",
      "LOSS PER INSTANCE: 0.798066\n",
      "DERIVATIVE LOSS: -2.221240\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.798066\n",
      "EPOCH 26\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.59532954  0.33439513  0.        ]\n",
      " [ 0.37409532 -0.74138702  0.        ]\n",
      " [ 0.08508617 -0.79103789  0.        ]]\n",
      "[]\n",
      "[[ 1.46662086  1.31263623]\n",
      " [-0.19975934  1.23876276]\n",
      " [ 0.94138589  0.04701196]]\n",
      "SOFTMAX_LAYER\n",
      "[0.54790026728062846, 0.45209973271937148]\n",
      "LOSS PER INSTANCE: 0.793852\n",
      "DERIVATIVE LOSS: -2.211901\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.793852\n",
      "EPOCH 27\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.60085617  0.33086478  0.        ]\n",
      " [ 0.36856869 -0.74491736  0.        ]\n",
      " [ 0.0906128  -0.78750754  0.        ]]\n",
      "[]\n",
      "[[ 1.47479571  1.32325962]\n",
      " [-0.19555033  1.24423245]\n",
      " [ 0.94898066  0.05688151]]\n",
      "SOFTMAX_LAYER\n",
      "[0.54607654657656091, 0.45392345342343909]\n",
      "LOSS PER INSTANCE: 0.789827\n",
      "DERIVATIVE LOSS: -2.203015\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.789827\n",
      "EPOCH 28\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.60619032  0.32743057  0.        ]\n",
      " [ 0.36323454 -0.74835158  0.        ]\n",
      " [ 0.09594695 -0.78407333  0.        ]]\n",
      "[]\n",
      "[[ 1.4827687   1.33353846]\n",
      " [-0.19143385  1.24953946]\n",
      " [ 0.95636192  0.0663975 ]]\n",
      "SOFTMAX_LAYER\n",
      "[0.54432586878281541, 0.45567413121718464]\n",
      "LOSS PER INSTANCE: 0.785977\n",
      "DERIVATIVE LOSS: -2.194551\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.785977\n",
      "EPOCH 29\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.61134266  0.32408806  0.        ]\n",
      " [ 0.3580822  -0.75169409  0.        ]\n",
      " [ 0.10109929 -0.78073082  0.        ]]\n",
      "[]\n",
      "[[ 1.4905488   1.34349068]\n",
      " [-0.18740591  1.25469195]\n",
      " [ 0.96354057  0.07558036]]\n",
      "SOFTMAX_LAYER\n",
      "[0.54264448840160151, 0.45735551159839855]\n",
      "LOSS PER INSTANCE: 0.782294\n",
      "DERIVATIVE LOSS: -2.186483\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.782294\n",
      "EPOCH 30\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.61632312  0.32083307  0.        ]\n",
      " [ 0.35310174 -0.75494908  0.        ]\n",
      " [ 0.10607975 -0.77747583  0.        ]]\n",
      "[]\n",
      "[[ 1.49814447  1.35313309]\n",
      " [-0.18346279  1.2596976 ]\n",
      " [ 0.97052672  0.08444899]]\n",
      "SOFTMAX_LAYER\n",
      "[0.54102885321976824, 0.45897114678023176]\n",
      "LOSS PER INSTANCE: 0.778768\n",
      "DERIVATIVE LOSS: -2.178786\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.778768\n",
      "EPOCH 31\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.62114096  0.31766166  0.        ]\n",
      " [ 0.3482839  -0.75812049  0.        ]\n",
      " [ 0.11089759 -0.77430442  0.        ]]\n",
      "[]\n",
      "[[ 1.50556362  1.36248138]\n",
      " [-0.17960097  1.26456357]\n",
      " [ 0.97732975  0.09302096]]\n",
      "SOFTMAX_LAYER\n",
      "[0.53947560041483777, 0.46052439958516228]\n",
      "LOSS PER INSTANCE: 0.775389\n",
      "DERIVATIVE LOSS: -2.171438\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.775389\n",
      "EPOCH 32\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.62580476  0.31457009  0.        ]\n",
      " [ 0.3436201  -0.76121206  0.        ]\n",
      " [ 0.11556139 -0.77121285  0.        ]]\n",
      "[]\n",
      "[[ 1.51281373  1.37155028]\n",
      " [-0.17581716  1.26929661]\n",
      " [ 0.98395844  0.10131255]]\n",
      "SOFTMAX_LAYER\n",
      "[0.53798155094295352, 0.46201844905704653]\n",
      "LOSS PER INSTANCE: 0.772150\n",
      "DERIVATIVE LOSS: -2.164416\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.772150\n",
      "EPOCH 33\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.63032256  0.31155483  0.        ]\n",
      " [ 0.3391023  -0.76422731  0.        ]\n",
      " [ 0.12007919 -0.76819759  0.        ]]\n",
      "[]\n",
      "[[ 1.51990182  1.38035357]\n",
      " [-0.17210826  1.273903  ]\n",
      " [ 0.99042095  0.10933888]]\n",
      "SOFTMAX_LAYER\n",
      "[0.53654370275127872, 0.46345629724872139]\n",
      "LOSS PER INSTANCE: 0.769043\n",
      "DERIVATIVE LOSS: -2.157701\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.769043\n",
      "EPOCH 34\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.63470182  0.30861256  0.        ]\n",
      " [ 0.33472304 -0.76716958  0.        ]\n",
      " [ 0.12445845 -0.76525533  0.        ]]\n",
      "[]\n",
      "[[ 1.52683451  1.38890417]\n",
      " [-0.16847134  1.27838868]\n",
      " [ 0.99672491  0.11711402]]\n",
      "SOFTMAX_LAYER\n",
      "[0.53515922323201059, 0.46484077676798952]\n",
      "LOSS PER INSTANCE: 0.766060\n",
      "DERIVATIVE LOSS: -2.151274\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.766060\n",
      "EPOCH 35\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.63894952  0.30574014  0.        ]\n",
      " [ 0.33047534 -0.77004201  0.        ]\n",
      " [ 0.12870616 -0.7623829   0.        ]]\n",
      "[]\n",
      "[[ 1.53361804  1.39721416]\n",
      " [-0.16490364  1.2827592 ]\n",
      " [ 1.00287746  0.12465105]]\n",
      "SOFTMAX_LAYER\n",
      "[0.53382544123611053, 0.46617455876388947]\n",
      "LOSS PER INSTANCE: 0.763195\n",
      "DERIVATIVE LOSS: -2.145119\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.763195\n",
      "EPOCH 36\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.64307219  0.30293459  0.        ]\n",
      " [ 0.32635267 -0.77284755  0.        ]\n",
      " [ 0.13282882 -0.75957735  0.        ]]\n",
      "[]\n",
      "[[ 1.54025831  1.4052949 ]\n",
      " [-0.16140256  1.28701976]\n",
      " [ 1.00888528  0.13196215]]\n",
      "SOFTMAX_LAYER\n",
      "[0.53253983888689893, 0.46746016111310101]\n",
      "LOSS PER INSTANCE: 0.760441\n",
      "DERIVATIVE LOSS: -2.139220\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.760441\n",
      "EPOCH 37\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.64707589  0.30019312  0.        ]\n",
      " [ 0.32234897 -0.77558903  0.        ]\n",
      " [ 0.13683253 -0.75683588  0.        ]]\n",
      "[]\n",
      "[[ 1.54676088  1.41315705]\n",
      " [-0.15796565  1.29117528]\n",
      " [ 1.01475463  0.13905869]]\n",
      "SOFTMAX_LAYER\n",
      "[0.53130004337257353, 0.46869995662742647]\n",
      "LOSS PER INSTANCE: 0.757792\n",
      "DERIVATIVE LOSS: -2.133561\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.757792\n",
      "EPOCH 38\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.65096635  0.29751307  0.        ]\n",
      " [ 0.31845851 -0.77826908  0.        ]\n",
      " [ 0.14072298 -0.75415583  0.        ]]\n",
      "[]\n",
      "[[ 1.553131    1.42081061]\n",
      " [-0.15459057  1.29523037]\n",
      " [ 1.02049139  0.14595127]]\n",
      "SOFTMAX_LAYER\n",
      "[0.53010381884905089, 0.46989618115094911]\n",
      "LOSS PER INSTANCE: 0.755243\n",
      "DERIVATIVE LOSS: -2.128130\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.755243\n",
      "EPOCH 39\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.65474888  0.29489193  0.        ]\n",
      " [ 0.31467598 -0.78089021  0.        ]\n",
      " [ 0.14450551 -0.7515347   0.        ]]\n",
      "[]\n",
      "[[ 1.55937366  1.42826497]\n",
      " [-0.15127511  1.29918935]\n",
      " [ 1.02610108  0.15264979]]\n",
      "SOFTMAX_LAYER\n",
      "[0.52894905854750529, 0.47105094145249471]\n",
      "LOSS PER INSTANCE: 0.752789\n",
      "DERIVATIVE LOSS: -2.122913\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.752789\n",
      "EPOCH 40\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.65842849  0.29232735  0.        ]\n",
      " [ 0.31099637 -0.78345479  0.        ]\n",
      " [ 0.14818512 -0.74897012  0.        ]]\n",
      "[]\n",
      "[[ 1.56549356  1.43552896]\n",
      " [-0.1480172   1.30305632]\n",
      " [ 1.03158889  0.15916352]]\n",
      "SOFTMAX_LAYER\n",
      "[0.52783377715235713, 0.47216622284764287]\n",
      "LOSS PER INSTANCE: 0.750424\n",
      "DERIVATIVE LOSS: -2.117898\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.750424\n",
      "EPOCH 41\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.66200988  0.28981709  0.        ]\n",
      " [ 0.30741498 -0.78596506  0.        ]\n",
      " [ 0.15176651 -0.74645985  0.        ]]\n",
      "[]\n",
      "[[ 1.57149517  1.44261091]\n",
      " [-0.14481484  1.30683513]\n",
      " [ 1.03695971  0.16550114]]\n",
      "SOFTMAX_LAYER\n",
      "[0.52675610349348501, 0.47324389650651499]\n",
      "LOSS PER INSTANCE: 0.748144\n",
      "DERIVATIVE LOSS: -2.113075\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.748144\n",
      "EPOCH 42\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.66549743  0.28735901  0.        ]\n",
      " [ 0.30392743 -0.78842313  0.        ]\n",
      " [ 0.15525406 -0.74400178  0.        ]]\n",
      "[]\n",
      "[[ 1.57738273  1.44951865]\n",
      " [-0.14166616  1.31052939]\n",
      " [ 1.04221815  0.17167075]]\n",
      "SOFTMAX_LAYER\n",
      "[0.52571427357965006, 0.47428572642034988]\n",
      "LOSS PER INSTANCE: 0.745945\n",
      "DERIVATIVE LOSS: -2.108434\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.745945\n",
      "EPOCH 43\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.6688953   0.28495113  0.        ]\n",
      " [ 0.30052956 -0.79083102  0.        ]\n",
      " [ 0.15865193 -0.74159389  0.        ]]\n",
      "[]\n",
      "[[ 1.58316025  1.45625954]\n",
      " [-0.13856938  1.31414256]\n",
      " [ 1.04736857  0.17767998]]\n",
      "SOFTMAX_LAYER\n",
      "[0.52470662398742884, 0.47529337601257116]\n",
      "LOSS PER INSTANCE: 0.743823\n",
      "DERIVATIVE LOSS: -2.103964\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.743823\n",
      "EPOCH 44\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.67220736  0.28259152  0.        ]\n",
      " [ 0.2972175  -0.79319062  0.        ]\n",
      " [ 0.161964   -0.73923428  0.        ]]\n",
      "[]\n",
      "[[ 1.58883154  1.46284056]\n",
      " [-0.13552279  1.31767784]\n",
      " [ 1.05241506  0.18353597]]\n",
      "SOFTMAX_LAYER\n",
      "[0.52373158561045063, 0.47626841438954942]\n",
      "LOSS PER INSTANCE: 0.741774\n",
      "DERIVATIVE LOSS: -2.099656\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.741774\n",
      "EPOCH 45\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.6754373   0.2802784   0.        ]\n",
      " [ 0.29398756 -0.79550375  0.        ]\n",
      " [ 0.16519393 -0.73692116  0.        ]]\n",
      "[]\n",
      "[[ 1.59440024  1.46926826]\n",
      " [-0.13252478  1.32113831]\n",
      " [ 1.05736152  0.18924545]]\n",
      "SOFTMAX_LAYER\n",
      "[0.52278767776671453, 0.47721232223328547]\n",
      "LOSS PER INSTANCE: 0.739794\n",
      "DERIVATIVE LOSS: -2.095503\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.739794\n",
      "EPOCH 46\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.67858855  0.27801005  0.        ]\n",
      " [ 0.29083631 -0.7977721   0.        ]\n",
      " [ 0.16834518 -0.73465281  0.        ]]\n",
      "[]\n",
      "[[ 1.59986979  1.47554884]\n",
      " [-0.12957381  1.32452686]\n",
      " [ 1.06221162  0.19481474]]\n",
      "SOFTMAX_LAYER\n",
      "[0.52187350265667998, 0.47812649734331997]\n",
      "LOSS PER INSTANCE: 0.737880\n",
      "DERIVATIVE LOSS: -2.091497\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.737880\n",
      "EPOCH 47\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.68166436  0.27578484  0.        ]\n",
      " [ 0.2877605  -0.79999731  0.        ]\n",
      " [ 0.171421   -0.7324276   0.        ]]\n",
      "[]\n",
      "[[ 1.60524347  1.48168817]\n",
      " [-0.1266684   1.32784623]\n",
      " [ 1.06696885  0.20024977]]\n",
      "SOFTMAX_LAYER\n",
      "[0.52098774016123117, 0.47901225983876888]\n",
      "LOSS PER INSTANCE: 0.736029\n",
      "DERIVATIVE LOSS: -2.087629\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.736029\n",
      "EPOCH 48\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.68466782  0.27360124  0.        ]\n",
      " [ 0.28475704 -0.80218091  0.        ]\n",
      " [ 0.17442446 -0.730244    0.        ]]\n",
      "[]\n",
      "[[ 1.61052442  1.48769179]\n",
      " [-0.12380717  1.331099  ]\n",
      " [ 1.07163649  0.20555615]]\n",
      "SOFTMAX_LAYER\n",
      "[0.52012914296617041, 0.47987085703382959]\n",
      "LOSS PER INSTANCE: 0.734238\n",
      "DERIVATIVE LOSS: -2.083894\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.734238\n",
      "EPOCH 49\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.68760182  0.27145778  0.        ]\n",
      " [ 0.28182304 -0.80432437  0.        ]\n",
      " [ 0.17735846 -0.72810054  0.        ]]\n",
      "[]\n",
      "[[ 1.61571562  1.49356494]\n",
      " [-0.12098878  1.33428764]\n",
      " [ 1.07621769  0.21073917]]\n",
      "SOFTMAX_LAYER\n",
      "[0.51929653199833148, 0.48070346800166847]\n",
      "LOSS PER INSTANCE: 0.732505\n",
      "DERIVATIVE LOSS: -2.080285\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.732505\n",
      "EPOCH 50\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.69046911  0.26935307  0.        ]\n",
      " [ 0.27895575 -0.80642908  0.        ]\n",
      " [ 0.18022574 -0.72599583  0.        ]]\n",
      "[]\n",
      "[[ 1.6208199   1.49931259]\n",
      " [-0.11821194  1.33741448]\n",
      " [ 1.08071541  0.21580381]]\n",
      "SOFTMAX_LAYER\n",
      "[0.5184887921575021, 0.4815112078424979]\n",
      "LOSS PER INSTANCE: 0.730826\n",
      "DERIVATIVE LOSS: -2.076795\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.730826\n",
      "EPOCH 51\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.69327227  0.26728577  0.        ]\n",
      " [ 0.27615259 -0.80849637  0.        ]\n",
      " [ 0.1830289  -0.72392854  0.        ]]\n",
      "[]\n",
      "[[ 1.62583999  1.50493945]\n",
      " [-0.11547545  1.34048174]\n",
      " [ 1.08513249  0.22075477]]\n",
      "SOFTMAX_LAYER\n",
      "[0.51770486832794915, 0.48229513167205074]\n",
      "LOSS PER INSTANCE: 0.729199\n",
      "DERIVATIVE LOSS: -2.073419\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.729199\n",
      "EPOCH 52\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.69601376  0.26525464  0.        ]\n",
      " [ 0.2734111  -0.8105275   0.        ]\n",
      " [ 0.18577039 -0.72189741  0.        ]]\n",
      "[]\n",
      "[[ 1.63077846  1.51044998]\n",
      " [-0.11277812  1.34349151]\n",
      " [ 1.08947161  0.22559652]]\n",
      "SOFTMAX_LAYER\n",
      "[0.51694376165331135, 0.4830562383466887]\n",
      "LOSS PER INSTANCE: 0.727622\n",
      "DERIVATIVE LOSS: -2.070152\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.727622\n",
      "EPOCH 53\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.6986959   0.26325847  0.        ]\n",
      " [ 0.27072896 -0.81252367  0.        ]\n",
      " [ 0.18845254 -0.71990123  0.        ]]\n",
      "[]\n",
      "[[ 1.63563781  1.51584843]\n",
      " [-0.11011886  1.34644579]\n",
      " [ 1.09373533  0.23033326]]\n",
      "SOFTMAX_LAYER\n",
      "[0.51620452605886757, 0.48379547394113237]\n",
      "LOSS PER INSTANCE: 0.726093\n",
      "DERIVATIVE LOSS: -2.066989\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.726093\n",
      "EPOCH 54\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.70132091  0.26129612  0.        ]\n",
      " [ 0.26810395 -0.81448603  0.        ]\n",
      " [ 0.19107755 -0.71793888  0.        ]]\n",
      "[]\n",
      "[[ 1.6404204   1.52113882]\n",
      " [-0.10749658  1.3493465 ]\n",
      " [ 1.09792609  0.23496898]]\n",
      "SOFTMAX_LAYER\n",
      "[0.51548626500563721, 0.48451373499436279]\n",
      "LOSS PER INSTANCE: 0.724609\n",
      "DERIVATIVE LOSS: -2.063925\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.724609\n",
      "EPOCH 55\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.70389088  0.25936648  0.        ]\n",
      " [ 0.26553398 -0.81641567  0.        ]\n",
      " [ 0.19364751 -0.71600924  0.        ]]\n",
      "[]\n",
      "[[ 1.64512849  1.52632498]\n",
      " [-0.10491027  1.35219542]\n",
      " [ 1.10204621  0.23950746]]\n",
      "SOFTMAX_LAYER\n",
      "[0.51478812846132627, 0.48521187153867373]\n",
      "LOSS PER INSTANCE: 0.723170\n",
      "DERIVATIVE LOSS: -2.060955\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.723170\n",
      "EPOCH 56\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.70640778  0.25746852  0.        ]\n",
      " [ 0.26301708 -0.81831362  0.        ]\n",
      " [ 0.19616442 -0.71411128  0.        ]]\n",
      "[]\n",
      "[[ 1.64976426  1.53141054]\n",
      " [-0.10235894  1.3549943 ]\n",
      " [ 1.1060979   0.24395228]]\n",
      "SOFTMAX_LAYER\n",
      "[0.51410931007381477, 0.48589068992618528]\n",
      "LOSS PER INSTANCE: 0.721772\n",
      "DERIVATIVE LOSS: -2.058076\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.721772\n",
      "EPOCH 57\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.70887352  0.25560125  0.        ]\n",
      " [ 0.26055134 -0.8201809   0.        ]\n",
      " [ 0.19863015 -0.71224401  0.        ]]\n",
      "[]\n",
      "[[ 1.65432978  1.53639897]\n",
      " [-0.09984165  1.35774478]\n",
      " [ 1.11008329  0.24830685]]\n",
      "SOFTMAX_LAYER\n",
      "[0.51344904453357965, 0.48655095546642024]\n",
      "LOSS PER INSTANCE: 0.720414\n",
      "DERIVATIVE LOSS: -2.055283\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.720414\n",
      "EPOCH 58\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.71128988  0.25376371  0.        ]\n",
      " [ 0.25813498 -0.82201843  0.        ]\n",
      " [ 0.20104651 -0.71040648  0.        ]]\n",
      "[]\n",
      "[[ 1.65882704  1.54129357]\n",
      " [-0.09735749  1.36044841]\n",
      " [ 1.1140044   0.25257438]]\n",
      "SOFTMAX_LAYER\n",
      "[0.51280660511220055, 0.48719339488779928]\n",
      "LOSS PER INSTANCE: 0.719094\n",
      "DERIVATIVE LOSS: -2.052573\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.719094\n",
      "EPOCH 59\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.71365857  0.251955    0.        ]\n",
      " [ 0.25576629 -0.82382714  0.        ]\n",
      " [ 0.20341521 -0.70859776  0.        ]]\n",
      "[]\n",
      "[[ 1.66325796  1.54609748]\n",
      " [-0.0949056   1.36310669]\n",
      " [ 1.11786315  0.25675796]]\n",
      "SOFTMAX_LAYER\n",
      "[0.51218130136484097, 0.4878186986351592]\n",
      "LOSS PER INSTANCE: 0.717811\n",
      "DERIVATIVE LOSS: -2.049942\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.717811\n",
      "EPOCH 60\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.71598123  0.25017425  0.        ]\n",
      " [ 0.25344363 -0.8256079   0.        ]\n",
      " [ 0.20573786 -0.70681701  0.        ]]\n",
      "[]\n",
      "[[ 1.66762437  1.55081369]\n",
      " [-0.09248515  1.36572106]\n",
      " [ 1.1216614   0.2608605 ]]\n",
      "SOFTMAX_LAYER\n",
      "[0.51157247698534192, 0.48842752301465814]\n",
      "LOSS PER INSTANCE: 0.716564\n",
      "DERIVATIVE LOSS: -2.047387\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.716564\n",
      "EPOCH 61\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.71825938  0.24842062  0.        ]\n",
      " [ 0.25116548 -0.82736153  0.        ]\n",
      " [ 0.20801602 -0.70506338  0.        ]]\n",
      "[]\n",
      "[[ 1.67192802  1.55544506]\n",
      " [-0.09009532  1.36829287]\n",
      " [ 1.12540091  0.26488477]]\n",
      "SOFTMAX_LAYER\n",
      "[0.5109795078032926, 0.4890204921967074]\n",
      "LOSS PER INSTANCE: 0.715351\n",
      "DERIVATIVE LOSS: -2.044904\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.715351\n",
      "EPOCH 62\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.72049453  0.24669332  0.        ]\n",
      " [ 0.24893033 -0.82908883  0.        ]\n",
      " [ 0.21025116 -0.70333608  0.        ]]\n",
      "[]\n",
      "[[ 1.67617061  1.55999432]\n",
      " [-0.08773535  1.37082343]\n",
      " [ 1.12908338  0.26883342]]\n",
      "SOFTMAX_LAYER\n",
      "[0.51040179991313983, 0.48959820008686017]\n",
      "LOSS PER INSTANCE: 0.714170\n",
      "DERIVATIVE LOSS: -2.042491\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.714170\n",
      "EPOCH 63\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.72268807  0.24499159  0.        ]\n",
      " [ 0.24673679 -0.83079056  0.        ]\n",
      " [ 0.2124447  -0.70163435  0.        ]]\n",
      "[]\n",
      "[[ 1.68035376  1.56446408]\n",
      " [-0.08540449  1.37331399]\n",
      " [ 1.13271043  0.27270898]]\n",
      "SOFTMAX_LAYER\n",
      "[0.50983878792606996, 0.49016121207393015]\n",
      "LOSS PER INSTANCE: 0.713021\n",
      "DERIVATIVE LOSS: -2.040145\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.713021\n",
      "EPOCH 64\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.72484134  0.24331469  0.        ]\n",
      " [ 0.24458352 -0.83246746  0.        ]\n",
      " [ 0.21459797 -0.69995745  0.        ]]\n",
      "[]\n",
      "[[ 1.68447903  1.56885682]\n",
      " [-0.08310203  1.37576573]\n",
      " [ 1.13628361  0.27651384]]\n",
      "SOFTMAX_LAYER\n",
      "[0.50928993333604022, 0.49071006666395989]\n",
      "LOSS PER INSTANCE: 0.711902\n",
      "DERIVATIVE LOSS: -2.037863\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.711902\n",
      "EPOCH 65\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.72695564  0.24166193  0.        ]\n",
      " [ 0.24246922 -0.83412021  0.        ]\n",
      " [ 0.21671227 -0.69830469  0.        ]]\n",
      "[]\n",
      "[[ 1.68854793  1.57317493]\n",
      " [-0.08082728  1.37817981]\n",
      " [ 1.13980443  0.28025029]]\n",
      "SOFTMAX_LAYER\n",
      "[0.50875472299193114, 0.4912452770080688]\n",
      "LOSS PER INSTANCE: 0.710812\n",
      "DERIVATIVE LOSS: -2.035643\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.710812\n",
      "EPOCH 66\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.72903218  0.24003264  0.        ]\n",
      " [ 0.24039268 -0.83574951  0.        ]\n",
      " [ 0.21878881 -0.6966754   0.        ]]\n",
      "[]\n",
      "[[ 1.69256189  1.57742068]\n",
      " [-0.07857957  1.38055731]\n",
      " [ 1.1432743   0.28392054]]\n",
      "SOFTMAX_LAYER\n",
      "[0.50823266766836994, 0.49176733233163017]\n",
      "LOSS PER INSTANCE: 0.709750\n",
      "DERIVATIVE LOSS: -2.033482\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.709750\n",
      "EPOCH 67\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.73107215  0.23842617  0.        ]\n",
      " [ 0.23835271 -0.83735598  0.        ]\n",
      " [ 0.22082878 -0.69506893  0.        ]]\n",
      "[]\n",
      "[[ 1.69652231  1.58159625]\n",
      " [-0.07635827  1.38289928]\n",
      " [ 1.14669461  0.28752665]]\n",
      "SOFTMAX_LAYER\n",
      "[0.50772330072829952, 0.49227669927170048]\n",
      "LOSS PER INSTANCE: 0.708714\n",
      "DERIVATIVE LOSS: -2.031378\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.708714\n",
      "EPOCH 68\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.73307666  0.23684189  0.        ]\n",
      " [ 0.2363482  -0.83894025  0.        ]\n",
      " [ 0.22283329 -0.69348465  0.        ]]\n",
      "[]\n",
      "[[ 1.70043054  1.58570373]\n",
      " [-0.07416276  1.38520673]\n",
      " [ 1.15006668  0.29107065]]\n",
      "SOFTMAX_LAYER\n",
      "[0.50722617687087335, 0.49277382312912682]\n",
      "LOSS PER INSTANCE: 0.707705\n",
      "DERIVATIVE LOSS: -2.029329\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.707705\n",
      "EPOCH 69\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.73504679  0.23527922  0.        ]\n",
      " [ 0.23437807 -0.84050292  0.        ]\n",
      " [ 0.22480342 -0.69192199  0.        ]]\n",
      "[]\n",
      "[[ 1.70428786  1.58974513]\n",
      " [-0.07199243  1.38748063]\n",
      " [ 1.15339178  0.29455443]]\n",
      "SOFTMAX_LAYER\n",
      "[0.50674087095872122, 0.49325912904127878]\n",
      "LOSS PER INSTANCE: 0.706721\n",
      "DERIVATIVE LOSS: -2.027332\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.706721\n",
      "EPOCH 70\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.73698357  0.23373759  0.        ]\n",
      " [ 0.23244129 -0.84204456  0.        ]\n",
      " [ 0.2267402  -0.69038035  0.        ]]\n",
      "[]\n",
      "[[ 1.70809552  1.59372235]\n",
      " [-0.06984672  1.3897219 ]\n",
      " [ 1.15667114  0.29797982]]\n",
      "SOFTMAX_LAYER\n",
      "[0.50626697691905775, 0.49373302308094225]\n",
      "LOSS PER INSTANCE: 0.705760\n",
      "DERIVATIVE LOSS: -2.025386\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.705760\n",
      "EPOCH 71\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.73888798  0.23221644  0.        ]\n",
      " [ 0.23053688 -0.84356571  0.        ]\n",
      " [ 0.22864461 -0.6888592   0.        ]]\n",
      "[]\n",
      "[[ 1.71185471  1.59763725]\n",
      " [-0.06772506  1.39193143]\n",
      " [ 1.15990591  0.30134857]]\n",
      "SOFTMAX_LAYER\n",
      "[0.50580410671352305, 0.49419589328647689]\n",
      "LOSS PER INSTANCE: 0.704823\n",
      "DERIVATIVE LOSS: -2.023489\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.704823\n",
      "EPOCH 72\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.74076097  0.23071524  0.        ]\n",
      " [ 0.22866389 -0.8450669   0.        ]\n",
      " [ 0.2305176  -0.68735801  0.        ]]\n",
      "[]\n",
      "[[ 1.7155666   1.60149157]\n",
      " [-0.06562693  1.39411007]\n",
      " [ 1.16309725  0.30466237]]\n",
      "SOFTMAX_LAYER\n",
      "[0.50535188937200126, 0.49464811062799868]\n",
      "LOSS PER INSTANCE: 0.703909\n",
      "DERIVATIVE LOSS: -2.021639\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.703909\n",
      "EPOCH 73\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.74260344  0.22923349  0.        ]\n",
      " [ 0.22682142 -0.84654865  0.        ]\n",
      " [ 0.23236007 -0.68587625  0.        ]]\n",
      "[]\n",
      "[[ 1.71923231  1.60528703]\n",
      " [-0.06355179  1.39625866]\n",
      " [ 1.16624624  0.30792282]]\n",
      "SOFTMAX_LAYER\n",
      "[0.50490997008602845, 0.49509002991397161]\n",
      "LOSS PER INSTANCE: 0.703016\n",
      "DERIVATIVE LOSS: -2.019835\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.703016\n",
      "EPOCH 74\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.74441627  0.2277707   0.        ]\n",
      " [ 0.22500859 -0.84801145  0.        ]\n",
      " [ 0.2341729  -0.68441346  0.        ]]\n",
      "[]\n",
      "[[ 1.72285291  1.60902524]\n",
      " [-0.06149916  1.39837797]\n",
      " [ 1.16935392  0.31113145]]\n",
      "SOFTMAX_LAYER\n",
      "[0.50447800935770881, 0.49552199064229113]\n",
      "LOSS PER INSTANCE: 0.702144\n",
      "DERIVATIVE LOSS: -2.018074\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.702144\n",
      "EPOCH 75\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.74620028  0.22632639  0.        ]\n",
      " [ 0.22322458 -0.84945576  0.        ]\n",
      " [ 0.23595691 -0.68296915  0.        ]]\n",
      "[]\n",
      "[[ 1.72642945  1.61270777]\n",
      " [-0.05946853  1.40046877]\n",
      " [ 1.17242132  0.31428975]]\n",
      "SOFTMAX_LAYER\n",
      "[0.50405568220036445, 0.49594431779963566]\n",
      "LOSS PER INSTANCE: 0.701292\n",
      "DERIVATIVE LOSS: -2.016355\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.701292\n",
      "EPOCH 76\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.74795629  0.2249001   0.        ]\n",
      " [ 0.22146857 -0.85088204  0.        ]\n",
      " [ 0.23771292 -0.68154286  0.        ]]\n",
      "[]\n",
      "[[ 1.72996294  1.61633613]\n",
      " [-0.05745945  1.4025318 ]\n",
      " [ 1.17544941  0.31739914]]\n",
      "SOFTMAX_LAYER\n",
      "[0.50364267738741608, 0.49635732261258375]\n",
      "LOSS PER INSTANCE: 0.700459\n",
      "DERIVATIVE LOSS: -2.014678\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.700459\n",
      "EPOCH 77\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.74968506  0.22349141  0.        ]\n",
      " [ 0.2197398  -0.85229074  0.        ]\n",
      " [ 0.23944169 -0.68013417  0.        ]]\n",
      "[]\n",
      "[[ 1.73345435  1.61991176]\n",
      " [-0.05547145  1.40456775]\n",
      " [ 1.17843912  0.32046097]]\n",
      "SOFTMAX_LAYER\n",
      "[0.50323869674625044, 0.49676130325374962]\n",
      "LOSS PER INSTANCE: 0.699646\n",
      "DERIVATIVE LOSS: -2.013039\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.699646\n",
      "EPOCH 78\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.75138733  0.22209988  0.        ]\n",
      " [ 0.21803753 -0.85368227  0.        ]\n",
      " [ 0.24114396 -0.67874264  0.        ]]\n",
      "[]\n",
      "[[ 1.73690463  1.62343606]\n",
      " [-0.0535041   1.4065773 ]\n",
      " [ 1.18139138  0.32347657]]\n",
      "SOFTMAX_LAYER\n",
      "[0.50284345449405965, 0.49715654550594029]\n",
      "LOSS PER INSTANCE: 0.698850\n",
      "DERIVATIVE LOSS: -2.011439\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.698850\n",
      "EPOCH 79\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.75306382  0.22072511  0.        ]\n",
      " [ 0.21636104 -0.85505704  0.        ]\n",
      " [ 0.24282045 -0.67736787  0.        ]]\n",
      "[]\n",
      "[[ 1.74031468  1.62691036]\n",
      " [-0.05155697  1.40856112]\n",
      " [ 1.18430705  0.32644717]]\n",
      "SOFTMAX_LAYER\n",
      "[0.50245667661286642, 0.49754332338713364]\n",
      "LOSS PER INSTANCE: 0.698073\n",
      "DERIVATIVE LOSS: -2.009875\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.698073\n",
      "EPOCH 80\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.75471521  0.2193667   0.        ]\n",
      " [ 0.21470965 -0.85641545  0.        ]\n",
      " [ 0.24447184 -0.67600946  0.        ]]\n",
      "[]\n",
      "[[ 1.74368538  1.63033595]\n",
      " [-0.04962965  1.41051983]\n",
      " [ 1.18718699  0.329374  ]]\n",
      "SOFTMAX_LAYER\n",
      "[0.50207810026113853, 0.49792189973886147]\n",
      "LOSS PER INSTANCE: 0.697312\n",
      "DERIVATIVE LOSS: -2.008347\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.697312\n",
      "EPOCH 81\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.75634216  0.21802428  0.        ]\n",
      " [ 0.2130827  -0.85775787  0.        ]\n",
      " [ 0.24609879 -0.67466704  0.        ]]\n",
      "[]\n",
      "[[ 1.7470176   1.63371408]\n",
      " [-0.04772172  1.41245404]\n",
      " [ 1.19003201  0.33225822]]\n",
      "SOFTMAX_LAYER\n",
      "[0.50170747321959197, 0.49829252678040808]\n",
      "LOSS PER INSTANCE: 0.696568\n",
      "DERIVATIVE LOSS: -2.006853\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.696568\n",
      "EPOCH 82\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.75794531  0.21669747  0.        ]\n",
      " [ 0.21147955 -0.85908468  0.        ]\n",
      " [ 0.24770194 -0.67334023  0.        ]]\n",
      "[]\n",
      "[[ 1.75031216  1.63704594]\n",
      " [-0.04583281  1.41436434]\n",
      " [ 1.19284291  0.33510095]]\n",
      "SOFTMAX_LAYER\n",
      "[0.50134455336894856, 0.49865544663105149]\n",
      "LOSS PER INSTANCE: 0.695840\n",
      "DERIVATIVE LOSS: -2.005393\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.695840\n",
      "EPOCH 83\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.75952526  0.21538592  0.        ]\n",
      " [ 0.2098996  -0.86039622  0.        ]\n",
      " [ 0.24928189 -0.67202868  0.        ]]\n",
      "[]\n",
      "[[ 1.75356986  1.64033269]\n",
      " [-0.04396254  1.41625129]\n",
      " [ 1.19562046  0.33790327]]\n",
      "SOFTMAX_LAYER\n",
      "[0.50098910819757647, 0.49901089180242353]\n",
      "LOSS PER INSTANCE: 0.695127\n",
      "DERIVATIVE LOSS: -2.003964\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.695127\n",
      "EPOCH 84\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.76108262  0.21408929  0.        ]\n",
      " [ 0.20834224 -0.86169285  0.        ]\n",
      " [ 0.25083925 -0.67073205  0.        ]]\n",
      "[]\n",
      "[[ 1.75679148  1.64357545]\n",
      " [-0.04211054  1.41811545]\n",
      " [ 1.19836538  0.3406662 ]]\n",
      "SOFTMAX_LAYER\n",
      "[0.5006409143370868, 0.4993590856629132]\n",
      "LOSS PER INSTANCE: 0.694430\n",
      "DERIVATIVE LOSS: -2.002567\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.694430\n",
      "EPOCH 85\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.76261795  0.21280725  0.        ]\n",
      " [ 0.20680691 -0.8629749   0.        ]\n",
      " [ 0.25237458 -0.66945001  0.        ]]\n",
      "[]\n",
      "[[ 1.75997776  1.64677529]\n",
      " [-0.04027645  1.41995734]\n",
      " [ 1.2010784   0.34339077]]\n",
      "SOFTMAX_LAYER\n",
      "[0.5002997571240968, 0.49970024287590309]\n",
      "LOSS PER INSTANCE: 0.693747\n",
      "DERIVATIVE LOSS: -2.001200\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.693747\n",
      "EPOCH 86\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.76413179  0.21153947  0.        ]\n",
      " [ 0.20529307 -0.86424268  0.        ]\n",
      " [ 0.25388842 -0.66818223  0.        ]]\n",
      "[]\n",
      "[[ 1.76312944  1.64993324]\n",
      " [-0.03845993  1.42177747]\n",
      " [ 1.20376022  0.34607792]]\n",
      "SOFTMAX_LAYER\n",
      "[0.49996543018649431, 0.50003456981350569]\n",
      "LOSS PER INSTANCE: 0.693078\n",
      "DERIVATIVE LOSS: -1.999862\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.693078\n",
      "EPOCH 87\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.76562468  0.21028564  0.        ]\n",
      " [ 0.20380018 -0.86549651  0.        ]\n",
      " [ 0.25538131 -0.6669284   0.        ]]\n",
      "[]\n",
      "[[ 1.76624723  1.65305031]\n",
      " [-0.03666065  1.42357634]\n",
      " [ 1.20641151  0.3487286 ]]\n",
      "SOFTMAX_LAYER\n",
      "[0.49963773505265946, 0.5003622649473406]\n",
      "LOSS PER INSTANCE: 0.692423\n",
      "DERIVATIVE LOSS: -1.998552\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.692423\n",
      "EPOCH 88\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.76709713  0.20904547  0.        ]\n",
      " [ 0.20232773 -0.86673668  0.        ]\n",
      " [ 0.25685376 -0.66568823  0.        ]]\n",
      "[]\n",
      "[[ 1.76933181  1.65612747]\n",
      " [-0.03487827  1.42535443]\n",
      " [ 1.20903291  0.3513437 ]]\n",
      "SOFTMAX_LAYER\n",
      "[0.49931648078219792, 0.50068351921780219]\n",
      "LOSS PER INSTANCE: 0.691781\n",
      "DERIVATIVE LOSS: -1.997270\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.691781\n",
      "EPOCH 89\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.76854963  0.20781865  0.        ]\n",
      " [ 0.20087523 -0.86796349  0.        ]\n",
      " [ 0.25830626 -0.66446141  0.        ]]\n",
      "[]\n",
      "[[ 1.77238385  1.65916566]\n",
      " [-0.03311248  1.4271122 ]\n",
      " [ 1.21162506  0.35392407]]\n",
      "SOFTMAX_LAYER\n",
      "[0.49900148361684943, 0.50099851638315052]\n",
      "LOSS PER INSTANCE: 0.691152\n",
      "DERIVATIVE LOSS: -1.996014\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.691152\n",
      "EPOCH 90\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.76998266  0.20660492  0.        ]\n",
      " [ 0.1994422  -0.86917723  0.        ]\n",
      " [ 0.25973929 -0.66324768  0.        ]]\n",
      "[]\n",
      "[[ 1.775404    1.66216576]\n",
      " [-0.03136298  1.42885009]\n",
      " [ 1.21418857  0.35647057]]\n",
      "SOFTMAX_LAYER\n",
      "[0.49869256665032269, 0.50130743334967731]\n",
      "LOSS PER INSTANCE: 0.690536\n",
      "DERIVATIVE LOSS: -1.994784\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.690536\n",
      "EPOCH 91\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.77139667  0.20540399  0.        ]\n",
      " [ 0.19802819 -0.87037815  0.        ]\n",
      " [ 0.26115331 -0.66204675  0.        ]]\n",
      "[]\n",
      "[[ 1.77839288  1.66512867]\n",
      " [-0.02962947  1.43056854]\n",
      " [ 1.21672403  0.358984  ]]\n",
      "SOFTMAX_LAYER\n",
      "[0.49838955951589065, 0.5016104404841093]\n",
      "LOSS PER INSTANCE: 0.689931\n",
      "DERIVATIVE LOSS: -1.993579\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.689931\n",
      "EPOCH 92\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.77279213  0.20421561  0.        ]\n",
      " [ 0.19663273 -0.87156654  0.        ]\n",
      " [ 0.26254876 -0.66085837  0.        ]]\n",
      "[]\n",
      "[[ 1.7813511   1.66805523]\n",
      " [-0.02791165  1.43226798]\n",
      " [ 1.21923201  0.36146514]]\n",
      "SOFTMAX_LAYER\n",
      "[0.49809229809066563, 0.50190770190933431]\n",
      "LOSS PER INSTANCE: 0.689339\n",
      "DERIVATIVE LOSS: -1.992398\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.689339\n",
      "EPOCH 93\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.77416945  0.2030395   0.        ]\n",
      " [ 0.19525541 -0.87274264  0.        ]\n",
      " [ 0.26392608 -0.65968227  0.        ]]\n",
      "[]\n",
      "[[ 1.78427926  1.67094625]\n",
      " [-0.02620924  1.43394879]\n",
      " [ 1.22171308  0.36391474]]\n",
      "SOFTMAX_LAYER\n",
      "[0.4978006242155415, 0.50219937578445839]\n",
      "LOSS PER INSTANCE: 0.688758\n",
      "DERIVATIVE LOSS: -1.991241\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.688758\n",
      "EPOCH 94\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.77552905  0.20187544  0.        ]\n",
      " [ 0.19389581 -0.87390671  0.        ]\n",
      " [ 0.26528568 -0.6585182   0.        ]]\n",
      "[]\n",
      "[[ 1.78717793  1.67380253]\n",
      " [-0.02452196  1.43561139]\n",
      " [ 1.22416778  0.36633353]]\n",
      "SOFTMAX_LAYER\n",
      "[0.49751438542986015, 0.50248561457013985]\n",
      "LOSS PER INSTANCE: 0.688188\n",
      "DERIVATIVE LOSS: -1.990107\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.688188\n",
      "EPOCH 95\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.77687133  0.20072316  0.        ]\n",
      " [ 0.19255353 -0.87505898  0.        ]\n",
      " [ 0.26662796 -0.65736593  0.        ]]\n",
      "[]\n",
      "[[ 1.79004768  1.67662483]\n",
      " [-0.02284955  1.43725615]\n",
      " [ 1.22659662  0.36872222]]\n",
      "SOFTMAX_LAYER\n",
      "[0.49723343471992387, 0.50276656528007613]\n",
      "LOSS PER INSTANCE: 0.687629\n",
      "DERIVATIVE LOSS: -1.988995\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.687629\n",
      "EPOCH 96\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.77819669  0.19958245  0.        ]\n",
      " [ 0.19122817 -0.8761997   0.        ]\n",
      " [ 0.26795332 -0.65622521  0.        ]]\n",
      "[]\n",
      "[[ 1.79288904  1.67941389]\n",
      " [-0.02119175  1.43888344]\n",
      " [ 1.22900013  0.37108149]]\n",
      "SOFTMAX_LAYER\n",
      "[0.4969576302805277, 0.50304236971947225]\n",
      "LOSS PER INSTANCE: 0.687081\n",
      "DERIVATIVE LOSS: -1.987904\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.687081\n",
      "EPOCH 97\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.7795055   0.19845307  0.        ]\n",
      " [ 0.18991936 -0.87732908  0.        ]\n",
      " [ 0.26926214 -0.65509583  0.        ]]\n",
      "[]\n",
      "[[ 1.79570254  1.68217044]\n",
      " [-0.0195483   1.44049362]\n",
      " [ 1.23137879  0.373412  ]]\n",
      "SOFTMAX_LAYER\n",
      "[0.49668683528875096, 0.50331316471124898]\n",
      "LOSS PER INSTANCE: 0.686543\n",
      "DERIVATIVE LOSS: -1.986835\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.686543\n",
      "EPOCH 98\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.78079814  0.1973348   0.        ]\n",
      " [ 0.18862672 -0.87844735  0.        ]\n",
      " [ 0.27055477 -0.65397756  0.        ]]\n",
      "[]\n",
      "[[ 1.79848871  1.68489518]\n",
      " [-0.01791896  1.44208703]\n",
      " [ 1.23373309  0.37571439]]\n",
      "SOFTMAX_LAYER\n",
      "[0.49642091768928459, 0.50357908231071535]\n",
      "LOSS PER INSTANCE: 0.686015\n",
      "DERIVATIVE LOSS: -1.985785\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.686015\n",
      "EPOCH 99\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.78207494  0.19622742  0.        ]\n",
      " [ 0.18734992 -0.87955473  0.        ]\n",
      " [ 0.27183157 -0.65287018  0.        ]]\n",
      "[]\n",
      "[[ 1.80124804  1.68758877]\n",
      " [-0.01630348  1.44366402]\n",
      " [ 1.23606349  0.37798927]]\n",
      "SOFTMAX_LAYER\n",
      "[0.49615974999062579, 0.50384025000937416]\n",
      "LOSS PER INSTANCE: 0.685496\n",
      "DERIVATIVE LOSS: -1.984756\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.685496\n"
     ]
    }
   ],
   "source": [
    "class SigmoidNN(NN):\n",
    "    def _activate(self, x):\n",
    "        \"\"\"\n",
    "        override RelU with sigmoid\n",
    "        \"\"\"\n",
    "        return self._sigmoid(x)\n",
    "    \n",
    "    def _derivative_activation(self, x):\n",
    "        \"\"\"\n",
    "        Override RelU' with Sigmoid'\n",
    "        \"\"\"\n",
    "        return self._derivative_sigmoid(x)\n",
    "    \n",
    "\"\"\"\n",
    "Run the same test with sigmoid\n",
    "\"\"\"\n",
    "MLP = SigmoidNN(2, 1, 2, 2)\n",
    "xor_inputs = [[1, 1], [-1, 1], [-1, -1], [1, -1]]\n",
    "xor_labels = ([1, 0, 1, 0])\n",
    "MLP.train(xor_inputs, xor_labels, epochs=100, lr=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.79098598 -0.05572377  0.        ]\n",
      " [ 0.08511857  0.25775903  0.        ]\n",
      " [-0.18411189 -1.29343291  0.        ]]\n",
      "[]\n",
      "[[ 0.59895566 -0.9057812 ]\n",
      " [ 0.34696668  0.45134984]\n",
      " [-0.47357902 -0.41719315]]\n",
      "SOFTMAX_LAYER\n",
      "[0.68401889935143889, 0.31598110064856111]\n",
      "LOSS PER INSTANCE: 1.152073\n",
      "DERIVATIVE LOSS: -3.164746\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 1.152073\n",
      "EPOCH 1\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.81341844 -0.01999502  0.        ]\n",
      " [ 0.06268612  0.29348778  0.        ]\n",
      " [-0.16167943 -1.32916166  0.        ]]\n",
      "[]\n",
      "[[ 0.63180385 -0.90036212]\n",
      " [ 0.28495804  0.44112007]\n",
      " [-0.42135735 -0.40857797]]\n",
      "SOFTMAX_LAYER\n",
      "[0.72012928543371213, 0.27987071456628787]\n",
      "LOSS PER INSTANCE: 1.273428\n",
      "DERIVATIVE LOSS: -3.573078\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 1.273428\n",
      "EPOCH 2\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.84084877  0.03564171  0.        ]\n",
      " [ 0.03525579  0.34912451  0.        ]\n",
      " [-0.1342491  -1.38479839  0.        ]]\n",
      "[]\n",
      "[[ 0.68169967 -0.89003912]\n",
      " [ 0.19802291  0.42313397]\n",
      " [-0.34955207 -0.3937221 ]]\n",
      "SOFTMAX_LAYER\n",
      "[0.76257873597637182, 0.23742126402362818]\n",
      "LOSS PER INSTANCE: 1.437919\n",
      "DERIVATIVE LOSS: -4.211923\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 1.437919\n",
      "EPOCH 3\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.87307498  0.11599721  0.        ]\n",
      " [ 0.00302957  0.42948002  0.        ]\n",
      " [-0.10202289 -1.46515389  0.        ]]\n",
      "[]\n",
      "[[ 0.75530196 -0.87228351]\n",
      " [ 0.07948279  0.39453767]\n",
      " [-0.25387262 -0.37064065]]\n",
      "SOFTMAX_LAYER\n",
      "[0.80906477320886983, 0.19093522679113026]\n",
      "LOSS PER INSTANCE: 1.655821\n",
      "DERIVATIVE LOSS: -5.237378\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 1.655821\n",
      "EPOCH 4\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.90298622  0.19831474  0.        ]\n",
      " [-0.02688166  0.51179754  0.        ]\n",
      " [-0.07211165 -1.54747142  0.        ]]\n",
      "[]\n",
      "[[ 0.84737555 -0.84654949]\n",
      " [-0.0580721   0.3560919 ]\n",
      " [-0.14528623 -0.3402914 ]]\n",
      "SOFTMAX_LAYER\n",
      "[0.84956080330496764, 0.15043919669503236]\n",
      "LOSS PER INSTANCE: 1.894196\n",
      "DERIVATIVE LOSS: -6.647204\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 1.894196\n",
      "EPOCH 5\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.91746122  0.22804052  0.        ]\n",
      " [-0.04135666  0.54152332  0.        ]\n",
      " [-0.05763665 -1.5771972   0.        ]]\n",
      "[]\n",
      "[[ 0.91795857 -0.82087468]\n",
      " [-0.15741773  0.3199546 ]\n",
      " [-0.06795113 -0.3121605 ]]\n",
      "SOFTMAX_LAYER\n",
      "[0.87002974310729631, 0.12997025689270364]\n",
      "LOSS PER INSTANCE: 2.040450\n",
      "DERIVATIVE LOSS: -7.694068\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.040450\n",
      "EPOCH 6\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92130694  0.22904151  0.        ]\n",
      " [-0.04520238  0.54252431  0.        ]\n",
      " [-0.05379093 -1.57819819  0.        ]]\n",
      "[]\n",
      "[[ 0.94729737 -0.8059424 ]\n",
      " [-0.19760133  0.29950275]\n",
      " [-0.03678205 -0.29629668]]\n",
      "SOFTMAX_LAYER\n",
      "[0.87570640455008864, 0.12429359544991141]\n",
      "LOSS PER INSTANCE: 2.085109\n",
      "DERIVATIVE LOSS: -8.045467\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.085109\n",
      "EPOCH 7\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92273965  0.22753866  0.        ]\n",
      " [-0.0466351   0.54102147  0.        ]\n",
      " [-0.05235822 -1.57669534  0.        ]]\n",
      "[]\n",
      "[[ 0.96066168 -0.79792686]\n",
      " [-0.21576668  0.28860767]\n",
      " [-0.02269333 -0.28784665]]\n",
      "SOFTMAX_LAYER\n",
      "[0.87774026291280327, 0.12225973708719674]\n",
      "LOSS PER INSTANCE: 2.101608\n",
      "DERIVATIVE LOSS: -8.179308\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.101608\n",
      "EPOCH 8\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92346817  0.22631239  0.        ]\n",
      " [-0.04736361  0.5397952   0.        ]\n",
      " [-0.0516297  -1.57546907  0.        ]]\n",
      "[]\n",
      "[[ 0.96827451 -0.79291944]\n",
      " [-0.22608342  0.28182172]\n",
      " [-0.01469053 -0.28258273]]\n",
      "SOFTMAX_LAYER\n",
      "[0.87872393393833281, 0.12127606606166712]\n",
      "LOSS PER INSTANCE: 2.109686\n",
      "DERIVATIVE LOSS: -8.245650\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.109686\n",
      "EPOCH 9\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92390526  0.22542768  0.        ]\n",
      " [-0.0478007   0.53891049  0.        ]\n",
      " [-0.05119261 -1.57458436  0.        ]]\n",
      "[]\n",
      "[[ 0.97321814 -0.7894616 ]\n",
      " [-0.23277244  0.27714307]\n",
      " [-0.00950109 -0.27895296]]\n",
      "SOFTMAX_LAYER\n",
      "[0.87928588140695174, 0.12071411859304826]\n",
      "LOSS PER INSTANCE: 2.114330\n",
      "DERIVATIVE LOSS: -8.284035\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.114330\n",
      "EPOCH 10\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.924195    0.22478368  0.        ]\n",
      " [-0.04809044  0.53826649  0.        ]\n",
      " [-0.05090287 -1.57394036  0.        ]]\n",
      "[]\n",
      "[[ 0.97670118 -0.78691363]\n",
      " [-0.23748071  0.2736988 ]\n",
      " [-0.00584799 -0.27628058]]\n",
      "SOFTMAX_LAYER\n",
      "[0.87964150402533992, 0.12035849597466011]\n",
      "LOSS PER INSTANCE: 2.117281\n",
      "DERIVATIVE LOSS: -8.308512\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.117281\n",
      "EPOCH 11\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92440032  0.22430259  0.        ]\n",
      " [-0.04829576  0.53778539  0.        ]\n",
      " [-0.05069755 -1.57345927  0.        ]]\n",
      "[]\n",
      "[[ 0.9792948  -0.78494946]\n",
      " [-0.24098445  0.2710454 ]\n",
      " [-0.00312927 -0.27422168]]\n",
      "SOFTMAX_LAYER\n",
      "[0.87988270003791103, 0.12011729996208897]\n",
      "LOSS PER INSTANCE: 2.119287\n",
      "DERIVATIVE LOSS: -8.325195\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.119287\n",
      "EPOCH 12\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92455295  0.22393371  0.        ]\n",
      " [-0.04844839  0.53741652  0.        ]\n",
      " [-0.05054492 -1.57309039  0.        ]]\n",
      "[]\n",
      "[[ 0.98130497 -0.78338429]\n",
      " [-0.24369876  0.26893195]\n",
      " [-0.00102299 -0.27258167]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88005469953363868, 0.11994530046636132]\n",
      "LOSS PER INSTANCE: 2.120719\n",
      "DERIVATIVE LOSS: -8.337134\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.120719\n",
      "EPOCH 13\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92467057  0.22364426  0.        ]\n",
      " [-0.04856601  0.53712706  0.        ]\n",
      " [-0.0504273  -1.57280094  0.        ]]\n",
      "[]\n",
      "[[  9.82910878e-01  -7.82104927e-01]\n",
      " [ -2.45866477e-01   2.67205024e-01]\n",
      " [  6.59198922e-04  -2.71241539e-01]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88018211294621973, 0.1198178870537803]\n",
      "LOSS PER INSTANCE: 2.121782\n",
      "DERIVATIVE LOSS: -8.345999\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.121782\n",
      "EPOCH 14\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.9247638   0.22341255  0.        ]\n",
      " [-0.04865924  0.53689535  0.        ]\n",
      " [-0.05033407 -1.57256923  0.        ]]\n",
      "[]\n",
      "[[ 0.98422468 -0.7810379 ]\n",
      " [-0.24763943  0.26576509]\n",
      " [ 0.00203509 -0.27012408]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88027936634755832, 0.11972063365244172]\n",
      "LOSS PER INSTANCE: 2.122594\n",
      "DERIVATIVE LOSS: -8.352779\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.122594\n",
      "EPOCH 15\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.9248394   0.22322386  0.        ]\n",
      " [-0.04873484  0.53670667  0.        ]\n",
      " [-0.05025847 -1.57238054  0.        ]]\n",
      "[]\n",
      "[[ 0.98532028 -0.78013326]\n",
      " [-0.24911762  0.26454455]\n",
      " [ 0.00318227 -0.26917686]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88035541708595033, 0.11964458291404968]\n",
      "LOSS PER INSTANCE: 2.123230\n",
      "DERIVATIVE LOSS: -8.358088\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.123230\n",
      "EPOCH 16\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92490185  0.22306792  0.        ]\n",
      " [-0.04879729  0.53655072  0.        ]\n",
      " [-0.05019602 -1.5722246   0.        ]]\n",
      "[]\n",
      "[[ 0.98624844 -0.77935582]\n",
      " [-0.25036969  0.26349579]\n",
      " [ 0.00415397 -0.26836294]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88041608825207707, 0.11958391174792292]\n",
      "LOSS PER INSTANCE: 2.123737\n",
      "DERIVATIVE LOSS: -8.362329\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.123737\n",
      "EPOCH 17\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92495425  0.22293737  0.        ]\n",
      " [-0.04884969  0.53642018  0.        ]\n",
      " [-0.05014362 -1.57209405  0.        ]]\n",
      "[]\n",
      "[[ 0.9870452  -0.77867998]\n",
      " [-0.25144435  0.26258422]\n",
      " [ 0.00498802 -0.26765547]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88046531015647156, 0.11953468984352834]\n",
      "LOSS PER INSTANCE: 2.124149\n",
      "DERIVATIVE LOSS: -8.365772\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.124149\n",
      "EPOCH 18\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.9249988   0.22282685  0.        ]\n",
      " [-0.04889424  0.53630965  0.        ]\n",
      " [-0.05009907 -1.57198353  0.        ]]\n",
      "[]\n",
      "[[ 0.9877369  -0.77808667]\n",
      " [-0.2523772   0.26178407]\n",
      " [ 0.00571201 -0.26703447]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88050581986285315, 0.11949418013714687]\n",
      "LOSS PER INSTANCE: 2.124488\n",
      "DERIVATIVE LOSS: -8.368608\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.124488\n",
      "EPOCH 19\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92503711  0.22273234  0.        ]\n",
      " [-0.04893255  0.53621515  0.        ]\n",
      " [-0.05006076 -1.57188902  0.        ]]\n",
      "[]\n",
      "[[ 0.98834323 -0.77756138]\n",
      " [-0.25319483  0.26107571]\n",
      " [ 0.00634659 -0.2664847 ]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88053957463191745, 0.11946042536808257]\n",
      "LOSS PER INSTANCE: 2.124770\n",
      "DERIVATIVE LOSS: -8.370973\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.124770\n",
      "EPOCH 20\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92507039  0.22265082  0.        ]\n",
      " [-0.04896583  0.53613363  0.        ]\n",
      " [-0.05002749 -1.5718075   0.        ]]\n",
      "[]\n",
      "[[ 0.98887921 -0.77709284]\n",
      " [-0.25391754  0.26044394]\n",
      " [ 0.0069075  -0.26599437]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88056800628578524, 0.11943199371421472]\n",
      "LOSS PER INSTANCE: 2.125008\n",
      "DERIVATIVE LOSS: -8.372966\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.125008\n",
      "EPOCH 21\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92509954  0.22257995  0.        ]\n",
      " [-0.04899498  0.53606275  0.        ]\n",
      " [-0.04999833 -1.57173663  0.        ]]\n",
      "[]\n",
      "[[ 0.98935652 -0.77667217]\n",
      " [-0.25456109  0.25987677]\n",
      " [ 0.00740699 -0.26555416]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88059218315285837, 0.11940781684714158]\n",
      "LOSS PER INSTANCE: 2.125211\n",
      "DERIVATIVE LOSS: -8.374661\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.125211\n",
      "EPOCH 22\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92512527  0.22251789  0.        ]\n",
      " [-0.04902072  0.53600069  0.        ]\n",
      " [-0.0499726  -1.57167457  0.        ]]\n",
      "[]\n",
      "[[ 0.98978439 -0.77629229]\n",
      " [-0.25513794  0.25936461]\n",
      " [ 0.0078547  -0.26515665]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88061291626731619, 0.11938708373268385]\n",
      "LOSS PER INSTANCE: 2.125384\n",
      "DERIVATIVE LOSS: -8.376115\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.125384\n",
      "EPOCH 23\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92514815  0.22246321  0.        ]\n",
      " [-0.0490436   0.53594601  0.        ]\n",
      " [-0.04994972 -1.57161989  0.        ]]\n",
      "[]\n",
      "[[ 0.99017017 -0.77594743]\n",
      " [-0.25565802  0.2588997 ]\n",
      " [ 0.00825836 -0.26479582]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88063083083358495, 0.11936916916641507]\n",
      "LOSS PER INSTANCE: 2.125534\n",
      "DERIVATIVE LOSS: -8.377373\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.125534\n",
      "EPOCH 24\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92516862  0.22241474  0.        ]\n",
      " [-0.04906406  0.53589755  0.        ]\n",
      " [-0.04992925 -1.57157142  0.        ]]\n",
      "[]\n",
      "[[ 0.99051984 -0.77563291]\n",
      " [-0.2561294   0.2584757 ]\n",
      " [ 0.00862422 -0.26446673]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88064641542296129, 0.11935358457703865]\n",
      "LOSS PER INSTANCE: 2.125665\n",
      "DERIVATIVE LOSS: -8.378466\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.125665\n",
      "EPOCH 25\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92518702  0.22237156  0.        ]\n",
      " [-0.04908246  0.53585437  0.        ]\n",
      " [-0.04991085 -1.57152824  0.        ]]\n",
      "[]\n",
      "[[ 0.99083828 -0.77534482]\n",
      " [-0.25655865  0.25808736]\n",
      " [ 0.00895738 -0.26416532]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88066005653182433, 0.1193399434681756]\n",
      "LOSS PER INSTANCE: 2.125779\n",
      "DERIVATIVE LOSS: -8.379424\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.125779\n",
      "EPOCH 26\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92520366  0.2223329   0.        ]\n",
      " [-0.0490991   0.53581571  0.        ]\n",
      " [-0.04989422 -1.57148958  0.        ]]\n",
      "[]\n",
      "[[ 0.99112952 -0.77507993]\n",
      " [-0.25695123  0.2577303 ]\n",
      " [ 0.00926209 -0.26388819]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88067206329945524, 0.11932793670054472]\n",
      "LOSS PER INSTANCE: 2.125880\n",
      "DERIVATIVE LOSS: -8.380267\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.125880\n",
      "EPOCH 27\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92521876  0.22229814  0.        ]\n",
      " [-0.0491142   0.53578094  0.        ]\n",
      " [-0.04987911 -1.57145482  0.        ]]\n",
      "[]\n",
      "[[ 0.99139694 -0.7748355 ]\n",
      " [-0.25731168  0.25740084]\n",
      " [ 0.00954185 -0.26363247]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88068268547712103, 0.11931731452287904]\n",
      "LOSS PER INSTANCE: 2.125969\n",
      "DERIVATIVE LOSS: -8.381013\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.125969\n",
      "EPOCH 28\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92523253  0.22226675  0.        ]\n",
      " [-0.04912798  0.53574955  0.        ]\n",
      " [-0.04986534 -1.57142343  0.        ]]\n",
      "[]\n",
      "[[ 0.99164336 -0.77460922]\n",
      " [-0.25764381  0.25709585]\n",
      " [ 0.00979965 -0.26339575]]\n",
      "SOFTMAX_LAYER\n",
      "[0.8806921266845017, 0.11930787331549826]\n",
      "LOSS PER INSTANCE: 2.126048\n",
      "DERIVATIVE LOSS: -8.381677\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126048\n",
      "EPOCH 29\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92524514  0.22223829  0.        ]\n",
      " [-0.04914059  0.5357211   0.        ]\n",
      " [-0.04985273 -1.57139497  0.        ]]\n",
      "[]\n",
      "[[ 0.99187118 -0.77439912]\n",
      " [-0.25795087  0.25681268]\n",
      " [ 0.01003797 -0.26317596]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88070055432103878, 0.11929944567896113]\n",
      "LOSS PER INSTANCE: 2.126119\n",
      "DERIVATIVE LOSS: -8.382269\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126119\n",
      "EPOCH 30\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92525672  0.22221241  0.        ]\n",
      " [-0.04915217  0.53569522  0.        ]\n",
      " [-0.04984115 -1.57136909  0.        ]]\n",
      "[]\n",
      "[[ 0.99208244 -0.7742035 ]\n",
      " [-0.2582356   0.25654903]\n",
      " [ 0.01025897 -0.26297132]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88070810706732372, 0.11929189293267627]\n",
      "LOSS PER INSTANCE: 2.126182\n",
      "DERIVATIVE LOSS: -8.382799\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126182\n",
      "EPOCH 31\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.9252674   0.22218879  0.        ]\n",
      " [-0.04916284  0.5356716   0.        ]\n",
      " [-0.04983047 -1.57134547  0.        ]]\n",
      "[]\n",
      "[[ 0.9922789  -0.77402089]\n",
      " [-0.25850038  0.25630292]\n",
      " [ 0.01046449 -0.2627803 ]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88071490062644753, 0.11928509937355247]\n",
      "LOSS PER INSTANCE: 2.126239\n",
      "DERIVATIVE LOSS: -8.383277\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126239\n",
      "EPOCH 32\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92527727  0.22216718  0.        ]\n",
      " [-0.04917271  0.53564998  0.        ]\n",
      " [-0.04982061 -1.57132386  0.        ]]\n",
      "[]\n",
      "[[ 0.99246207 -0.77385003]\n",
      " [-0.25874723  0.25607265]\n",
      " [ 0.01065609 -0.26260157]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88072103216379849, 0.11927896783620147]\n",
      "LOSS PER INSTANCE: 2.126290\n",
      "DERIVATIVE LOSS: -8.383708\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126290\n",
      "EPOCH 33\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92528641  0.22214733  0.        ]\n",
      " [-0.04918185  0.53563013  0.        ]\n",
      " [-0.04981146 -1.57130401  0.        ]]\n",
      "[]\n",
      "[[ 0.99263326 -0.7736898 ]\n",
      " [-0.25897795  0.25585671]\n",
      " [ 0.01083516 -0.26243396]]\n",
      "SOFTMAX_LAYER\n",
      "[0.880726583773215, 0.11927341622678507]\n",
      "LOSS PER INSTANCE: 2.126337\n",
      "DERIVATIVE LOSS: -8.384098\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126337\n",
      "EPOCH 34\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92529491  0.22212907  0.        ]\n",
      " [-0.04919036  0.53561187  0.        ]\n",
      " [-0.04980296 -1.57128575  0.        ]]\n",
      "[]\n",
      "[[ 0.99279362 -0.77353923]\n",
      " [-0.25919405  0.2556538 ]\n",
      " [ 0.0110029  -0.26227647]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88073162520699311, 0.11926837479300681]\n",
      "LOSS PER INSTANCE: 2.126379\n",
      "DERIVATIVE LOSS: -8.384452\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126379\n",
      "EPOCH 35\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92530283  0.22211221  0.        ]\n",
      " [-0.04919828  0.53559501  0.        ]\n",
      " [-0.04979504 -1.57126889  0.        ]]\n",
      "[]\n",
      "[[ 0.99294415 -0.77339747]\n",
      " [-0.25939691  0.25546275]\n",
      " [ 0.01116036 -0.26212818]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88073621604379759, 0.11926378395620245]\n",
      "LOSS PER INSTANCE: 2.126418\n",
      "DERIVATIVE LOSS: -8.384775\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126418\n",
      "EPOCH 36\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92531023  0.22209662  0.        ]\n",
      " [-0.04920567  0.53557943  0.        ]\n",
      " [-0.04978764 -1.5712533   0.        ]]\n",
      "[]\n",
      "[[ 0.99308574 -0.77326374]\n",
      " [-0.25958771  0.25528255]\n",
      " [ 0.01130845 -0.26198831]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88074040742340731, 0.11925959257659265]\n",
      "LOSS PER INSTANCE: 2.126453\n",
      "DERIVATIVE LOSS: -8.385070\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126453\n",
      "EPOCH 37\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92531715  0.22208217  0.        ]\n",
      " [-0.0492126   0.53556498  0.        ]\n",
      " [-0.04978072 -1.57123885  0.        ]]\n",
      "[]\n",
      "[[ 0.99321915 -0.7731374 ]\n",
      " [-0.2597675   0.25511229]\n",
      " [ 0.011448   -0.26185615]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88074424344479296, 0.11925575655520711]\n",
      "LOSS PER INSTANCE: 2.126485\n",
      "DERIVATIVE LOSS: -8.385339\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126485\n",
      "EPOCH 38\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92532365  0.22206875  0.        ]\n",
      " [-0.04921909  0.53555155  0.        ]\n",
      " [-0.04977423 -1.57122543  0.        ]]\n",
      "[]\n",
      "[[ 0.99334509 -0.77301782]\n",
      " [-0.2599372   0.25495115]\n",
      " [ 0.01157972 -0.26173108]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88074776230041296, 0.11925223769958708]\n",
      "LOSS PER INSTANCE: 2.126514\n",
      "DERIVATIVE LOSS: -8.385587\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126514\n",
      "EPOCH 39\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92532975  0.22205626  0.        ]\n",
      " [-0.04922519  0.53553906  0.        ]\n",
      " [-0.04976813 -1.57121294  0.        ]]\n",
      "[]\n",
      "[[ 0.99346416 -0.77290448]\n",
      " [-0.26009766  0.25479843]\n",
      " [ 0.01170427 -0.26161254]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88075099720228955, 0.11924900279771042]\n",
      "LOSS PER INSTANCE: 2.126542\n",
      "DERIVATIVE LOSS: -8.385814\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126542\n",
      "EPOCH 40\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92533549  0.22204461  0.        ]\n",
      " [-0.04923093  0.53552741  0.        ]\n",
      " [-0.04976238 -1.57120129  0.        ]]\n",
      "[]\n",
      "[[ 0.99357693 -0.7727969 ]\n",
      " [-0.26024961  0.25465346]\n",
      " [ 0.01182221 -0.26150002]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88075397714255421, 0.11924602285744582]\n",
      "LOSS PER INSTANCE: 2.126567\n",
      "DERIVATIVE LOSS: -8.386024\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126567\n",
      "EPOCH 41\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.9253409   0.22203372  0.        ]\n",
      " [-0.04923634  0.53551653  0.        ]\n",
      " [-0.04975697 -1.5711904   0.        ]]\n",
      "[]\n",
      "[[ 0.99368387 -0.77269465]\n",
      " [-0.26039372  0.25451567]\n",
      " [ 0.01193406 -0.26139307]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88075672752152867, 0.1192432724784713]\n",
      "LOSS PER INSTANCE: 2.126590\n",
      "DERIVATIVE LOSS: -8.386217\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126590\n",
      "EPOCH 42\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92534601  0.22202354  0.        ]\n",
      " [-0.04924145  0.53550634  0.        ]\n",
      " [-0.04975186 -1.57118022  0.        ]]\n",
      "[]\n",
      "[[ 0.99378543 -0.77259733]\n",
      " [-0.26053057  0.25438453]\n",
      " [ 0.01204028 -0.26129128]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88075927066913917, 0.11924072933086081]\n",
      "LOSS PER INSTANCE: 2.126611\n",
      "DERIVATIVE LOSS: -8.386396\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126611\n",
      "EPOCH 43\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92535085  0.22201399  0.        ]\n",
      " [-0.04924629  0.5354968   0.        ]\n",
      " [-0.04974703 -1.57117067  0.        ]]\n",
      "[]\n",
      "[[ 0.99388201 -0.77250459]\n",
      " [-0.26066071  0.25425957]\n",
      " [ 0.01214129 -0.26119429]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88076162627992671, 0.11923837372007333]\n",
      "LOSS PER INSTANCE: 2.126631\n",
      "DERIVATIVE LOSS: -8.386562\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126631\n",
      "EPOCH 44\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92535542  0.22200503  0.        ]\n",
      " [-0.04925087  0.53548784  0.        ]\n",
      " [-0.04974245 -1.57116171  0.        ]]\n",
      "[]\n",
      "[[ 0.99397397 -0.77241612]\n",
      " [-0.26078462  0.25414036]\n",
      " [ 0.01223747 -0.26110176]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88076381177767837, 0.11923618822232161]\n",
      "LOSS PER INSTANCE: 2.126649\n",
      "DERIVATIVE LOSS: -8.386716\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126649\n",
      "EPOCH 45\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92535977  0.22199661  0.        ]\n",
      " [-0.04925521  0.53547941  0.        ]\n",
      " [-0.0497381  -1.57115329  0.        ]]\n",
      "[]\n",
      "[[ 0.99406163 -0.77233162]\n",
      " [-0.26090274  0.25402651]\n",
      " [ 0.01232915 -0.26101339]]\n",
      "SOFTMAX_LAYER\n",
      "[0.8807658426224283, 0.11923415737757166]\n",
      "LOSS PER INSTANCE: 2.126666\n",
      "DERIVATIVE LOSS: -8.386858\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126666\n",
      "EPOCH 46\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92536389  0.22198868  0.        ]\n",
      " [-0.04925933  0.53547148  0.        ]\n",
      " [-0.04973398 -1.57114536  0.        ]]\n",
      "[]\n",
      "[[ 0.99414529 -0.77225084]\n",
      " [-0.26101546  0.25391766]\n",
      " [ 0.01241665 -0.2609289 ]]\n",
      "SOFTMAX_LAYER\n",
      "[0.8807677325700296, 0.11923226742997049]\n",
      "LOSS PER INSTANCE: 2.126682\n",
      "DERIVATIVE LOSS: -8.386991\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126682\n",
      "EPOCH 47\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92536781  0.2219812   0.        ]\n",
      " [-0.04926326  0.53546401  0.        ]\n",
      " [-0.04973006 -1.57113788  0.        ]]\n",
      "[]\n",
      "[[ 0.99422522 -0.77217352]\n",
      " [-0.26112316  0.25381348]\n",
      " [ 0.01250025 -0.26084804]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88076949389250725, 0.11923050610749275]\n",
      "LOSS PER INSTANCE: 2.126697\n",
      "DERIVATIVE LOSS: -8.387115\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126697\n",
      "EPOCH 48\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92537155  0.22197415  0.        ]\n",
      " [-0.04926699  0.53545695  0.        ]\n",
      " [-0.04972632 -1.57113083  0.        ]]\n",
      "[]\n",
      "[[ 0.99430166 -0.77209946]\n",
      " [-0.26122616  0.25371368]\n",
      " [ 0.01258019 -0.26077057]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88077113756583603, 0.11922886243416393]\n",
      "LOSS PER INSTANCE: 2.126710\n",
      "DERIVATIVE LOSS: -8.387231\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126710\n",
      "EPOCH 49\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92537511  0.22196748  0.        ]\n",
      " [-0.04927055  0.53545028  0.        ]\n",
      " [-0.04972276 -1.57112416  0.        ]]\n",
      "[]\n",
      "[[ 0.99437484 -0.77202844]\n",
      " [-0.26132476  0.25361799]\n",
      " [ 0.01265673 -0.2606963 ]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88077267343053955, 0.11922732656946039]\n",
      "LOSS PER INSTANCE: 2.126723\n",
      "DERIVATIVE LOSS: -8.387339\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126723\n"
     ]
    }
   ],
   "source": [
    "class TanHNN(NN):\n",
    "    \n",
    "    def _activate(self, x):\n",
    "        \"\"\"\n",
    "        Override with TanH\n",
    "        \"\"\"\n",
    "        return np.tanh(x)\n",
    "    \n",
    "    def _derivative_activation(self, x):\n",
    "        \"\"\"\n",
    "        Override with Derivative TanH (1 - tanH squared)\n",
    "        \"\"\"\n",
    "        return 1 - x*x\n",
    "    \n",
    "\"\"\"\n",
    "Run the same test with TanH\n",
    "\"\"\"\n",
    "MLP = TanHNN(2, 1, 2, 2)\n",
    "xor_inputs = [[1, 1], [-1, 1], [-1, -1], [1, -1]]\n",
    "xor_labels = ([1, 0, 1, 0])\n",
    "MLP.train(xor_inputs, xor_labels, epochs=50, lr=.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "def neighborhood2int(n):\n",
    "    \"\"\"\n",
    "    For mapping neighborhoods into integer labels\n",
    "    \"\"\"\n",
    "    return 1 if n == \"Blmngtn\" else 0\n",
    "\n",
    "df = pd.DataFrame.from_csv(\"./data/housing_date_train_2_features.csv\")\n",
    "housing_df = df.loc[df['Neighborhood'].isin([\"BrDale\", \"Blmngtn\"])]\n",
    "\n",
    "# Grab X and its labels as a single matrix\n",
    "dataset = housing_df[[\"LotArea\", \"SalePrice\", \"Neighborhood\"]].as_matrix()\n",
    "\n",
    "# 'shuffle' the matrix to randomize the position of each sample in it\n",
    "np.random.shuffle(dataset)\n",
    "\n",
    "# Not sure why shuffling changed the type, but need to \n",
    "# change the type of each scalar in X for some numpy methods to work\n",
    "X = dataset[:, :2].astype('int64')\n",
    "# Encode the labels\n",
    "y = [neighborhood2int(s) for s in dataset[:, 2]]\n",
    "\n",
    "# Find the length of 80% of the dataset for training data\n",
    "train_length = int(X.shape[0] * 0.8)\n",
    "\n",
    "# split 80%/20% for train and test\n",
    "train_X = X[:train_length]\n",
    "test_X = X[train_length:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
