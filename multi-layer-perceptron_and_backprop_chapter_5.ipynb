{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.01706483 -0.21897627  0.        ]\n",
      " [-0.54772216  0.06135303  0.        ]\n",
      " [ 1.94917891  0.75766211  0.        ]]\n",
      "[]\n",
      "[[-1.92696616 -0.94133878]\n",
      " [-1.02244142 -0.70361589]\n",
      " [-1.60804001  0.27499612]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0094458776944937022, 0.99055412230550621]\n",
      "LOSS PER INSTANCE: 0.009491\n",
      "DERIVATIVE LOSS: -1.009536\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.009491\n",
      "EPOCH 1\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.01706483 -0.21897627  0.        ]\n",
      " [-0.54772216  0.06135303  0.        ]\n",
      " [ 1.94917891  0.75766211  0.        ]]\n",
      "[]\n",
      "[[-1.92696616 -0.94133878]\n",
      " [-1.02244142 -0.70361589]\n",
      " [-1.60804001  0.27499612]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0094458776944937022, 0.99055412230550621]\n",
      "LOSS PER INSTANCE: 0.009491\n",
      "DERIVATIVE LOSS: -1.009536\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.009491\n",
      "EPOCH 2\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.01706483 -0.21897627  0.        ]\n",
      " [-0.54772216  0.06135303  0.        ]\n",
      " [ 1.94917891  0.75766211  0.        ]]\n",
      "[]\n",
      "[[-1.92696616 -0.94133878]\n",
      " [-1.02244142 -0.70361589]\n",
      " [-1.60804001  0.27499612]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0094458776944937022, 0.99055412230550621]\n",
      "LOSS PER INSTANCE: 0.009491\n",
      "DERIVATIVE LOSS: -1.009536\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.009491\n",
      "EPOCH 3\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.01706483 -0.21897627  0.        ]\n",
      " [-0.54772216  0.06135303  0.        ]\n",
      " [ 1.94917891  0.75766211  0.        ]]\n",
      "[]\n",
      "[[-1.92696616 -0.94133878]\n",
      " [-1.02244142 -0.70361589]\n",
      " [-1.60804001  0.27499612]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0094458776944937022, 0.99055412230550621]\n",
      "LOSS PER INSTANCE: 0.009491\n",
      "DERIVATIVE LOSS: -1.009536\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.009491\n",
      "EPOCH 4\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.01706483 -0.21897627  0.        ]\n",
      " [-0.54772216  0.06135303  0.        ]\n",
      " [ 1.94917891  0.75766211  0.        ]]\n",
      "[]\n",
      "[[-1.92696616 -0.94133878]\n",
      " [-1.02244142 -0.70361589]\n",
      " [-1.60804001  0.27499612]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0094458776944937022, 0.99055412230550621]\n",
      "LOSS PER INSTANCE: 0.009491\n",
      "DERIVATIVE LOSS: -1.009536\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.009491\n",
      "EPOCH 5\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.01706483 -0.21897627  0.        ]\n",
      " [-0.54772216  0.06135303  0.        ]\n",
      " [ 1.94917891  0.75766211  0.        ]]\n",
      "[]\n",
      "[[-1.92696616 -0.94133878]\n",
      " [-1.02244142 -0.70361589]\n",
      " [-1.60804001  0.27499612]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0094458776944937022, 0.99055412230550621]\n",
      "LOSS PER INSTANCE: 0.009491\n",
      "DERIVATIVE LOSS: -1.009536\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.009491\n",
      "EPOCH 6\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.01706483 -0.21897627  0.        ]\n",
      " [-0.54772216  0.06135303  0.        ]\n",
      " [ 1.94917891  0.75766211  0.        ]]\n",
      "[]\n",
      "[[-1.92696616 -0.94133878]\n",
      " [-1.02244142 -0.70361589]\n",
      " [-1.60804001  0.27499612]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0094458776944937022, 0.99055412230550621]\n",
      "LOSS PER INSTANCE: 0.009491\n",
      "DERIVATIVE LOSS: -1.009536\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.009491\n",
      "EPOCH 7\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.01706483 -0.21897627  0.        ]\n",
      " [-0.54772216  0.06135303  0.        ]\n",
      " [ 1.94917891  0.75766211  0.        ]]\n",
      "[]\n",
      "[[-1.92696616 -0.94133878]\n",
      " [-1.02244142 -0.70361589]\n",
      " [-1.60804001  0.27499612]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0094458776944937022, 0.99055412230550621]\n",
      "LOSS PER INSTANCE: 0.009491\n",
      "DERIVATIVE LOSS: -1.009536\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.009491\n",
      "EPOCH 8\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.01706483 -0.21897627  0.        ]\n",
      " [-0.54772216  0.06135303  0.        ]\n",
      " [ 1.94917891  0.75766211  0.        ]]\n",
      "[]\n",
      "[[-1.92696616 -0.94133878]\n",
      " [-1.02244142 -0.70361589]\n",
      " [-1.60804001  0.27499612]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0094458776944937022, 0.99055412230550621]\n",
      "LOSS PER INSTANCE: 0.009491\n",
      "DERIVATIVE LOSS: -1.009536\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.009491\n",
      "EPOCH 9\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.01706483 -0.21897627  0.        ]\n",
      " [-0.54772216  0.06135303  0.        ]\n",
      " [ 1.94917891  0.75766211  0.        ]]\n",
      "[]\n",
      "[[-1.92696616 -0.94133878]\n",
      " [-1.02244142 -0.70361589]\n",
      " [-1.60804001  0.27499612]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0094458776944937022, 0.99055412230550621]\n",
      "LOSS PER INSTANCE: 0.009491\n",
      "DERIVATIVE LOSS: -1.009536\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.009491\n",
      "EPOCH 10\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.01706483 -0.21897627  0.        ]\n",
      " [-0.54772216  0.06135303  0.        ]\n",
      " [ 1.94917891  0.75766211  0.        ]]\n",
      "[]\n",
      "[[-1.92696616 -0.94133878]\n",
      " [-1.02244142 -0.70361589]\n",
      " [-1.60804001  0.27499612]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0094458776944937022, 0.99055412230550621]\n",
      "LOSS PER INSTANCE: 0.009491\n",
      "DERIVATIVE LOSS: -1.009536\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.009491\n",
      "EPOCH 11\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.01706483 -0.21897627  0.        ]\n",
      " [-0.54772216  0.06135303  0.        ]\n",
      " [ 1.94917891  0.75766211  0.        ]]\n",
      "[]\n",
      "[[-1.92696616 -0.94133878]\n",
      " [-1.02244142 -0.70361589]\n",
      " [-1.60804001  0.27499612]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0094458776944937022, 0.99055412230550621]\n",
      "LOSS PER INSTANCE: 0.009491\n",
      "DERIVATIVE LOSS: -1.009536\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.009491\n",
      "EPOCH 12\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.01706483 -0.21897627  0.        ]\n",
      " [-0.54772216  0.06135303  0.        ]\n",
      " [ 1.94917891  0.75766211  0.        ]]\n",
      "[]\n",
      "[[-1.92696616 -0.94133878]\n",
      " [-1.02244142 -0.70361589]\n",
      " [-1.60804001  0.27499612]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0094458776944937022, 0.99055412230550621]\n",
      "LOSS PER INSTANCE: 0.009491\n",
      "DERIVATIVE LOSS: -1.009536\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.009491\n",
      "EPOCH 13\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.01706483 -0.21897627  0.        ]\n",
      " [-0.54772216  0.06135303  0.        ]\n",
      " [ 1.94917891  0.75766211  0.        ]]\n",
      "[]\n",
      "[[-1.92696616 -0.94133878]\n",
      " [-1.02244142 -0.70361589]\n",
      " [-1.60804001  0.27499612]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0094458776944937022, 0.99055412230550621]\n",
      "LOSS PER INSTANCE: 0.009491\n",
      "DERIVATIVE LOSS: -1.009536\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.009491\n",
      "EPOCH 14\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.01706483 -0.21897627  0.        ]\n",
      " [-0.54772216  0.06135303  0.        ]\n",
      " [ 1.94917891  0.75766211  0.        ]]\n",
      "[]\n",
      "[[-1.92696616 -0.94133878]\n",
      " [-1.02244142 -0.70361589]\n",
      " [-1.60804001  0.27499612]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0094458776944937022, 0.99055412230550621]\n",
      "LOSS PER INSTANCE: 0.009491\n",
      "DERIVATIVE LOSS: -1.009536\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.009491\n",
      "EPOCH 15\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.01706483 -0.21897627  0.        ]\n",
      " [-0.54772216  0.06135303  0.        ]\n",
      " [ 1.94917891  0.75766211  0.        ]]\n",
      "[]\n",
      "[[-1.92696616 -0.94133878]\n",
      " [-1.02244142 -0.70361589]\n",
      " [-1.60804001  0.27499612]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0094458776944937022, 0.99055412230550621]\n",
      "LOSS PER INSTANCE: 0.009491\n",
      "DERIVATIVE LOSS: -1.009536\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.009491\n",
      "EPOCH 16\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.01706483 -0.21897627  0.        ]\n",
      " [-0.54772216  0.06135303  0.        ]\n",
      " [ 1.94917891  0.75766211  0.        ]]\n",
      "[]\n",
      "[[-1.92696616 -0.94133878]\n",
      " [-1.02244142 -0.70361589]\n",
      " [-1.60804001  0.27499612]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0094458776944937022, 0.99055412230550621]\n",
      "LOSS PER INSTANCE: 0.009491\n",
      "DERIVATIVE LOSS: -1.009536\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.009491\n",
      "EPOCH 17\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.01706483 -0.21897627  0.        ]\n",
      " [-0.54772216  0.06135303  0.        ]\n",
      " [ 1.94917891  0.75766211  0.        ]]\n",
      "[]\n",
      "[[-1.92696616 -0.94133878]\n",
      " [-1.02244142 -0.70361589]\n",
      " [-1.60804001  0.27499612]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0094458776944937022, 0.99055412230550621]\n",
      "LOSS PER INSTANCE: 0.009491\n",
      "DERIVATIVE LOSS: -1.009536\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.009491\n",
      "EPOCH 18\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.01706483 -0.21897627  0.        ]\n",
      " [-0.54772216  0.06135303  0.        ]\n",
      " [ 1.94917891  0.75766211  0.        ]]\n",
      "[]\n",
      "[[-1.92696616 -0.94133878]\n",
      " [-1.02244142 -0.70361589]\n",
      " [-1.60804001  0.27499612]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0094458776944937022, 0.99055412230550621]\n",
      "LOSS PER INSTANCE: 0.009491\n",
      "DERIVATIVE LOSS: -1.009536\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.009491\n",
      "EPOCH 19\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.01706483 -0.21897627  0.        ]\n",
      " [-0.54772216  0.06135303  0.        ]\n",
      " [ 1.94917891  0.75766211  0.        ]]\n",
      "[]\n",
      "[[-1.92696616 -0.94133878]\n",
      " [-1.02244142 -0.70361589]\n",
      " [-1.60804001  0.27499612]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0094458776944937022, 0.99055412230550621]\n",
      "LOSS PER INSTANCE: 0.009491\n",
      "DERIVATIVE LOSS: -1.009536\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.009491\n",
      "EPOCH 20\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.01706483 -0.21897627  0.        ]\n",
      " [-0.54772216  0.06135303  0.        ]\n",
      " [ 1.94917891  0.75766211  0.        ]]\n",
      "[]\n",
      "[[-1.92696616 -0.94133878]\n",
      " [-1.02244142 -0.70361589]\n",
      " [-1.60804001  0.27499612]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0094458776944937022, 0.99055412230550621]\n",
      "LOSS PER INSTANCE: 0.009491\n",
      "DERIVATIVE LOSS: -1.009536\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.009491\n",
      "EPOCH 21\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.01706483 -0.21897627  0.        ]\n",
      " [-0.54772216  0.06135303  0.        ]\n",
      " [ 1.94917891  0.75766211  0.        ]]\n",
      "[]\n",
      "[[-1.92696616 -0.94133878]\n",
      " [-1.02244142 -0.70361589]\n",
      " [-1.60804001  0.27499612]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0094458776944937022, 0.99055412230550621]\n",
      "LOSS PER INSTANCE: 0.009491\n",
      "DERIVATIVE LOSS: -1.009536\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.009491\n",
      "EPOCH 22\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.01706483 -0.21897627  0.        ]\n",
      " [-0.54772216  0.06135303  0.        ]\n",
      " [ 1.94917891  0.75766211  0.        ]]\n",
      "[]\n",
      "[[-1.92696616 -0.94133878]\n",
      " [-1.02244142 -0.70361589]\n",
      " [-1.60804001  0.27499612]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0094458776944937022, 0.99055412230550621]\n",
      "LOSS PER INSTANCE: 0.009491\n",
      "DERIVATIVE LOSS: -1.009536\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.009491\n",
      "EPOCH 23\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.01706483 -0.21897627  0.        ]\n",
      " [-0.54772216  0.06135303  0.        ]\n",
      " [ 1.94917891  0.75766211  0.        ]]\n",
      "[]\n",
      "[[-1.92696616 -0.94133878]\n",
      " [-1.02244142 -0.70361589]\n",
      " [-1.60804001  0.27499612]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0094458776944937022, 0.99055412230550621]\n",
      "LOSS PER INSTANCE: 0.009491\n",
      "DERIVATIVE LOSS: -1.009536\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.009491\n",
      "EPOCH 24\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.01706483 -0.21897627  0.        ]\n",
      " [-0.54772216  0.06135303  0.        ]\n",
      " [ 1.94917891  0.75766211  0.        ]]\n",
      "[]\n",
      "[[-1.92696616 -0.94133878]\n",
      " [-1.02244142 -0.70361589]\n",
      " [-1.60804001  0.27499612]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0094458776944937022, 0.99055412230550621]\n",
      "LOSS PER INSTANCE: 0.009491\n",
      "DERIVATIVE LOSS: -1.009536\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.009491\n",
      "EPOCH 25\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.01706483 -0.21897627  0.        ]\n",
      " [-0.54772216  0.06135303  0.        ]\n",
      " [ 1.94917891  0.75766211  0.        ]]\n",
      "[]\n",
      "[[-1.92696616 -0.94133878]\n",
      " [-1.02244142 -0.70361589]\n",
      " [-1.60804001  0.27499612]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0094458776944937022, 0.99055412230550621]\n",
      "LOSS PER INSTANCE: 0.009491\n",
      "DERIVATIVE LOSS: -1.009536\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.009491\n",
      "EPOCH 26\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.01706483 -0.21897627  0.        ]\n",
      " [-0.54772216  0.06135303  0.        ]\n",
      " [ 1.94917891  0.75766211  0.        ]]\n",
      "[]\n",
      "[[-1.92696616 -0.94133878]\n",
      " [-1.02244142 -0.70361589]\n",
      " [-1.60804001  0.27499612]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0094458776944937022, 0.99055412230550621]\n",
      "LOSS PER INSTANCE: 0.009491\n",
      "DERIVATIVE LOSS: -1.009536\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.009491\n",
      "EPOCH 27\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.01706483 -0.21897627  0.        ]\n",
      " [-0.54772216  0.06135303  0.        ]\n",
      " [ 1.94917891  0.75766211  0.        ]]\n",
      "[]\n",
      "[[-1.92696616 -0.94133878]\n",
      " [-1.02244142 -0.70361589]\n",
      " [-1.60804001  0.27499612]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0094458776944937022, 0.99055412230550621]\n",
      "LOSS PER INSTANCE: 0.009491\n",
      "DERIVATIVE LOSS: -1.009536\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.009491\n",
      "EPOCH 28\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.01706483 -0.21897627  0.        ]\n",
      " [-0.54772216  0.06135303  0.        ]\n",
      " [ 1.94917891  0.75766211  0.        ]]\n",
      "[]\n",
      "[[-1.92696616 -0.94133878]\n",
      " [-1.02244142 -0.70361589]\n",
      " [-1.60804001  0.27499612]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0094458776944937022, 0.99055412230550621]\n",
      "LOSS PER INSTANCE: 0.009491\n",
      "DERIVATIVE LOSS: -1.009536\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.009491\n",
      "EPOCH 29\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.01706483 -0.21897627  0.        ]\n",
      " [-0.54772216  0.06135303  0.        ]\n",
      " [ 1.94917891  0.75766211  0.        ]]\n",
      "[]\n",
      "[[-1.92696616 -0.94133878]\n",
      " [-1.02244142 -0.70361589]\n",
      " [-1.60804001  0.27499612]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0094458776944937022, 0.99055412230550621]\n",
      "LOSS PER INSTANCE: 0.009491\n",
      "DERIVATIVE LOSS: -1.009536\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.009491\n",
      "EPOCH 30\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.01706483 -0.21897627  0.        ]\n",
      " [-0.54772216  0.06135303  0.        ]\n",
      " [ 1.94917891  0.75766211  0.        ]]\n",
      "[]\n",
      "[[-1.92696616 -0.94133878]\n",
      " [-1.02244142 -0.70361589]\n",
      " [-1.60804001  0.27499612]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0094458776944937022, 0.99055412230550621]\n",
      "LOSS PER INSTANCE: 0.009491\n",
      "DERIVATIVE LOSS: -1.009536\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.009491\n",
      "EPOCH 31\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.01706483 -0.21897627  0.        ]\n",
      " [-0.54772216  0.06135303  0.        ]\n",
      " [ 1.94917891  0.75766211  0.        ]]\n",
      "[]\n",
      "[[-1.92696616 -0.94133878]\n",
      " [-1.02244142 -0.70361589]\n",
      " [-1.60804001  0.27499612]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0094458776944937022, 0.99055412230550621]\n",
      "LOSS PER INSTANCE: 0.009491\n",
      "DERIVATIVE LOSS: -1.009536\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.009491\n",
      "EPOCH 32\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.01706483 -0.21897627  0.        ]\n",
      " [-0.54772216  0.06135303  0.        ]\n",
      " [ 1.94917891  0.75766211  0.        ]]\n",
      "[]\n",
      "[[-1.92696616 -0.94133878]\n",
      " [-1.02244142 -0.70361589]\n",
      " [-1.60804001  0.27499612]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0094458776944937022, 0.99055412230550621]\n",
      "LOSS PER INSTANCE: 0.009491\n",
      "DERIVATIVE LOSS: -1.009536\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.009491\n",
      "EPOCH 33\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.01706483 -0.21897627  0.        ]\n",
      " [-0.54772216  0.06135303  0.        ]\n",
      " [ 1.94917891  0.75766211  0.        ]]\n",
      "[]\n",
      "[[-1.92696616 -0.94133878]\n",
      " [-1.02244142 -0.70361589]\n",
      " [-1.60804001  0.27499612]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0094458776944937022, 0.99055412230550621]\n",
      "LOSS PER INSTANCE: 0.009491\n",
      "DERIVATIVE LOSS: -1.009536\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.009491\n",
      "EPOCH 34\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.01706483 -0.21897627  0.        ]\n",
      " [-0.54772216  0.06135303  0.        ]\n",
      " [ 1.94917891  0.75766211  0.        ]]\n",
      "[]\n",
      "[[-1.92696616 -0.94133878]\n",
      " [-1.02244142 -0.70361589]\n",
      " [-1.60804001  0.27499612]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0094458776944937022, 0.99055412230550621]\n",
      "LOSS PER INSTANCE: 0.009491\n",
      "DERIVATIVE LOSS: -1.009536\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.009491\n",
      "EPOCH 35\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.01706483 -0.21897627  0.        ]\n",
      " [-0.54772216  0.06135303  0.        ]\n",
      " [ 1.94917891  0.75766211  0.        ]]\n",
      "[]\n",
      "[[-1.92696616 -0.94133878]\n",
      " [-1.02244142 -0.70361589]\n",
      " [-1.60804001  0.27499612]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0094458776944937022, 0.99055412230550621]\n",
      "LOSS PER INSTANCE: 0.009491\n",
      "DERIVATIVE LOSS: -1.009536\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.009491\n",
      "EPOCH 36\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.01706483 -0.21897627  0.        ]\n",
      " [-0.54772216  0.06135303  0.        ]\n",
      " [ 1.94917891  0.75766211  0.        ]]\n",
      "[]\n",
      "[[-1.92696616 -0.94133878]\n",
      " [-1.02244142 -0.70361589]\n",
      " [-1.60804001  0.27499612]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0094458776944937022, 0.99055412230550621]\n",
      "LOSS PER INSTANCE: 0.009491\n",
      "DERIVATIVE LOSS: -1.009536\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.009491\n",
      "EPOCH 37\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.01706483 -0.21897627  0.        ]\n",
      " [-0.54772216  0.06135303  0.        ]\n",
      " [ 1.94917891  0.75766211  0.        ]]\n",
      "[]\n",
      "[[-1.92696616 -0.94133878]\n",
      " [-1.02244142 -0.70361589]\n",
      " [-1.60804001  0.27499612]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0094458776944937022, 0.99055412230550621]\n",
      "LOSS PER INSTANCE: 0.009491\n",
      "DERIVATIVE LOSS: -1.009536\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.009491\n",
      "EPOCH 38\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.01706483 -0.21897627  0.        ]\n",
      " [-0.54772216  0.06135303  0.        ]\n",
      " [ 1.94917891  0.75766211  0.        ]]\n",
      "[]\n",
      "[[-1.92696616 -0.94133878]\n",
      " [-1.02244142 -0.70361589]\n",
      " [-1.60804001  0.27499612]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0094458776944937022, 0.99055412230550621]\n",
      "LOSS PER INSTANCE: 0.009491\n",
      "DERIVATIVE LOSS: -1.009536\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.009491\n",
      "EPOCH 39\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.01706483 -0.21897627  0.        ]\n",
      " [-0.54772216  0.06135303  0.        ]\n",
      " [ 1.94917891  0.75766211  0.        ]]\n",
      "[]\n",
      "[[-1.92696616 -0.94133878]\n",
      " [-1.02244142 -0.70361589]\n",
      " [-1.60804001  0.27499612]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0094458776944937022, 0.99055412230550621]\n",
      "LOSS PER INSTANCE: 0.009491\n",
      "DERIVATIVE LOSS: -1.009536\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.009491\n",
      "EPOCH 40\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.01706483 -0.21897627  0.        ]\n",
      " [-0.54772216  0.06135303  0.        ]\n",
      " [ 1.94917891  0.75766211  0.        ]]\n",
      "[]\n",
      "[[-1.92696616 -0.94133878]\n",
      " [-1.02244142 -0.70361589]\n",
      " [-1.60804001  0.27499612]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0094458776944937022, 0.99055412230550621]\n",
      "LOSS PER INSTANCE: 0.009491\n",
      "DERIVATIVE LOSS: -1.009536\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.009491\n",
      "EPOCH 41\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.01706483 -0.21897627  0.        ]\n",
      " [-0.54772216  0.06135303  0.        ]\n",
      " [ 1.94917891  0.75766211  0.        ]]\n",
      "[]\n",
      "[[-1.92696616 -0.94133878]\n",
      " [-1.02244142 -0.70361589]\n",
      " [-1.60804001  0.27499612]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0094458776944937022, 0.99055412230550621]\n",
      "LOSS PER INSTANCE: 0.009491\n",
      "DERIVATIVE LOSS: -1.009536\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.009491\n",
      "EPOCH 42\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.01706483 -0.21897627  0.        ]\n",
      " [-0.54772216  0.06135303  0.        ]\n",
      " [ 1.94917891  0.75766211  0.        ]]\n",
      "[]\n",
      "[[-1.92696616 -0.94133878]\n",
      " [-1.02244142 -0.70361589]\n",
      " [-1.60804001  0.27499612]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0094458776944937022, 0.99055412230550621]\n",
      "LOSS PER INSTANCE: 0.009491\n",
      "DERIVATIVE LOSS: -1.009536\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.009491\n",
      "EPOCH 43\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.01706483 -0.21897627  0.        ]\n",
      " [-0.54772216  0.06135303  0.        ]\n",
      " [ 1.94917891  0.75766211  0.        ]]\n",
      "[]\n",
      "[[-1.92696616 -0.94133878]\n",
      " [-1.02244142 -0.70361589]\n",
      " [-1.60804001  0.27499612]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0094458776944937022, 0.99055412230550621]\n",
      "LOSS PER INSTANCE: 0.009491\n",
      "DERIVATIVE LOSS: -1.009536\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.009491\n",
      "EPOCH 44\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.01706483 -0.21897627  0.        ]\n",
      " [-0.54772216  0.06135303  0.        ]\n",
      " [ 1.94917891  0.75766211  0.        ]]\n",
      "[]\n",
      "[[-1.92696616 -0.94133878]\n",
      " [-1.02244142 -0.70361589]\n",
      " [-1.60804001  0.27499612]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0094458776944937022, 0.99055412230550621]\n",
      "LOSS PER INSTANCE: 0.009491\n",
      "DERIVATIVE LOSS: -1.009536\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.009491\n",
      "EPOCH 45\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.01706483 -0.21897627  0.        ]\n",
      " [-0.54772216  0.06135303  0.        ]\n",
      " [ 1.94917891  0.75766211  0.        ]]\n",
      "[]\n",
      "[[-1.92696616 -0.94133878]\n",
      " [-1.02244142 -0.70361589]\n",
      " [-1.60804001  0.27499612]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0094458776944937022, 0.99055412230550621]\n",
      "LOSS PER INSTANCE: 0.009491\n",
      "DERIVATIVE LOSS: -1.009536\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.009491\n",
      "EPOCH 46\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.01706483 -0.21897627  0.        ]\n",
      " [-0.54772216  0.06135303  0.        ]\n",
      " [ 1.94917891  0.75766211  0.        ]]\n",
      "[]\n",
      "[[-1.92696616 -0.94133878]\n",
      " [-1.02244142 -0.70361589]\n",
      " [-1.60804001  0.27499612]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0094458776944937022, 0.99055412230550621]\n",
      "LOSS PER INSTANCE: 0.009491\n",
      "DERIVATIVE LOSS: -1.009536\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.009491\n",
      "EPOCH 47\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.01706483 -0.21897627  0.        ]\n",
      " [-0.54772216  0.06135303  0.        ]\n",
      " [ 1.94917891  0.75766211  0.        ]]\n",
      "[]\n",
      "[[-1.92696616 -0.94133878]\n",
      " [-1.02244142 -0.70361589]\n",
      " [-1.60804001  0.27499612]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0094458776944937022, 0.99055412230550621]\n",
      "LOSS PER INSTANCE: 0.009491\n",
      "DERIVATIVE LOSS: -1.009536\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.009491\n",
      "EPOCH 48\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.01706483 -0.21897627  0.        ]\n",
      " [-0.54772216  0.06135303  0.        ]\n",
      " [ 1.94917891  0.75766211  0.        ]]\n",
      "[]\n",
      "[[-1.92696616 -0.94133878]\n",
      " [-1.02244142 -0.70361589]\n",
      " [-1.60804001  0.27499612]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0094458776944937022, 0.99055412230550621]\n",
      "LOSS PER INSTANCE: 0.009491\n",
      "DERIVATIVE LOSS: -1.009536\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.009491\n",
      "EPOCH 49\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.01706483 -0.21897627  0.        ]\n",
      " [-0.54772216  0.06135303  0.        ]\n",
      " [ 1.94917891  0.75766211  0.        ]]\n",
      "[]\n",
      "[[-1.92696616 -0.94133878]\n",
      " [-1.02244142 -0.70361589]\n",
      " [-1.60804001  0.27499612]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0094458776944937022, 0.99055412230550621]\n",
      "LOSS PER INSTANCE: 0.009491\n",
      "DERIVATIVE LOSS: -1.009536\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.009491\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nclass Node(Object):\\n    def __init__(self):\\n        \\n    def \\n'"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class NN():\n",
    "    \"\"\"\n",
    "    Class for a neural network. Requires input/output sizes, number of hidden layers, and number of neurons\n",
    "    at each layer (we assume all hidden layers are of the same size)\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, num_HL, hidden_size, output_size):\n",
    "        # Initialize by setting random \n",
    "        self.input_size = input_size\n",
    "        self.hidden_layers = num_HL\n",
    "        # NOTE we are assuming all hidden layers are the same size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        # Activations for each neuron\n",
    "        # + 1 for bias neuron\n",
    "        self.activations_in = np.ones(self.input_size + 1)\n",
    "        # Hidden can comprise multiple layers, so we have a matrix\n",
    "        # + 1 for bias neuron\n",
    "        self.activations_hidden = np.ones((self.hidden_layers, self.hidden_size + 1))\n",
    "        self.activations_out = np.ones(self.output_size)\n",
    "        # Weights of all the edges, randomized for good results\n",
    "        # PLUS ONE FOR BIASES\n",
    "        self.weights_in = np.random.randn(self.input_size + 1, self.hidden_size)\n",
    "        self.weights_in = np.column_stack((self.weights_in, np.zeros(self.input_size + 1)))\n",
    "        # We will only have hidden weights if there are multiple hidden layers\n",
    "        if self.hidden_layers > 1:\n",
    "            self.weights_hidden = np.random.randn(self.hidden_layers - 1, self.hidden_size + 1, self.hidden_size + 1)\n",
    "            # Set the weights corresponding with next layers biases to 0\n",
    "            for weights in self.weights_hidden:\n",
    "                weights[-1] = 0.0\n",
    "        else:\n",
    "            self.weights_hidden = []\n",
    "        # No plus one for output, as it should not have a bias parameter\n",
    "        self.weights_out = np.random.randn(self.hidden_size + 1, self.output_size)\n",
    "        # To be valued when train() is called\n",
    "        self.learning_rate = 0.0\n",
    "\n",
    "        # Instantiate deltas for holding gradients\n",
    "        self.deltas_in = []\n",
    "        self.Deltas_hidden = []\n",
    "        self.deltas_out = []\n",
    "    \n",
    "    def _sigmoid(self, x):\n",
    "        \"\"\"\n",
    "        Sigmoid function for calculating a distribution over 2 classes\n",
    "        \"\"\"\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def _derivative_sigmoid(self, x):\n",
    "        \"\"\"\n",
    "        Derivative of the sigmoid function where x = the output of the sigmoid\n",
    "        \n",
    "        This can be used in backpropogation, wherein we would have \n",
    "        already computed the sigmoid in the forward pass, and we can draw upon its cached value\n",
    "        \"\"\"\n",
    "        return self._sigmoid(x) * (1.0 - self._sigmoid(x))\n",
    "    \n",
    "    def _softmax(self, x):\n",
    "        exponentials = [np.exp(p) for p in x]\n",
    "        denominator = sum(exponentials)\n",
    "        return [p / denominator for p in exponentials]\n",
    "    \n",
    "    def _relu(self, x):\n",
    "        \"\"\"\n",
    "        relu function used for activation\n",
    "        \"\"\"\n",
    "        return max(x, 0.0)\n",
    "    \n",
    "    def _derivative_relu(self, x):\n",
    "        \"\"\"\n",
    "        Derivative of the relu function, the input will be the output of the relu function.\n",
    "        This is because in practice we will have already performed this computation in the forward pass\n",
    "        so in the backward pass, we need to find its derivative drawing upon the cached relu(x).\n",
    "        \"\"\"\n",
    "        return 1 if x > 0.0 else 0.0\n",
    "    \n",
    "    def _binary_cross_ent(self, y_hat, y):\n",
    "        \"\"\"\n",
    "        This basically finds the negative of the log probability of class1 - its inverse\n",
    "        \"\"\"\n",
    "        return (-y * np.log(y_hat)) - ((1 - y) * np.log(1 - y_hat))\n",
    "    \n",
    "    def _negative_log_likelihood(self, y_hat):\n",
    "        return -np.log(y_hat)\n",
    "    \n",
    "    def _derivative_negative_log_likelihood(self, y_hat):\n",
    "        return -1/y_hat\n",
    "    \n",
    "    def _derivative_binary_cross_ent(self, y_hat, y):\n",
    "        \"\"\"\n",
    "        Derivative of binary cross-entropy\n",
    "        \n",
    "        This description is misleading. \n",
    "        This is the part of the partial derivative of binary cross-entropy \n",
    "        w.r.t the parameters of our function. In practice, the other part is \n",
    "        the dot product of this and the activations (activate(w, x))\n",
    "        \"\"\"\n",
    "        #return -(y / y_hat) - ((1 - y) / (1 - y_hat))\n",
    "        return (y_hat - y)\n",
    "\n",
    "    def _activate(self, x):\n",
    "        \"\"\"\n",
    "        RELU for non-linear activation function\n",
    "        \"\"\"\n",
    "        return self._relu(x)\n",
    "    \n",
    "    def _activate_vector(self, X):\n",
    "        \"\"\"\n",
    "        Run on a numpy vector\n",
    "        \"\"\"\n",
    "        activations = np.vectorize(self._activate)\n",
    "        return activations(X)\n",
    "    \n",
    "    def _derivative_activation(self, x):\n",
    "        \"\"\"\n",
    "        Compute the derivative of the activation function given the activation output\n",
    "        \n",
    "        x: activate(node)\n",
    "        \"\"\"\n",
    "        return self._derivative_relu(x)\n",
    "    \n",
    "    def _derivative_vector_activation(self, X):\n",
    "        \"\"\"\n",
    "        Derivative for each scalar in a numpy vector\n",
    "        \"\"\"\n",
    "        derivative_activations = np.vectorize(self._derivative_activation)\n",
    "        return derivative_activations(X)\n",
    "\n",
    "    def _loss(self, y_hat, y):\n",
    "        \"\"\"\n",
    "        y_hat: sofmax vector\n",
    "        y:     one-hot vector for the target\n",
    "        \n",
    "        Here we will plug in the negative_log_likelihood\n",
    "        in order to be able to compare the proability of our output at\n",
    "        the correct class, to 1.\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        Get the index of the correct class \n",
    "        (numpy will return a tuple of the index in each dimension)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Get the first (and only) dim, and the first (and only) index\n",
    "        i = np.where(y==1)[0][0]\n",
    "        return self._negative_log_likelihood(y_hat[i])\n",
    "    \n",
    "    def _derivative_loss(self, y_hat, y):\n",
    "        \"\"\"\n",
    "        This will be used in backprop for finding L'(output_layer_node)\n",
    "        \"\"\"\n",
    "        # Get the first (and only) dim, and the first (and only) index\n",
    "        i = np.where(y==1)[0][0]\n",
    "        return self._derivative_negative_log_likelihood(y_hat[i])\n",
    "    \n",
    "    def _targets_to_one_hots(self, targets):\n",
    "        \"\"\"\n",
    "        Interpret a vector of targets into a matrix\n",
    "        of one-hot representations\n",
    "        \"\"\"\n",
    "        # Get the number of unique target classes\n",
    "        num_classes = len(set(targets))\n",
    "        # Instantiate a matrix of one-hot vectors\n",
    "        # with one row per target, and one col per class\n",
    "        one_hots = np.zeros((len(targets), num_classes))\n",
    "        for i, one_hot in enumerate(one_hots):\n",
    "            # Set the one-hot vector to hae a 1 at its corresponding target slot\n",
    "            t = targets[i]\n",
    "            one_hot[t] = 1\n",
    "            \n",
    "        return one_hots\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Forward pass: Calculate the activations of each neuron\n",
    "        \"\"\"\n",
    "        if len(inputs) != self.input_size:\n",
    "          raise Exception(\"That is not the size of the input layer... try %i\" % self.input_size)\n",
    "        \n",
    "        # Set input activations, no need to actually calculate anything\n",
    "        for i, input in enumerate(inputs):\n",
    "            self.activations_in[i] = input\n",
    "        \n",
    "        # calculate the activations for each hidden layer\n",
    "        for h_layer_i in range(self.hidden_layers):\n",
    "            # Need to take previous layer activation value * weights for a given layer\n",
    "            # Starting with input layer X first hidden layer\n",
    "            if h_layer_i == 0:\n",
    "                \"\"\"\n",
    "                # Loop over the layer\n",
    "                for h_dim_j in range(self.hidden_size):\n",
    "                    # Loop over neurons in the layer before it\n",
    "                    for k in range(self.input_size):\n",
    "                        # Sum [f_k * w_k_j for k in input layer]\n",
    "                        self.activations_hidden[h_layer_i][h_dim_j] += self.activations_in[k] * self.weights_in[k][h_dim_j]\n",
    "                    # h(sum from above), aka run the nonlinear activation function\n",
    "                    self.activations_hidden[h_layer_i][h_dim_j] = self._activate(self.activations_hidden[h_layer_i][h_dim_j])\n",
    "                \"\"\"\n",
    "                # multiply the previous layer's activations by its weight vector for this layer's activations\n",
    "                self.activations_hidden[h_layer_i] = self.activations_in.T.dot(self.weights_in)\n",
    "                # Reset bias activation to 1.0\n",
    "                self.activations_hidden[h_layer_i][-1] = 1.0\n",
    "            else:\n",
    "                \"\"\"\n",
    "                if h_layer_i == 0:\n",
    "                    # Loop over the layer\n",
    "                    for h_dim_j in range(self.hidden_size):\n",
    "                        # Loop over neurons in the layer before it\n",
    "                        for k in range(self.hidden_size):\n",
    "                            # Sum [f_k * w_k_j for k in previous hidden layer]\n",
    "                            self.activations_hidden[h_layer_i][h_dim_j] += self.activations_hidden[h_layer_i - 1][k]\\\n",
    "                            * self.weights_hidden[h_layer_i][k][h_dim_j]\n",
    "                        # h(sum from above), aka run the nonlinear activation function\n",
    "                        self.activations_hidden[h_layer_i][h_dim_j] = self.activations_hidden[h_layer_i][h_dim_j]\n",
    "                \"\"\"\n",
    "                # multiply the previous layer's activations by its weight vector for this layer's activations\n",
    "                self.activations_hidden[h_layer_i] = self._activate_vector(self.activations_hidden[h_layer_i - 1]).T.dot(self.weights_hidden[h_layer_i - 1])\n",
    "                # Reset bias activation to 1.0\n",
    "                self.activations_hidden[h_layer_i][-1] = 1.0\n",
    "\n",
    "                \n",
    "        # Output activations will be the dot product of the final hidden layer, and the output weights\n",
    "        \"\"\"\n",
    "        for i in range(self.output_size):\n",
    "            for j in range(self.hidden_size):\n",
    "                print(self.weights_out)\n",
    "                print(self.weights_out[j][i])\n",
    "                self.activations_out[i] += self.activations_hidden[-1][j] * self.weights_out[j][i]\n",
    "            # h(sum from above), aka run the nonlinear activation function\n",
    "            self.activations_out[i] = self._activate(self.activations_out[i])\n",
    "        \"\"\"\n",
    "        # Activate the vector before, but do not activate the activations_out\n",
    "        self.activations_out = self._activate_vector(self.activations_hidden[-1]).T.dot(self.weights_out)\n",
    "        \n",
    "        #Print all of the weights, to see updates\n",
    "        \"\"\"\n",
    "        print(\"ACTIVATIONS\")\n",
    "        print(self.activations_in)\n",
    "        print(self.activations_hidden)\n",
    "        print(self.activations_out)\n",
    "        \"\"\"\n",
    "        print(\"WEIGHTS:\")\n",
    "        print(self.weights_in)\n",
    "        print(self.weights_hidden)\n",
    "        print(self.weights_out)\n",
    "\n",
    "    def backward(self, targets):\n",
    "        \"\"\"\n",
    "        Backpropogation for finding the partial derivative of the each node w.r.t the loss function,\n",
    "        and updating weights based on those gradients\n",
    "        \"\"\"\n",
    "        if len(targets) != len(self.activations_out):\n",
    "            raise Exception(\"Your labels are not the same size as your output layer!\")\n",
    "        # Calculate loss - there will be a value for each node in the output layer\n",
    "        # Take the simoid of the activations of the output layer, because we are doing 2 class classification\n",
    "        # ***If we have >2 classes, we would use softmax***\n",
    "        \"\"\"\n",
    "        print(\"ACTIVATIONS IN\")\n",
    "        print(self.activations_in)\n",
    "        \n",
    "        print(\"ACTIVATIONS HIDDEN\")\n",
    "        print(self.activations_hidden)\n",
    "        \n",
    "        print(\"ACTIVATIONS OUT\")\n",
    "        print(self.activations_out)\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"SOFTMAX_LAYER\")\n",
    "        print(self._softmax(self.activations_out))\n",
    "        \"\"\"\n",
    "        print(\"TARGETS\")\n",
    "        print(targets)\n",
    "        \"\"\"\n",
    "        loss = self._loss(self._softmax(self.activations_out), targets)\n",
    "        \n",
    "        \"\"\"\n",
    "        Now we need to calculate the partial derivative of the loss w.r.t each weight.\n",
    "        Think of this as finding the amount that each node contributes to a change in the final loss.\n",
    "        \n",
    "        Each node has a value \"delta\", which represents the partial derivative of the loss w.r.t. its value:\n",
    "        Use the partial derivative of the loss function, in our case binary cross-entropy\n",
    "        \"\"\"\n",
    "        self.deltas_out = np.zeros([self.output_size])\n",
    "        derivative_loss = self._derivative_loss(self._softmax(self.activations_out), targets)\n",
    "        print(\"LOSS PER INSTANCE: %2f\" % loss)\n",
    "        print(\"DERIVATIVE LOSS: %2f\" % derivative_loss)\n",
    "        for i, activation_out in enumerate(self.activations_out):\n",
    "            self.deltas_out[i] = derivative_loss * self._derivative_activation(activation_out)\n",
    "        \n",
    "        \"\"\"\n",
    "        Find derivative of activation (activation was found in the forward pass) * derivative of the inner function,\n",
    "        which is the parameter w\n",
    "        \"\"\"\n",
    "        self.Deltas_hidden = np.zeros([self.hidden_layers, self.hidden_size + 1])\n",
    "        ##############\n",
    "        #####TODO Needs to go in reverse if we have multiple hidden\n",
    "        for h_layer_i in range(self.hidden_layers):\n",
    "            # If it is the last hidden layer, then we look at the activations and deltas\n",
    "            # of the output layer, not the next hidden layer\n",
    "            if h_layer_i == self.hidden_layers - 1:\n",
    "                # Loop over each in hidden activation, +1 for bias\n",
    "                for h_dim_j in range(self.hidden_size + 1):\n",
    "                    for k, delta_out in enumerate(self.deltas_out):\n",
    "                        self.Deltas_hidden[h_layer_i][h_dim_j] += delta_out * self._derivative_activation(self.activations_out[k]) * self.weights_out[h_dim_j][k]\n",
    "            else:\n",
    "                # Do the same to find the hidden deltas\n",
    "                for h_dim_j in range(self.hidden_size + 1):\n",
    "                    for k, delta_h in enumerate(self.Deltas_hidden[h_layer_i + 1]):\n",
    "                        self.Deltas_hidden[h_layer_i][h_dim_j] += delta_h * self._derivative_activation(self.activations_hidden[h_layer_i + 1][k]) * self.weights_hidden[h_layer_i][h_dim_j][k]\n",
    "                        \n",
    "        \"\"\"\n",
    "        Now just do the same for L'(input layer)\n",
    "        \"\"\"\n",
    "        self.deltas_in = np.zeros([self.input_size+1])\n",
    "        #### Need deltas_hidden[0].dot(der_act_hidden[0] * weights_in)\n",
    "        # Loop over each in input activation, +1 for bias\n",
    "        #for dim_i in range(self.input_size + 1):\n",
    "        #    for k, delta_h in enumerate(self.Deltas_hidden[0]):\n",
    "        #        self.deltas_in[dim_i] += delta_h * self._derivative_activation(self.activations_hidden[0][k]) * self.weights_in[dim_i][k]\n",
    "        \n",
    "        self.update_weights()\n",
    "        return loss\n",
    "        \n",
    "    def update_weights(self):\n",
    "        print(\"UPDATING WEIGHTS\")\n",
    "        # Now we can use the deltas to adjust each weight by L'(w_i_j)\n",
    "        # These weights are the edges shared between last hidden layer, and output layer\n",
    "        # Rows of weights_out correponds with length of last hidden layer\n",
    "        for i in range(len(self.weights_out)):\n",
    "            # Cols of weights_out correspinds with length of output layer\n",
    "            for j in range(len(self.weights_out[i])):\n",
    "                self.weights_out[i][j] -= self._activate(self.activations_hidden[-1][i])\\\n",
    "                * self._derivative_activation(self.activations_out[j])\\\n",
    "                * self.deltas_out[j]\\\n",
    "                * self.learning_rate\n",
    "                    \n",
    "        # Loop over each hidden layer\n",
    "        for w_i in reversed(range(len(self.weights_hidden))):\n",
    "            # Rows (i) in the weights for this layer will correspond to the size of the layer BEFORE (hidden or input)\n",
    "            for i in range(len(self.weights_hidden[w_i])):\n",
    "                # Cols (j) in these weights will correspond to the size of hidden layer w_i\n",
    "                for j in range(len(self.weights_hidden[w_i][i])):\n",
    "                    # We do not want to update the dummy 0 weight going TO the extra bias dimension\n",
    "                    if j == len(self.weights_hidden[w_i][i]) - 1:\n",
    "                        continue\n",
    "                    else:\n",
    "                        # + 1 for layer before, because we are looping in reverse\n",
    "                        self.weights_hidden[w_i][i][j] -= self._activate(self.activations_hidden[w_i + 1][i])\\\n",
    "                        * self._derivative_activation(self.activations_hidden[w_i][j])\\\n",
    "                        * self.Deltas_hidden[w_i][j]\\\n",
    "                        * self.learning_rate\n",
    "                        \n",
    "            #self.weights_hidden[w_i] -= self.activations_hidden[w_i].T.dot(self.Deltas_hidden[w_i]) * self.learning_rate\n",
    "        # Rows (i) of weights_in corresponds to size of the input layer\n",
    "        for i in range(len(self.weights_in)):\n",
    "            # Cols (j) corresponds to size of the first hidden layer (layer above input layer)\n",
    "            for j in range(len(self.weights_in[i])):\n",
    "                # We do not want to update the dummy 0 weight going TO the extra bias dimension\n",
    "                if j == len(self.weights_in[i]) - 1:\n",
    "                    continue\n",
    "                else:\n",
    "                    \"\"\"\n",
    "                    print(\"act, deriv_act, delta, weight update val\")\n",
    "                    print(self.activations_in[i])\n",
    "                    print(self._derivative_activation(self.activations_hidden[0][j]))\n",
    "                    print(self.Deltas_hidden[0][j])\n",
    "                    print(self.activations_in[i]\\\n",
    "                    * self._derivative_activation(self.activations_hidden[0][j])\\\n",
    "                    * self.Deltas_hidden[0][j]\\\n",
    "                    * self.learning_rate)\n",
    "                    \"\"\"\n",
    "                    \n",
    "                    self.weights_in[i][j] -= self.activations_in[i]\\\n",
    "                    * self._derivative_activation(self.activations_hidden[0][j])\\\n",
    "                    * self.Deltas_hidden[0][j]\\\n",
    "                    * self.learning_rate\n",
    "    \n",
    "    def train(self, inputs, targets, epochs=50, lr=.01):\n",
    "        self.learning_rate = lr\n",
    "        one_hot_targets = self._targets_to_one_hots(targets)\n",
    "        for e in range(epochs):\n",
    "            print(\"EPOCH %i\" % e)\n",
    "            \"\"\"\n",
    "            SGD - randomize the order of the training samples, and \n",
    "            \"\"\"\n",
    "            in_out = list(zip(inputs, one_hot_targets))\n",
    "            random.shuffle(in_out)\n",
    "            # For tracking average loss over SGD, just for logging\n",
    "            losses = []\n",
    "            \n",
    "            for inp, target in in_out:\n",
    "                if inp == [-1, -1]:\n",
    "                    print(\"TARGET: \")\n",
    "                    print(target)\n",
    "                    self.forward(inp)\n",
    "                    losses.append(self.backward(target))\n",
    "\n",
    "            print(\"LOSS: %2f\" % (sum(losses)/len(losses)))\n",
    "            \n",
    "\"\"\"\n",
    "Note that the 4th param, the size of the output layer, should be the\n",
    "number of classes\n",
    "\"\"\"\n",
    "MLP = NN(2, 1, 2, 2)\n",
    "xor_inputs = [[1, 1], [-1, 1], [-1, -1], [1, -1]]\n",
    "xor_labels = ([1, 0, 1, 0])\n",
    "MLP.train(xor_inputs, xor_labels)\n",
    "\"\"\"\n",
    "class Node(Object):\n",
    "    def __init__(self):\n",
    "        \n",
    "    def \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.37334211 -1.04700271  0.        ]\n",
      " [ 1.77345667  0.78435871  0.        ]\n",
      " [ 0.02289695 -1.0850001   0.        ]]\n",
      "[]\n",
      "[[-0.73416315 -0.12838877]\n",
      " [-0.14478656 -1.09944542]\n",
      " [-0.72896166  0.93786627]]\n",
      "SOFTMAX_LAYER\n",
      "[0.27055274907148041, 0.72944725092851959]\n",
      "LOSS PER INSTANCE: 0.315468\n",
      "DERIVATIVE LOSS: -1.370901\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.315468\n",
      "EPOCH 1\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.37509722 -1.04069823  0.        ]\n",
      " [ 1.77521177  0.7906632   0.        ]\n",
      " [ 0.02114185 -1.09130459  0.        ]]\n",
      "[]\n",
      "[[-0.73194048 -0.12579391]\n",
      " [-0.13843328 -1.09202825]\n",
      " [-0.71374655  0.95562922]]\n",
      "SOFTMAX_LAYER\n",
      "[0.26942258001688779, 0.73057741998311221]\n",
      "LOSS PER INSTANCE: 0.313920\n",
      "DERIVATIVE LOSS: -1.368780\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.313920\n",
      "EPOCH 2\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.37684295 -1.03454844  0.        ]\n",
      " [ 1.77695751  0.79681298  0.        ]\n",
      " [ 0.01939611 -1.09745437  0.        ]]\n",
      "[]\n",
      "[[-0.7297119  -0.1232328 ]\n",
      " [-0.13211684 -1.08476934]\n",
      " [-0.69841901  0.97324378]]\n",
      "SOFTMAX_LAYER\n",
      "[0.26836565431959392, 0.73163434568040608]\n",
      "LOSS PER INSTANCE: 0.312474\n",
      "DERIVATIVE LOSS: -1.366803\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.312474\n",
      "EPOCH 3\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.37857943 -1.02855045  0.        ]\n",
      " [ 1.77869398  0.80281097  0.        ]\n",
      " [ 0.01765964 -1.10345236  0.        ]]\n",
      "[]\n",
      "[[-0.72747751 -0.12070532]\n",
      " [-0.12583596 -1.07766459]\n",
      " [-0.68297946  0.99070855]]\n",
      "SOFTMAX_LAYER\n",
      "[0.26738039632200855, 0.7326196036779915]\n",
      "LOSS PER INSTANCE: 0.311129\n",
      "DERIVATIVE LOSS: -1.364965\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.311129\n",
      "EPOCH 4\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.38030676 -1.02270129  0.        ]\n",
      " [ 1.78042131  0.80866014  0.        ]\n",
      " [ 0.01593231 -1.10930153  0.        ]]\n",
      "[]\n",
      "[[-0.72523744 -0.11821132]\n",
      " [-0.11958939 -1.07070991]\n",
      " [-0.66742837  1.0080225 ]]\n",
      "SOFTMAX_LAYER\n",
      "[0.26646524671876892, 0.73353475328123108]\n",
      "LOSS PER INSTANCE: 0.309880\n",
      "DERIVATIVE LOSS: -1.363262\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.309880\n",
      "EPOCH 5\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.38202505 -1.01699795  0.        ]\n",
      " [ 1.78213961  0.81436348  0.        ]\n",
      " [ 0.01421401 -1.11500487  0.        ]]\n",
      "[]\n",
      "[[-0.72299182 -0.1157506 ]\n",
      " [-0.11337591 -1.06390126]\n",
      " [-0.65176624  1.02518488]]\n",
      "SOFTMAX_LAYER\n",
      "[0.26561866747117541, 0.73438133252882465]\n",
      "LOSS PER INSTANCE: 0.308727\n",
      "DERIVATIVE LOSS: -1.361690\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.308727\n",
      "EPOCH 6\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.38373443 -1.0114374   0.        ]\n",
      " [ 1.78384898  0.81992403  0.        ]\n",
      " [ 0.01250464 -1.12056541  0.        ]]\n",
      "[]\n",
      "[[-0.72074077 -0.1133229 ]\n",
      " [-0.10719434 -1.0572346 ]\n",
      " [-0.63599363  1.04219521]]\n",
      "SOFTMAX_LAYER\n",
      "[0.26483914572916362, 0.73516085427083644]\n",
      "LOSS PER INSTANCE: 0.307666\n",
      "DERIVATIVE LOSS: -1.360247\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.307666\n",
      "EPOCH 7\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.38543498 -1.0060166   0.        ]\n",
      " [ 1.78554953  0.82534483  0.        ]\n",
      " [ 0.01080409 -1.12598621  0.        ]]\n",
      "[]\n",
      "[[-0.71848443 -0.11092797]\n",
      " [-0.10104353 -1.05070597]\n",
      " [-0.62011115  1.05905329]]\n",
      "SOFTMAX_LAYER\n",
      "[0.26412519688181574, 0.73587480311818421]\n",
      "LOSS PER INSTANCE: 0.306695\n",
      "DERIVATIVE LOSS: -1.358927\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.306695\n",
      "EPOCH 8\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.38712681 -1.00073252  0.        ]\n",
      " [ 1.78724136  0.83062891  0.        ]\n",
      " [ 0.00911226 -1.1312703   0.        ]]\n",
      "[]\n",
      "[[-0.71622295 -0.10856549]\n",
      " [-0.09492237 -1.04431146]\n",
      " [-0.60411947  1.07575912]]\n",
      "SOFTMAX_LAYER\n",
      "[0.26347536684730199, 0.73652463315269812]\n",
      "LOSS PER INSTANCE: 0.305813\n",
      "DERIVATIVE LOSS: -1.357728\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.305813\n",
      "EPOCH 9\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.38881002 -0.99558213  0.        ]\n",
      " [ 1.78892457  0.83577929  0.        ]\n",
      " [ 0.00742905 -1.13642068  0.        ]]\n",
      "[]\n",
      "[[-0.71395646 -0.10623514]\n",
      " [-0.08882981 -1.03804723]\n",
      " [-0.58801931  1.09231293]]\n",
      "SOFTMAX_LAYER\n",
      "[0.26288823370301695, 0.73711176629698305]\n",
      "LOSS PER INSTANCE: 0.305016\n",
      "DERIVATIVE LOSS: -1.356646\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.305016\n",
      "EPOCH 10\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.39048469 -0.99056245  0.        ]\n",
      " [ 1.79059924  0.84079897  0.        ]\n",
      " [ 0.00575438 -1.14144036  0.        ]]\n",
      "[]\n",
      "[[-0.71168513 -0.10393657]\n",
      " [-0.0827648  -1.0319095 ]\n",
      " [-0.57181146  1.10871512]]\n",
      "SOFTMAX_LAYER\n",
      "[0.26236240874680444, 0.7376375912531955]\n",
      "LOSS PER INSTANCE: 0.304303\n",
      "DERIVATIVE LOSS: -1.355679\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.304303\n",
      "EPOCH 11\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.3921509  -0.98567052  0.        ]\n",
      " [ 1.79226545  0.84569091  0.        ]\n",
      " [ 0.00408817 -1.1463323   0.        ]]\n",
      "[]\n",
      "[[-0.70940911 -0.10166942]\n",
      " [-0.07672638 -1.02589458]\n",
      " [-0.55549677  1.12496628]]\n",
      "SOFTMAX_LAYER\n",
      "[0.26189653707073157, 0.73810346292926843]\n",
      "LOSS PER INSTANCE: 0.303671\n",
      "DERIVATIVE LOSS: -1.354824\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.303671\n",
      "EPOCH 12\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.39380873 -0.98090341  0.        ]\n",
      " [ 1.79392328  0.85045801  0.        ]\n",
      " [ 0.00243034 -1.1510994   0.        ]]\n",
      "[]\n",
      "[[-0.70712858 -0.09943329]\n",
      " [-0.07071359 -1.01999887]\n",
      " [-0.53907618  1.14106715]]\n",
      "SOFTMAX_LAYER\n",
      "[0.26148929772002072, 0.73851070227997939]\n",
      "LOSS PER INSTANCE: 0.303120\n",
      "DERIVATIVE LOSS: -1.354077\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.303120\n",
      "EPOCH 13\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[  3.95458245e-01  -9.76258271e-01   0.00000000e+00]\n",
      " [  1.79557280e+00   8.55103154e-01   0.00000000e+00]\n",
      " [  7.80822115e-04  -1.15574454e+00   0.00000000e+00]]\n",
      "[]\n",
      "[[-0.70484372 -0.0972278 ]\n",
      " [-0.06472555 -1.01421884]\n",
      " [-0.52255067  1.15701861]]\n",
      "SOFTMAX_LAYER\n",
      "[0.26113940350153392, 0.73886059649846603]\n",
      "LOSS PER INSTANCE: 0.302646\n",
      "DERIVATIVE LOSS: -1.353435\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.302646\n",
      "EPOCH 14\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[  3.97099500e-01  -9.71732276e-01   0.00000000e+00]\n",
      " [  1.79721405e+00   8.59629150e-01   0.00000000e+00]\n",
      " [ -8.60433664e-04  -1.16027054e+00   0.00000000e+00]]\n",
      "[]\n",
      "[[-0.70255471 -0.09505253]\n",
      " [-0.05876141 -1.00855106]\n",
      " [-0.50592131  1.17282165]]\n",
      "SOFTMAX_LAYER\n",
      "[0.26084560049868016, 0.73915439950131989]\n",
      "LOSS PER INSTANCE: 0.302248\n",
      "DERIVATIVE LOSS: -1.352897\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.302248\n",
      "EPOCH 15\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.39873255 -0.96732267  0.        ]\n",
      " [ 1.7988471   0.86403876  0.        ]\n",
      " [-0.00249348 -1.16468015  0.        ]]\n",
      "[]\n",
      "[[-0.70026174 -0.09290706]\n",
      " [-0.05282035 -1.00299217]\n",
      " [-0.48918925  1.18847739]]\n",
      "SOFTMAX_LAYER\n",
      "[0.26060666734277588, 0.73939333265722407]\n",
      "LOSS PER INSTANCE: 0.301925\n",
      "DERIVATIVE LOSS: -1.352460\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.301925\n",
      "EPOCH 16\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.40035743 -0.96302674  0.        ]\n",
      " [ 1.80047198  0.86833468  0.        ]\n",
      " [-0.00411836 -1.16897607  0.        ]]\n",
      "[]\n",
      "[[-0.69796501 -0.09079095]\n",
      " [-0.04690162 -0.99753892]\n",
      " [-0.47235572  1.20398705]]\n",
      "SOFTMAX_LAYER\n",
      "[0.26042141428473087, 0.73957858571526924]\n",
      "LOSS PER INSTANCE: 0.301675\n",
      "DERIVATIVE LOSS: -1.352121\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.301675\n",
      "EPOCH 17\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.40197418 -0.95884186  0.        ]\n",
      " [ 1.80208874  0.87251956  0.        ]\n",
      " [-0.00573512 -1.17316095  0.        ]]\n",
      "[]\n",
      "[[-0.69566473 -0.08870379]\n",
      " [-0.0410045  -0.99218814]\n",
      " [-0.45542201  1.21935192]]\n",
      "SOFTMAX_LAYER\n",
      "[0.26028868210541384, 0.73971131789458622]\n",
      "LOSS PER INSTANCE: 0.301495\n",
      "DERIVATIVE LOSS: -1.351879\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.301495\n",
      "EPOCH 18\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.40358283 -0.95476545  0.        ]\n",
      " [ 1.80369738  0.87659597  0.        ]\n",
      " [-0.00734376 -1.17723736  0.        ]]\n",
      "[]\n",
      "[[-0.69336113 -0.08664512]\n",
      " [-0.03512832 -0.98693676]\n",
      " [-0.43838953  1.23457338]]\n",
      "SOFTMAX_LAYER\n",
      "[0.26020734089815079, 0.73979265910184921]\n",
      "LOSS PER INSTANCE: 0.301385\n",
      "DERIVATIVE LOSS: -1.351730\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.301385\n",
      "EPOCH 19\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.40518338 -0.950795    0.        ]\n",
      " [ 1.80529793  0.88056643  0.        ]\n",
      " [-0.00894431 -1.18120782  0.        ]]\n",
      "[]\n",
      "[[-0.69105442 -0.0846145 ]\n",
      " [-0.02927245 -0.98178179]\n",
      " [-0.42125974  1.24965288]]\n",
      "SOFTMAX_LAYER\n",
      "[0.26017628875246257, 0.73982371124753743]\n",
      "LOSS PER INSTANCE: 0.301343\n",
      "DERIVATIVE LOSS: -1.351673\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.301343\n",
      "EPOCH 20\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.40677585 -0.94692805  0.        ]\n",
      " [ 1.80689041  0.88443338  0.        ]\n",
      " [-0.01053679 -1.18507477  0.        ]]\n",
      "[]\n",
      "[[-0.68874483 -0.08261149]\n",
      " [-0.02343631 -0.97672033]\n",
      " [-0.40403421  1.26459192]]\n",
      "SOFTMAX_LAYER\n",
      "[0.26019445036432848, 0.73980554963567158]\n",
      "LOSS PER INSTANCE: 0.301368\n",
      "DERIVATIVE LOSS: -1.351707\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.301368\n",
      "EPOCH 21\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.40836025 -0.94316222  0.        ]\n",
      " [ 1.8084748   0.88819921  0.        ]\n",
      " [-0.01212118 -1.18884059  0.        ]]\n",
      "[]\n",
      "[[-0.68643262 -0.08063564]\n",
      " [-0.01761934 -0.97174956]\n",
      " [-0.38671458  1.27939205]]\n",
      "SOFTMAX_LAYER\n",
      "[0.26026077559490329, 0.73973922440509665]\n",
      "LOSS PER INSTANCE: 0.301458\n",
      "DERIVATIVE LOSS: -1.351828\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.301458\n",
      "EPOCH 22\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.40993655 -0.93949519  0.        ]\n",
      " [ 1.81005111  0.89186624  0.        ]\n",
      " [-0.01369749 -1.19250762  0.        ]]\n",
      "[]\n",
      "[[-0.68411804 -0.0786865 ]\n",
      " [-0.01182107 -0.96686676]\n",
      " [-0.3693026   1.29405488]]\n",
      "SOFTMAX_LAYER\n",
      "[0.26037423799668463, 0.73962576200331542]\n",
      "LOSS PER INSTANCE: 0.301611\n",
      "DERIVATIVE LOSS: -1.352035\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.301611\n",
      "EPOCH 23\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.41150475 -0.9359247   0.        ]\n",
      " [ 1.8116193   0.89543672  0.        ]\n",
      " [-0.01526568 -1.19607811  0.        ]]\n",
      "[]\n",
      "[[-0.68180133 -0.07676362]\n",
      " [-0.00604102 -0.9620693 ]\n",
      " [-0.3518001   1.30858204]]\n",
      "SOFTMAX_LAYER\n",
      "[0.26053383332356556, 0.73946616667643439]\n",
      "LOSS PER INSTANCE: 0.301827\n",
      "DERIVATIVE LOSS: -1.352327\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.301827\n",
      "EPOCH 24\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.41306482 -0.93244856  0.        ]\n",
      " [ 1.81317938  0.89891286  0.        ]\n",
      " [-0.01682576 -1.19955425  0.        ]]\n",
      "[]\n",
      "[[ -6.79482772e-01  -7.48665614e-02]\n",
      " [ -2.78781394e-04  -9.57354595e-01]\n",
      " [ -3.34209001e-01   1.32297520e+00]]\n",
      "SOFTMAX_LAYER\n",
      "[0.26073857803898853, 0.73926142196101141]\n",
      "LOSS PER INSTANCE: 0.302104\n",
      "DERIVATIVE LOSS: -1.352701\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.302104\n",
      "EPOCH 25\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.41461673 -0.92906464  0.        ]\n",
      " [ 1.81473129  0.90229679  0.        ]\n",
      " [-0.01837767 -1.20293818  0.        ]]\n",
      "[]\n",
      "[[-0.67716264 -0.07299487]\n",
      " [ 0.00546602 -0.95272018]\n",
      " [-0.31653131  1.33723604]]\n",
      "SOFTMAX_LAYER\n",
      "[0.26098750783448049, 0.73901249216551956]\n",
      "LOSS PER INSTANCE: 0.302440\n",
      "DERIVATIVE LOSS: -1.353157\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.302440\n",
      "EPOCH 26\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.41616045 -0.92577085  0.        ]\n",
      " [ 1.816275    0.90559058  0.        ]\n",
      " [-0.01992138 -1.20623197  0.        ]]\n",
      "[]\n",
      "[[-0.67484121 -0.07114812]\n",
      " [ 0.01119371 -0.94816366]\n",
      " [-0.29876913  1.35136628]]\n",
      "SOFTMAX_LAYER\n",
      "[0.26127967616917791, 0.73872032383082209]\n",
      "LOSS PER INSTANCE: 0.302836\n",
      "DERIVATIVE LOSS: -1.353692\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.302836\n",
      "EPOCH 27\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.41769592 -0.92256518  0.        ]\n",
      " [ 1.81781047  0.90879624  0.        ]\n",
      " [-0.02145685 -1.20943763  0.        ]]\n",
      "[]\n",
      "[[-0.67251877 -0.06932586]\n",
      " [ 0.0169046  -0.94368271]\n",
      " [-0.28092467  1.36536764]]\n",
      "SOFTMAX_LAYER\n",
      "[0.26161415283950001, 0.73838584716049993]\n",
      "LOSS PER INSTANCE: 0.303289\n",
      "DERIVATIVE LOSS: -1.354305\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.303289\n",
      "EPOCH 28\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.41922309 -0.91944569  0.        ]\n",
      " [ 1.81933764  0.91191574  0.        ]\n",
      " [-0.02298402 -1.21255713  0.        ]]\n",
      "[]\n",
      "[[-0.67019563 -0.06752766]\n",
      " [ 0.02259894 -0.93927507]\n",
      " [-0.26300021  1.37924186]]\n",
      "SOFTMAX_LAYER\n",
      "[0.2619900225868676, 0.73800997741313235]\n",
      "LOSS PER INSTANCE: 0.303798\n",
      "DERIVATIVE LOSS: -1.354995\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.303798\n",
      "EPOCH 29\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.4207419  -0.91641045  0.        ]\n",
      " [ 1.82085646  0.91495097  0.        ]\n",
      " [-0.02450284 -1.21559236  0.        ]]\n",
      "[]\n",
      "[[-0.66787209 -0.06575309]\n",
      " [ 0.02827695 -0.93493858]\n",
      " [-0.24499813  1.39299068]]\n",
      "SOFTMAX_LAYER\n",
      "[0.26240638375027497, 0.73759361624972508]\n",
      "LOSS PER INSTANCE: 0.304362\n",
      "DERIVATIVE LOSS: -1.355760\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.304362\n",
      "EPOCH 30\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.4222523  -0.91345763  0.        ]\n",
      " [ 1.82236685  0.91790379  0.        ]\n",
      " [-0.02601323 -1.21854518  0.        ]]\n",
      "[]\n",
      "[[-0.66554846 -0.06400172]\n",
      " [ 0.03393882 -0.93067112]\n",
      " [-0.2269209   1.40661585]]\n",
      "SOFTMAX_LAYER\n",
      "[0.26286234696957028, 0.73713765303042966]\n",
      "LOSS PER INSTANCE: 0.304981\n",
      "DERIVATIVE LOSS: -1.356599\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.304981\n",
      "EPOCH 31\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.4237542  -0.91058543  0.        ]\n",
      " [ 1.82386875  0.920776    0.        ]\n",
      " [-0.02751513 -1.22141738  0.        ]]\n",
      "[]\n",
      "[[-0.66322505 -0.06227314]\n",
      " [ 0.03958468 -0.92647066]\n",
      " [-0.20877108  1.4201191 ]]\n",
      "SOFTMAX_LAYER\n",
      "[0.26335703394446863, 0.73664296605553137]\n",
      "LOSS PER INSTANCE: 0.305652\n",
      "DERIVATIVE LOSS: -1.357510\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.305652\n",
      "EPOCH 32\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.42524753 -0.9077921   0.        ]\n",
      " [ 1.82536209  0.92356933  0.        ]\n",
      " [-0.02900847 -1.22421072  0.        ]]\n",
      "[]\n",
      "[[-0.66090221 -0.06056692]\n",
      " [ 0.04521466 -0.92233523]\n",
      " [-0.19055132  1.43350219]]\n",
      "SOFTMAX_LAYER\n",
      "[0.26388957625359066, 0.73611042374640934]\n",
      "LOSS PER INSTANCE: 0.306375\n",
      "DERIVATIVE LOSS: -1.358492\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.306375\n",
      "EPOCH 33\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.42673221 -0.90507593  0.        ]\n",
      " [ 1.82684677  0.92628549  0.        ]\n",
      " [-0.03049315 -1.22692688  0.        ]]\n",
      "[]\n",
      "[[-0.65858025 -0.05888266]\n",
      " [ 0.05082884 -0.91826293]\n",
      " [-0.17226436  1.44676684]]\n",
      "SOFTMAX_LAYER\n",
      "[0.26445911423717477, 0.73554088576282517]\n",
      "LOSS PER INSTANCE: 0.307149\n",
      "DERIVATIVE LOSS: -1.359544\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.307149\n",
      "EPOCH 34\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.42820816 -0.90243529  0.        ]\n",
      " [ 1.82832271  0.92892614  0.        ]\n",
      " [-0.03196909 -1.22956753  0.        ]]\n",
      "[]\n",
      "[[-0.65625951 -0.05721995]\n",
      " [ 0.05642726 -0.9142519 ]\n",
      " [-0.153913    1.45991479]]\n",
      "SOFTMAX_LAYER\n",
      "[0.26506479594653243, 0.73493520405346757]\n",
      "LOSS PER INSTANCE: 0.307973\n",
      "DERIVATIVE LOSS: -1.360664\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.307973\n",
      "EPOCH 35\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.42967528 -0.89986855  0.        ]\n",
      " [ 1.82978983  0.93149287  0.        ]\n",
      " [-0.03343621 -1.23213426  0.        ]]\n",
      "[]\n",
      "[[-0.65394033 -0.0555784 ]\n",
      " [ 0.06200994 -0.91030038]\n",
      " [-0.13550016  1.47294775]]\n",
      "SOFTMAX_LAYER\n",
      "[0.26570577616279695, 0.734294223837203]\n",
      "LOSS PER INSTANCE: 0.308845\n",
      "DERIVATIVE LOSS: -1.361852\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.308845\n",
      "EPOCH 36\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.43113347 -0.89737417  0.        ]\n",
      " [ 1.83124802  0.93398726  0.        ]\n",
      " [-0.0348944  -1.23462865  0.        ]]\n",
      "[]\n",
      "[[-0.65162307 -0.0539576 ]\n",
      " [ 0.06757686 -0.90640663]\n",
      " [-0.11702882  1.48586742]]\n",
      "SOFTMAX_LAYER\n",
      "[0.26638121548704374, 0.73361878451295626]\n",
      "LOSS PER INSTANCE: 0.309766\n",
      "DERIVATIVE LOSS: -1.363106\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.309766\n",
      "EPOCH 37\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.43258264 -0.8949506   0.        ]\n",
      " [ 1.8326972   0.93641083  0.        ]\n",
      " [-0.03634358 -1.23705222  0.        ]]\n",
      "[]\n",
      "[[-0.64930807 -0.05235718]\n",
      " [ 0.07312798 -0.90256898]\n",
      " [-0.09850203  1.4986755 ]]\n",
      "SOFTMAX_LAYER\n",
      "[0.26709027950342107, 0.73290972049657888]\n",
      "LOSS PER INSTANCE: 0.310733\n",
      "DERIVATIVE LOSS: -1.364425\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.310733\n",
      "EPOCH 38\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.4340227  -0.89259636  0.        ]\n",
      " [ 1.83413725  0.93876506  0.        ]\n",
      " [-0.03778363 -1.23940645  0.        ]]\n",
      "[]\n",
      "[[-0.64699569 -0.05077675]\n",
      " [ 0.07866323 -0.89878583]\n",
      " [-0.07992293  1.51137366]]\n",
      "SOFTMAX_LAYER\n",
      "[0.26783213801652839, 0.73216786198347172]\n",
      "LOSS PER INSTANCE: 0.311745\n",
      "DERIVATIVE LOSS: -1.365807\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.311745\n",
      "EPOCH 39\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.43545352 -0.89031002  0.        ]\n",
      " [ 1.83556807  0.94105141  0.        ]\n",
      " [-0.03921445 -1.24169279  0.        ]]\n",
      "[]\n",
      "[[-0.64468629 -0.04921594]\n",
      " [ 0.08418252 -0.89505562]\n",
      " [-0.06129473  1.52396355]]\n",
      "SOFTMAX_LAYER\n",
      "[0.26860596436389073, 0.73139403563610927]\n",
      "LOSS PER INSTANCE: 0.312803\n",
      "DERIVATIVE LOSS: -1.367252\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.312803\n",
      "EPOCH 40\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.43687501 -0.88809015  0.        ]\n",
      " [ 1.83698957  0.94327127  0.        ]\n",
      " [-0.04063595 -1.24391266  0.        ]]\n",
      "[]\n",
      "[[-0.64238022 -0.04767437]\n",
      " [ 0.08968571 -0.89137683]\n",
      " [-0.04262069  1.53644682]]\n",
      "SOFTMAX_LAYER\n",
      "[0.26941093480401984, 0.7305890651959801]\n",
      "LOSS PER INSTANCE: 0.313904\n",
      "DERIVATIVE LOSS: -1.368759\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.313904\n",
      "EPOCH 41\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.43828706 -0.88593538  0.        ]\n",
      " [ 1.83840162  0.94542604  0.        ]\n",
      " [-0.042048   -1.24606743  0.        ]]\n",
      "[]\n",
      "[[-0.64007786 -0.04615169]\n",
      " [ 0.09517266 -0.88774801]\n",
      " [-0.02390416  1.54882509]]\n",
      "SOFTMAX_LAYER\n",
      "[0.27024622798019532, 0.72975377201980474]\n",
      "LOSS PER INSTANCE: 0.315048\n",
      "DERIVATIVE LOSS: -1.370325\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.315048\n",
      "EPOCH 42\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.43968957 -0.88384437  0.        ]\n",
      " [ 1.83980412  0.94751706  0.        ]\n",
      " [-0.0434505  -1.24815845  0.        ]]\n",
      "[]\n",
      "[[-0.63777957 -0.04464755]\n",
      " [ 0.10064319 -0.88416775]\n",
      " [-0.00514853  1.56109995]]\n",
      "SOFTMAX_LAYER\n",
      "[0.27111102445976792, 0.72888897554023213]\n",
      "LOSS PER INSTANCE: 0.316234\n",
      "DERIVATIVE LOSS: -1.371951\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.316234\n",
      "EPOCH 43\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.44108241 -0.88181579  0.        ]\n",
      " [ 1.84119696  0.94954563  0.        ]\n",
      " [-0.04484334 -1.25018702  0.        ]]\n",
      "[]\n",
      "[[-0.63548571 -0.04316158]\n",
      " [ 0.10609713 -0.88063468]\n",
      " [ 0.01364275  1.57327298]]\n",
      "SOFTMAX_LAYER\n",
      "[0.27200450634845269, 0.72799549365154725]\n",
      "LOSS PER INSTANCE: 0.317460\n",
      "DERIVATIVE LOSS: -1.373635\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.317460\n",
      "EPOCH 44\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.44246548 -0.87984837  0.        ]\n",
      " [ 1.84258003  0.95151305  0.        ]\n",
      " [-0.04622641 -1.25215444  0.        ]]\n",
      "[]\n",
      "[[-0.63319666 -0.04169346]\n",
      " [ 0.11153424 -0.87714748]\n",
      " [ 0.03246617  1.58534573]]\n",
      "SOFTMAX_LAYER\n",
      "[0.27292585697876087, 0.72707414302123907]\n",
      "LOSS PER INSTANCE: 0.318727\n",
      "DERIVATIVE LOSS: -1.375376\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.318727\n",
      "EPOCH 45\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.44383866 -0.87794085  0.        ]\n",
      " [ 1.84395322  0.95342057  0.        ]\n",
      " [-0.0475996  -1.25406196  0.        ]]\n",
      "[]\n",
      "[[-0.63091279 -0.04024284]\n",
      " [ 0.1169543  -0.87370489]\n",
      " [ 0.05131817  1.59731974]]\n",
      "SOFTMAX_LAYER\n",
      "[0.27387426067140824, 0.7261257393285917]\n",
      "LOSS PER INSTANCE: 0.320032\n",
      "DERIVATIVE LOSS: -1.377172\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.320032\n",
      "EPOCH 46\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.44520186 -0.876092    0.        ]\n",
      " [ 1.84531641  0.95526942  0.        ]\n",
      " [-0.04896279 -1.25591081  0.        ]]\n",
      "[]\n",
      "[[-0.62863446 -0.03880939]\n",
      " [ 0.12235706 -0.87030566]\n",
      " [ 0.07019517  1.60919651]]\n",
      "SOFTMAX_LAYER\n",
      "[0.27484890256822775, 0.72515109743177231]\n",
      "LOSS PER INSTANCE: 0.321375\n",
      "DERIVATIVE LOSS: -1.379023\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.321375\n",
      "EPOCH 47\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.44655495 -0.87430062  0.        ]\n",
      " [ 1.8466695   0.9570608   0.        ]\n",
      " [-0.05031588 -1.25770219  0.        ]]\n",
      "[]\n",
      "[[-0.62636204 -0.03739279]\n",
      " [ 0.12774225 -0.86694859]\n",
      " [ 0.08909353  1.62097752]]\n",
      "SOFTMAX_LAYER\n",
      "[0.27584896853482294, 0.72415103146517712]\n",
      "LOSS PER INSTANCE: 0.322755\n",
      "DERIVATIVE LOSS: -1.380927\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.322755\n",
      "EPOCH 48\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.44789782 -0.87256553  0.        ]\n",
      " [ 1.84801238  0.95879589  0.        ]\n",
      " [-0.05165876 -1.25943728  0.        ]]\n",
      "[]\n",
      "[[-0.6240959  -0.03599272]\n",
      " [ 0.13310958 -0.86363255]\n",
      " [ 0.10800959  1.63266424]]\n",
      "SOFTMAX_LAYER\n",
      "[0.27687364513090257, 0.72312635486909749]\n",
      "LOSS PER INSTANCE: 0.324171\n",
      "DERIVATIVE LOSS: -1.382884\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.324171\n",
      "EPOCH 49\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.44923038 -0.87088558  0.        ]\n",
      " [ 1.84934493  0.96047585  0.        ]\n",
      " [-0.05299131 -1.26111724  0.        ]]\n",
      "[]\n",
      "[[-0.62183641 -0.03460888]\n",
      " [ 0.13845876 -0.8603564 ]\n",
      " [ 0.12693966  1.64425811]]\n",
      "SOFTMAX_LAYER\n",
      "[0.27792211964596825, 0.72207788035403175]\n",
      "LOSS PER INSTANCE: 0.325622\n",
      "DERIVATIVE LOSS: -1.384892\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.325622\n",
      "EPOCH 50\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.45055251 -0.86925962  0.        ]\n",
      " [ 1.85066706  0.9621018   0.        ]\n",
      " [-0.05431344 -1.26274319  0.        ]]\n",
      "[]\n",
      "[[-0.61958392 -0.03324095]\n",
      " [ 0.14378948 -0.85711907]\n",
      " [ 0.14588002  1.65576052]]\n",
      "SOFTMAX_LAYER\n",
      "[0.27899358019775117, 0.72100641980224878]\n",
      "LOSS PER INSTANCE: 0.327107\n",
      "DERIVATIVE LOSS: -1.386950\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.327107\n",
      "EPOCH 51\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.4518641  -0.86768656  0.        ]\n",
      " [ 1.85197866  0.96367487  0.        ]\n",
      " [-0.05562504 -1.26431626  0.        ]]\n",
      "[]\n",
      "[[-0.6173388  -0.03188864]\n",
      " [ 0.14910142 -0.85391952]\n",
      " [ 0.16482694  1.66717287]]\n",
      "SOFTMAX_LAYER\n",
      "[0.28008721589054975, 0.71991278410945025]\n",
      "LOSS PER INSTANCE: 0.328625\n",
      "DERIVATIVE LOSS: -1.389057\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.328625\n",
      "EPOCH 52\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.45316507 -0.86616529  0.        ]\n",
      " [ 1.85327962  0.96519614  0.        ]\n",
      " [-0.056926   -1.26583753  0.        ]]\n",
      "[]\n",
      "[[-0.6151014  -0.03055166]\n",
      " [ 0.15439424 -0.85075673]\n",
      " [ 0.18377669  1.67849651]]\n",
      "SOFTMAX_LAYER\n",
      "[0.28120221703037723, 0.71879778296962282]\n",
      "LOSS PER INSTANCE: 0.330175\n",
      "DERIVATIVE LOSS: -1.391212\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.330175\n",
      "EPOCH 53\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.4544553  -0.86469475  0.        ]\n",
      " [ 1.85456986  0.96666668  0.        ]\n",
      " [-0.05821624 -1.26730807  0.        ]]\n",
      "[]\n",
      "[[-0.61287208 -0.02922972]\n",
      " [ 0.15966761 -0.84762973]\n",
      " [ 0.20272552  1.68973278]]\n",
      "SOFTMAX_LAYER\n",
      "[0.28233777539361199, 0.71766222460638818]\n",
      "LOSS PER INSTANCE: 0.331756\n",
      "DERIVATIVE LOSS: -1.393413\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.331756\n",
      "EPOCH 54\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.45573471 -0.86327388  0.        ]\n",
      " [ 1.85584927  0.96808755  0.        ]\n",
      " [-0.05949564 -1.26872894  0.        ]]\n",
      "[]\n",
      "[[-0.61065118 -0.02792253]\n",
      " [ 0.16492118 -0.84453757]\n",
      " [ 0.22166968  1.70088298]]\n",
      "SOFTMAX_LAYER\n",
      "[0.28349308454564148, 0.71650691545435852]\n",
      "LOSS PER INSTANCE: 0.333367\n",
      "DERIVATIVE LOSS: -1.395660\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.333367\n",
      "EPOCH 55\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.4570032  -0.86190165  0.        ]\n",
      " [ 1.85711775  0.96945978  0.        ]\n",
      " [-0.06076413 -1.27010117  0.        ]]\n",
      "[]\n",
      "[[-0.60843904 -0.02662983]\n",
      " [ 0.1701546  -0.84147934]\n",
      " [ 0.24060543  1.7119484 ]]\n",
      "SOFTMAX_LAYER\n",
      "[0.2846673402058113, 0.71533265979418881]\n",
      "LOSS PER INSTANCE: 0.335008\n",
      "DERIVATIVE LOSS: -1.397951\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.335008\n",
      "EPOCH 56\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.45826068 -0.86057703  0.        ]\n",
      " [ 1.85837524  0.97078439  0.        ]\n",
      " [-0.06202162 -1.27142578  0.        ]]\n",
      "[]\n",
      "[[-0.606236   -0.02535135]\n",
      " [ 0.1753675  -0.83845415]\n",
      " [ 0.25952905  1.7229303 ]]\n",
      "SOFTMAX_LAYER\n",
      "[0.28585974065483444, 0.71414025934516556]\n",
      "LOSS PER INSTANCE: 0.336676\n",
      "DERIVATIVE LOSS: -1.400285\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.336676\n",
      "EPOCH 57\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.45950708 -0.85929904  0.        ]\n",
      " [ 1.85962163  0.97206238  0.        ]\n",
      " [-0.06326801 -1.27270377  0.        ]]\n",
      "[]\n",
      "[[-0.60404239 -0.02408681]\n",
      " [ 0.18055952 -0.83546115]\n",
      " [ 0.27843681  1.7338299 ]]\n",
      "SOFTMAX_LAYER\n",
      "[0.28706948718068465, 0.71293051281931541]\n",
      "LOSS PER INSTANCE: 0.338371\n",
      "DERIVATIVE LOSS: -1.402661\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.338371\n",
      "EPOCH 58\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.4607423  -0.85806668  0.        ]\n",
      " [ 1.86085685  0.97329474  0.        ]\n",
      " [-0.06450323 -1.27393613  0.        ]]\n",
      "[]\n",
      "[[-0.60185853 -0.02283598]\n",
      " [ 0.1857303  -0.8324995 ]\n",
      " [ 0.29732503  1.74464842]]\n",
      "SOFTMAX_LAYER\n",
      "[0.28829578455888744, 0.71170421544111251]\n",
      "LOSS PER INSTANCE: 0.340093\n",
      "DERIVATIVE LOSS: -1.405078\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.340093\n",
      "EPOCH 59\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.46196628 -0.85687899  0.        ]\n",
      " [ 1.86208083  0.97448244  0.        ]\n",
      " [-0.06572721 -1.27512383  0.        ]]\n",
      "[]\n",
      "[[-0.59968475 -0.02159859]\n",
      " [ 0.19087948 -0.82956842]\n",
      " [ 0.31619005  1.75538703]]\n",
      "SOFTMAX_LAYER\n",
      "[0.28953784156304729, 0.71046215843695271]\n",
      "LOSS PER INSTANCE: 0.341840\n",
      "DERIVATIVE LOSS: -1.407535\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.341840\n",
      "EPOCH 60\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.46317894 -0.855735    0.        ]\n",
      " [ 1.86329349  0.97562643  0.        ]\n",
      " [-0.06693987 -1.27626782  0.        ]]\n",
      "[]\n",
      "[[-0.59752135 -0.02037439]\n",
      " [ 0.19600668 -0.82666711]\n",
      " [ 0.33502823  1.76604689]]\n",
      "SOFTMAX_LAYER\n",
      "[0.29079487150139072, 0.70920512849860917]\n",
      "LOSS PER INSTANCE: 0.343610\n",
      "DERIVATIVE LOSS: -1.410029\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.343610\n",
      "EPOCH 61\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.46438021 -0.85463378  0.        ]\n",
      " [ 1.86449477  0.97672765  0.        ]\n",
      " [-0.06814115 -1.27736904  0.        ]]\n",
      "[]\n",
      "[[-0.59536863 -0.01916316]\n",
      " [ 0.20111154 -0.82379485]\n",
      " [ 0.35383597  1.77662913]]\n",
      "SOFTMAX_LAYER\n",
      "[0.29206609277508411, 0.707933907224916]\n",
      "LOSS PER INSTANCE: 0.345405\n",
      "DERIVATIVE LOSS: -1.412561\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.345405\n",
      "EPOCH 62\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.46557005 -0.8535744   0.        ]\n",
      " [ 1.8656846   0.97778702  0.        ]\n",
      " [-0.06933098 -1.27842841  0.        ]]\n",
      "[]\n",
      "[[-0.59322688 -0.01796464]\n",
      " [ 0.20619369 -0.82095089]\n",
      " [ 0.37260973  1.78713487]]\n",
      "SOFTMAX_LAYER\n",
      "[0.29335072945408569, 0.70664927054591431]\n",
      "LOSS PER INSTANCE: 0.347221\n",
      "DERIVATIVE LOSS: -1.415129\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.347221\n",
      "EPOCH 63\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.46674838 -0.85255595  0.        ]\n",
      " [ 1.86686293  0.97880547  0.        ]\n",
      " [-0.07050931 -1.27944686  0.        ]]\n",
      "[]\n",
      "[[-0.5910964  -0.01677862]\n",
      " [ 0.21125278 -0.81813454]\n",
      " [ 0.391346    1.79756517]]\n",
      "SOFTMAX_LAYER\n",
      "[0.29464801186632239, 0.70535198813367761]\n",
      "LOSS PER INSTANCE: 0.349058\n",
      "DERIVATIVE LOSS: -1.417732\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.349058\n",
      "EPOCH 64\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.46791517 -0.85157754  0.        ]\n",
      " [ 1.86802972  0.97978389  0.        ]\n",
      " [-0.0716761  -1.28042528  0.        ]]\n",
      "[]\n",
      "[[-0.58897745 -0.01560487]\n",
      " [ 0.21628845 -0.81534513]\n",
      " [ 0.41004133  1.80792111]]\n",
      "SOFTMAX_LAYER\n",
      "[0.29595717719603837, 0.70404282280396169]\n",
      "LOSS PER INSTANCE: 0.350916\n",
      "DERIVATIVE LOSS: -1.420368\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.350916\n",
      "EPOCH 65\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.46907036 -0.85063827  0.        ]\n",
      " [ 1.86918491  0.98072316  0.        ]\n",
      " [-0.07283129 -1.28136455  0.        ]]\n",
      "[]\n",
      "[[-0.5868703  -0.01444316]\n",
      " [ 0.22130034 -0.81258198]\n",
      " [ 0.42869232  1.81820373]]\n",
      "SOFTMAX_LAYER\n",
      "[0.2972774700872472, 0.70272252991275286]\n",
      "LOSS PER INSTANCE: 0.352793\n",
      "DERIVATIVE LOSS: -1.423037\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.352793\n",
      "EPOCH 66\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.47021391 -0.84973727  0.        ]\n",
      " [ 1.87032846  0.98162415  0.        ]\n",
      " [-0.07397484 -1.28226554  0.        ]]\n",
      "[]\n",
      "[[-0.58477521 -0.01329329]\n",
      " [ 0.22628811 -0.80984448]\n",
      " [ 0.44729563  1.82841402]]\n",
      "SOFTMAX_LAYER\n",
      "[0.29860814324832963, 0.70139185675167026]\n",
      "LOSS PER INSTANCE: 0.354689\n",
      "DERIVATIVE LOSS: -1.425737\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.354689\n",
      "EPOCH 67\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.4713458  -0.84887369  0.        ]\n",
      " [ 1.87146035  0.98248773  0.        ]\n",
      " [-0.07510673 -1.28312912  0.        ]]\n",
      "[]\n",
      "[[-0.58269243 -0.01215504]\n",
      " [ 0.23125142 -0.80713201]\n",
      " [ 0.46584799  1.83855298]]\n",
      "SOFTMAX_LAYER\n",
      "[0.29994845805394904, 0.7000515419460509]\n",
      "LOSS PER INSTANCE: 0.356601\n",
      "DERIVATIVE LOSS: -1.428466\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.356601\n",
      "EPOCH 68\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.47246599 -0.84804668  0.        ]\n",
      " [ 1.87258055  0.98331475  0.        ]\n",
      " [-0.07622692 -1.28395614  0.        ]]\n",
      "[]\n",
      "[[-0.58062219 -0.0110282 ]\n",
      " [ 0.23618993 -0.80444396]\n",
      " [ 0.4843462   1.84862159]]\n",
      "SOFTMAX_LAYER\n",
      "[0.30129768514061439, 0.69870231485938561]\n",
      "LOSS PER INSTANCE: 0.358531\n",
      "DERIVATIVE LOSS: -1.431225\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.358531\n",
      "EPOCH 69\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.47357447 -0.8472554   0.        ]\n",
      " [ 1.87368902  0.98410603  0.        ]\n",
      " [-0.0773354  -1.28474742  0.        ]]\n",
      "[]\n",
      "[[-0.57856472 -0.00991258]\n",
      " [ 0.24110333 -0.80177978]\n",
      " [ 0.50278712  1.85862078]]\n",
      "SOFTMAX_LAYER\n",
      "[0.30265510499239617, 0.69734489500760388]\n",
      "LOSS PER INSTANCE: 0.360475\n",
      "DERIVATIVE LOSS: -1.434011\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.360475\n",
      "EPOCH 70\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.4746712  -0.84649903  0.        ]\n",
      " [ 1.87478576  0.9848624   0.        ]\n",
      " [-0.07843214 -1.28550378  0.        ]]\n",
      "[]\n",
      "[[-0.57652024 -0.00880799]\n",
      " [ 0.2459913  -0.7991389 ]\n",
      " [ 0.5211677   1.86855148]]\n",
      "SOFTMAX_LAYER\n",
      "[0.30402000851349209, 0.69597999148650791]\n",
      "LOSS PER INSTANCE: 0.362434\n",
      "DERIVATIVE LOSS: -1.436823\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.362434\n",
      "EPOCH 71\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.47575619 -0.84577677  0.        ]\n",
      " [ 1.87587075  0.98558466  0.        ]\n",
      " [-0.07951713 -1.28622605  0.        ]]\n",
      "[]\n",
      "[[-0.57448895 -0.00771422]\n",
      " [ 0.25085353 -0.79652078]\n",
      " [ 0.53948495  1.87841459]]\n",
      "SOFTMAX_LAYER\n",
      "[0.30539169758455159, 0.69460830241544846]\n",
      "LOSS PER INSTANCE: 0.364407\n",
      "DERIVATIVE LOSS: -1.439660\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.364407\n",
      "EPOCH 72\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.47682943 -0.84508781  0.        ]\n",
      " [ 1.87694399  0.98627362  0.        ]\n",
      " [-0.08059037 -1.28691501  0.        ]]\n",
      "[]\n",
      "[[-0.57247105 -0.00663109]\n",
      " [ 0.25568972 -0.79392491]\n",
      " [ 0.55773597  1.88821099]]\n",
      "SOFTMAX_LAYER\n",
      "[0.30676948559989198, 0.69323051440010797]\n",
      "LOSS PER INSTANCE: 0.366393\n",
      "DERIVATIVE LOSS: -1.442522\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.366393\n",
      "EPOCH 73\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.47789092 -0.84443137  0.        ]\n",
      " [ 1.87800547  0.98693006  0.        ]\n",
      " [-0.08165185 -1.28757145  0.        ]]\n",
      "[]\n",
      "[[-0.57046673 -0.00555843]\n",
      " [ 0.26049959 -0.79135079]\n",
      " [ 0.57591796  1.89794154]]\n",
      "SOFTMAX_LAYER\n",
      "[0.3081526979829714, 0.6918473020170286]\n",
      "LOSS PER INSTANCE: 0.368390\n",
      "DERIVATIVE LOSS: -1.445406\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.368390\n",
      "EPOCH 74\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.47894066 -0.84380668  0.        ]\n",
      " [ 1.87905521  0.98755475  0.        ]\n",
      " [-0.08270159 -1.28819614  0.        ]]\n",
      "[]\n",
      "[[-0.56847615 -0.00449605]\n",
      " [ 0.26528288 -0.78879791]\n",
      " [ 0.59402817  1.90760709]]\n",
      "SOFTMAX_LAYER\n",
      "[0.3095406726777295, 0.69045932732227044]\n",
      "LOSS PER INSTANCE: 0.370398\n",
      "DERIVATIVE LOSS: -1.448311\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.370398\n",
      "EPOCH 75\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.47997867 -0.84321298  0.        ]\n",
      " [ 1.88009322  0.98814845  0.        ]\n",
      " [-0.0837396  -1.28878984  0.        ]]\n",
      "[]\n",
      "[[-0.56649949 -0.00344377]\n",
      " [ 0.27003931 -0.78626583]\n",
      " [ 0.61206397  1.91720845]]\n",
      "SOFTMAX_LAYER\n",
      "[0.3109327606136576, 0.68906723938634229]\n",
      "LOSS PER INSTANCE: 0.372416\n",
      "DERIVATIVE LOSS: -1.451237\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.372416\n",
      "EPOCH 76\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.48100495 -0.84264951  0.        ]\n",
      " [ 1.88111951  0.98871191  0.        ]\n",
      " [-0.08476589 -1.2893533   0.        ]]\n",
      "[]\n",
      "[[-0.5645369  -0.00240143]\n",
      " [ 0.27476863 -0.78375407]\n",
      " [ 0.63002279  1.92674642]]\n",
      "SOFTMAX_LAYER\n",
      "[0.31232832614271061, 0.68767167385728933]\n",
      "LOSS PER INSTANCE: 0.374444\n",
      "DERIVATIVE LOSS: -1.454182\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.374444\n",
      "EPOCH 77\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.48201954 -0.84211555  0.        ]\n",
      " [ 1.8821341   0.98924587  0.        ]\n",
      " [-0.08578048 -1.28988726  0.        ]]\n",
      "[]\n",
      "[[ -5.62588513e-01  -1.36886354e-03]\n",
      " [  2.79470616e-01  -7.81262206e-01]\n",
      " [  6.47902188e-01   1.93622180e+00]]\n",
      "SOFTMAX_LAYER\n",
      "[0.31372674744643297, 0.68627325255356708]\n",
      "LOSS PER INSTANCE: 0.376479\n",
      "DERIVATIVE LOSS: -1.457146\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.376479\n",
      "EPOCH 78\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.48302246 -0.84161037  0.        ]\n",
      " [ 1.88313702  0.98975106  0.        ]\n",
      " [-0.0867834  -1.29039245  0.        ]]\n",
      "[]\n",
      "[[ -5.60654467e-01  -3.45904269e-04]\n",
      " [  2.84145032e-01  -7.78789804e-01]\n",
      " [  6.65699776e-01   1.94563534e+00]]\n",
      "SOFTMAX_LAYER\n",
      "[0.31512741691192175, 0.68487258308807819]\n",
      "LOSS PER INSTANCE: 0.378522\n",
      "DERIVATIVE LOSS: -1.460126\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.378522\n",
      "EPOCH 79\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.48401375 -0.84113325  0.        ]\n",
      " [ 1.8841283   0.99022817  0.        ]\n",
      " [-0.08777468 -1.29086956  0.        ]]\n",
      "[]\n",
      "[[ -5.58734884e-01   6.67605011e-04]\n",
      " [  2.88791671e-01  -7.76336453e-01]\n",
      " [  6.83413281e-01   1.95498778e+00]]\n",
      "SOFTMAX_LAYER\n",
      "[0.31652974147550456, 0.6834702585244955]\n",
      "LOSS PER INSTANCE: 0.380572\n",
      "DERIVATIVE LOSS: -1.463121\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.380572\n",
      "EPOCH 80\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.48499343 -0.8406835   0.        ]\n",
      " [ 1.88510798  0.99067793  0.        ]\n",
      " [-0.08875436 -1.29131931  0.        ]]\n",
      "[]\n",
      "[[ -5.56829874e-01   1.67181917e-03]\n",
      " [  2.93410332e-01  -7.73901754e-01]\n",
      " [  7.01040517e-01   1.96427987e+00]]\n",
      "SOFTMAX_LAYER\n",
      "[0.31793314293325536, 0.68206685706674453]\n",
      "LOSS PER INSTANCE: 0.382628\n",
      "DERIVATIVE LOSS: -1.466132\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.382628\n",
      "EPOCH 81\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.48596156 -0.84026042  0.        ]\n",
      " [ 1.88607611  0.991101    0.        ]\n",
      " [-0.08972249 -1.29174239  0.        ]]\n",
      "[]\n",
      "[[-0.55493954  0.00266689]\n",
      " [ 0.29800083 -0.77148532]\n",
      " [ 0.71857939  1.97351231]]\n",
      "SOFTMAX_LAYER\n",
      "[0.31933705821771269, 0.68066294178228737]\n",
      "LOSS PER INSTANCE: 0.384688\n",
      "DERIVATIVE LOSS: -1.469156\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.384688\n",
      "EPOCH 82\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.48691817 -0.83986335  0.        ]\n",
      " [ 1.88703273  0.99149807  0.        ]\n",
      " [-0.0906791  -1.29213946  0.        ]]\n",
      "[]\n",
      "[[-0.55306396  0.00365296]\n",
      " [ 0.302563   -0.76908678]\n",
      " [ 0.73602792  1.98268579]]\n",
      "SOFTMAX_LAYER\n",
      "[0.32074093964039446, 0.67925906035960559]\n",
      "LOSS PER INSTANCE: 0.386753\n",
      "DERIVATIVE LOSS: -1.472192\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.386753\n",
      "EPOCH 83\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.48786333 -0.83949162  0.        ]\n",
      " [ 1.88797788  0.99186981  0.        ]\n",
      " [-0.09162426 -1.2925112   0.        ]]\n",
      "[]\n",
      "[[-0.55120324  0.00463019]\n",
      " [ 0.30709667 -0.76670578]\n",
      " [ 0.75338418  1.991801  ]]\n",
      "SOFTMAX_LAYER\n",
      "[0.32214425509992806, 0.67785574490007205]\n",
      "LOSS PER INSTANCE: 0.388821\n",
      "DERIVATIVE LOSS: -1.475240\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.388821\n",
      "EPOCH 84\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.48879708 -0.83914456  0.        ]\n",
      " [ 1.88891163  0.99221686  0.        ]\n",
      " [-0.09255801 -1.29285825  0.        ]]\n",
      "[]\n",
      "[[-0.54935742  0.0055987 ]\n",
      " [ 0.3116017  -0.76434196]\n",
      " [ 0.77064638  2.0008586 ]]\n",
      "SOFTMAX_LAYER\n",
      "[0.32354648825582205, 0.676453511744178]\n",
      "LOSS PER INSTANCE: 0.390892\n",
      "DERIVATIVE LOSS: -1.478298\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.390892\n",
      "EPOCH 85\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.48971949 -0.83882156  0.        ]\n",
      " [ 1.88983404  0.99253987  0.        ]\n",
      " [-0.09348042 -1.29318126  0.        ]]\n",
      "[]\n",
      "[[-0.54752659  0.00655864]\n",
      " [ 0.31607796 -0.76199498]\n",
      " [ 0.78781279  2.00985923]]\n",
      "SOFTMAX_LAYER\n",
      "[0.32494713866810521, 0.67505286133189479]\n",
      "LOSS PER INSTANCE: 0.392964\n",
      "DERIVATIVE LOSS: -1.481365\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.392964\n",
      "EPOCH 86\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.49063062 -0.83852197  0.        ]\n",
      " [ 1.89074517  0.99283946  0.        ]\n",
      " [-0.09439155 -1.29348085  0.        ]]\n",
      "[]\n",
      "[[-0.54571077  0.00751014]\n",
      " [ 0.32052534 -0.75966452]\n",
      " [ 0.80488181  2.01880354]]\n",
      "SOFTMAX_LAYER\n",
      "[0.32634572190324401, 0.67365427809675593]\n",
      "LOSS PER INSTANCE: 0.395038\n",
      "DERIVATIVE LOSS: -1.484441\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.395038\n",
      "EPOCH 87\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.49153054 -0.83824518  0.        ]\n",
      " [ 1.89164509  0.99311625  0.        ]\n",
      " [-0.09529147 -1.29375763  0.        ]]\n",
      "[]\n",
      "[[-0.54391003  0.00845333]\n",
      " [ 0.32494373 -0.75735025]\n",
      " [ 0.82185191  2.02769213]]\n",
      "SOFTMAX_LAYER\n",
      "[0.32774176960691837, 0.67225823039308175]\n",
      "LOSS PER INSTANCE: 0.397113\n",
      "DERIVATIVE LOSS: -1.487524\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.397113\n",
      "EPOCH 88\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.49241932 -0.83799059  0.        ]\n",
      " [ 1.89253387  0.99337084  0.        ]\n",
      " [-0.09618025 -1.29401223  0.        ]]\n",
      "[]\n",
      "[[-0.5421244   0.00938834]\n",
      " [ 0.32933303 -0.75505189]\n",
      " [ 0.83872164  2.03652562]]\n",
      "SOFTMAX_LAYER\n",
      "[0.32913482954439294, 0.67086517045560701]\n",
      "LOSS PER INSTANCE: 0.399187\n",
      "DERIVATIVE LOSS: -1.490612\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.399187\n",
      "EPOCH 89\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.49329703 -0.8377576   0.        ]\n",
      " [ 1.89341158  0.99360382  0.        ]\n",
      " [-0.09705796 -1.29424521  0.        ]]\n",
      "[]\n",
      "[[-0.54035388  0.0103153 ]\n",
      " [ 0.33369317 -0.75276911]\n",
      " [ 0.85548966  2.0453046 ]]\n",
      "SOFTMAX_LAYER\n",
      "[0.33052446560936466, 0.66947553439063534]\n",
      "LOSS PER INSTANCE: 0.401261\n",
      "DERIVATIVE LOSS: -1.493707\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.401261\n",
      "EPOCH 90\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.49416376 -0.83754564  0.        ]\n",
      " [ 1.89427831  0.99381579  0.        ]\n",
      " [-0.09792469 -1.29445718  0.        ]]\n",
      "[]\n",
      "[[-0.53859852  0.01123433]\n",
      " [ 0.33802409 -0.75050165]\n",
      " [ 0.87215472  2.05402964]]\n",
      "SOFTMAX_LAYER\n",
      "[0.33191025780228722, 0.66808974219771278]\n",
      "LOSS PER INSTANCE: 0.403333\n",
      "DERIVATIVE LOSS: -1.496805\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.403333\n",
      "EPOCH 91\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.49501959 -0.83735413  0.        ]\n",
      " [ 1.89513414  0.9940073   0.        ]\n",
      " [-0.09878052 -1.29464868  0.        ]]\n",
      "[]\n",
      "[[-0.5368583   0.01214554]\n",
      " [ 0.34232572 -0.74824922]\n",
      " [ 0.88871565  2.06270131]]\n",
      "SOFTMAX_LAYER\n",
      "[0.33329180217929461, 0.66670819782070534]\n",
      "LOSS PER INSTANCE: 0.405403\n",
      "DERIVATIVE LOSS: -1.499907\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.405403\n",
      "EPOCH 92\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.4958646  -0.83718252  0.        ]\n",
      " [ 1.89597915  0.9941789   0.        ]\n",
      " [-0.09962553 -1.29482029  0.        ]]\n",
      "[]\n",
      "[[-0.53513323  0.01304907]\n",
      " [ 0.34659805 -0.74601155]\n",
      " [ 0.90517137  2.07132015]]\n",
      "SOFTMAX_LAYER\n",
      "[0.3346687107729317, 0.66533128922706819]\n",
      "LOSS PER INSTANCE: 0.407470\n",
      "DERIVATIVE LOSS: -1.503011\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.407470\n",
      "EPOCH 93\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.49669888 -0.83703027  0.        ]\n",
      " [ 1.89681343  0.99433116  0.        ]\n",
      " [-0.10045981 -1.29497255  0.        ]]\n",
      "[]\n",
      "[[-0.5334233   0.01394501]\n",
      " [ 0.35084102 -0.74378838]\n",
      " [ 0.92152089  2.07988673]]\n",
      "SOFTMAX_LAYER\n",
      "[0.33604061148599063, 0.66395938851400937]\n",
      "LOSS PER INSTANCE: 0.409534\n",
      "DERIVATIVE LOSS: -1.506116\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.409534\n",
      "EPOCH 94\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.49752252 -0.83689683  0.        ]\n",
      " [ 1.89763707  0.99446459  0.        ]\n",
      " [-0.10128345 -1.29510598  0.        ]]\n",
      "[]\n",
      "[[-0.5317285   0.01483348]\n",
      " [ 0.35505464 -0.74157945]\n",
      " [ 0.93776329  2.08840155]]\n",
      "SOFTMAX_LAYER\n",
      "[0.33740714795981464, 0.66259285204018525]\n",
      "LOSS PER INSTANCE: 0.411595\n",
      "DERIVATIVE LOSS: -1.509222\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.411595\n",
      "EPOCH 95\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.49833561 -0.8367817   0.        ]\n",
      " [ 1.89845017  0.99457972  0.        ]\n",
      " [-0.10209655 -1.29522111  0.        ]]\n",
      "[]\n",
      "[[-0.5300488   0.0157146 ]\n",
      " [ 0.3592389  -0.73938453]\n",
      " [ 0.95389774  2.09686514]]\n",
      "SOFTMAX_LAYER\n",
      "[0.33876797941848835, 0.66123202058151154]\n",
      "LOSS PER INSTANCE: 0.413650\n",
      "DERIVATIVE LOSS: -1.512328\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.413650\n",
      "EPOCH 96\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.49913826 -0.83668436  0.        ]\n",
      " [ 1.89925281  0.99467707  0.        ]\n",
      " [-0.10289919 -1.29531846  0.        ]]\n",
      "[]\n",
      "[[-0.52838417  0.01658846]\n",
      " [ 0.3633938  -0.73720338]\n",
      " [ 0.96992349  2.10527801]]\n",
      "SOFTMAX_LAYER\n",
      "[0.34012278049037292, 0.65987721950962708]\n",
      "LOSS PER INSTANCE: 0.415701\n",
      "DERIVATIVE LOSS: -1.515433\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.415701\n",
      "EPOCH 97\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.49993055 -0.8366043   0.        ]\n",
      " [ 1.9000451   0.99475712  0.        ]\n",
      " [-0.10369148 -1.29539851  0.        ]]\n",
      "[]\n",
      "[[-0.52673458  0.01745517]\n",
      " [ 0.36751938 -0.73503576]\n",
      " [ 0.98583987  2.11364065]]\n",
      "SOFTMAX_LAYER\n",
      "[0.34147124100847526, 0.65852875899152474]\n",
      "LOSS PER INSTANCE: 0.417747\n",
      "DERIVATIVE LOSS: -1.518537\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.417747\n",
      "EPOCH 98\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.50071258 -0.83654105  0.        ]\n",
      " [ 1.90082714  0.99482037  0.        ]\n",
      " [-0.10447351 -1.29546176  0.        ]]\n",
      "[]\n",
      "[[-0.52509997  0.01831484]\n",
      " [ 0.37161565 -0.73288145]\n",
      " [ 1.00164629  2.12195355]]\n",
      "SOFTMAX_LAYER\n",
      "[0.34281306579115861, 0.65718693420884133]\n",
      "LOSS PER INSTANCE: 0.419787\n",
      "DERIVATIVE LOSS: -1.521637\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.419787\n",
      "EPOCH 99\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.50148447 -0.83649413  0.        ]\n",
      " [ 1.90159902  0.9948673   0.        ]\n",
      " [-0.1052454  -1.29550868  0.        ]]\n",
      "[]\n",
      "[[-0.52348032  0.01916756]\n",
      " [ 0.37568266 -0.73074024]\n",
      " [ 1.01734221  2.13021718]]\n",
      "SOFTMAX_LAYER\n",
      "[0.34414797440470607, 0.65585202559529387]\n",
      "LOSS PER INSTANCE: 0.421820\n",
      "DERIVATIVE LOSS: -1.524734\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.421820\n"
     ]
    }
   ],
   "source": [
    "class SigmoidNN(NN):\n",
    "    def _activate(self, x):\n",
    "        \"\"\"\n",
    "        override RelU with sigmoid\n",
    "        \"\"\"\n",
    "        return self._sigmoid(x)\n",
    "    \n",
    "    def _derivative_activation(self, x):\n",
    "        \"\"\"\n",
    "        Override RelU' with Sigmoid'\n",
    "        \"\"\"\n",
    "        return self._derivative_sigmoid(x)\n",
    "    \n",
    "\"\"\"\n",
    "Run the same test with sigmoid\n",
    "\"\"\"\n",
    "MLP = SigmoidNN(2, 1, 2, 2)\n",
    "xor_inputs = [[1, 1], [-1, 1], [-1, -1], [1, -1]]\n",
    "xor_labels = ([1, 0, 1, 0])\n",
    "MLP.train(xor_inputs, xor_labels, epochs=100, lr=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.79098598 -0.05572377  0.        ]\n",
      " [ 0.08511857  0.25775903  0.        ]\n",
      " [-0.18411189 -1.29343291  0.        ]]\n",
      "[]\n",
      "[[ 0.59895566 -0.9057812 ]\n",
      " [ 0.34696668  0.45134984]\n",
      " [-0.47357902 -0.41719315]]\n",
      "SOFTMAX_LAYER\n",
      "[0.68401889935143889, 0.31598110064856111]\n",
      "LOSS PER INSTANCE: 1.152073\n",
      "DERIVATIVE LOSS: -3.164746\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 1.152073\n",
      "EPOCH 1\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.81341844 -0.01999502  0.        ]\n",
      " [ 0.06268612  0.29348778  0.        ]\n",
      " [-0.16167943 -1.32916166  0.        ]]\n",
      "[]\n",
      "[[ 0.63180385 -0.90036212]\n",
      " [ 0.28495804  0.44112007]\n",
      " [-0.42135735 -0.40857797]]\n",
      "SOFTMAX_LAYER\n",
      "[0.72012928543371213, 0.27987071456628787]\n",
      "LOSS PER INSTANCE: 1.273428\n",
      "DERIVATIVE LOSS: -3.573078\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 1.273428\n",
      "EPOCH 2\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.84084877  0.03564171  0.        ]\n",
      " [ 0.03525579  0.34912451  0.        ]\n",
      " [-0.1342491  -1.38479839  0.        ]]\n",
      "[]\n",
      "[[ 0.68169967 -0.89003912]\n",
      " [ 0.19802291  0.42313397]\n",
      " [-0.34955207 -0.3937221 ]]\n",
      "SOFTMAX_LAYER\n",
      "[0.76257873597637182, 0.23742126402362818]\n",
      "LOSS PER INSTANCE: 1.437919\n",
      "DERIVATIVE LOSS: -4.211923\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 1.437919\n",
      "EPOCH 3\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.87307498  0.11599721  0.        ]\n",
      " [ 0.00302957  0.42948002  0.        ]\n",
      " [-0.10202289 -1.46515389  0.        ]]\n",
      "[]\n",
      "[[ 0.75530196 -0.87228351]\n",
      " [ 0.07948279  0.39453767]\n",
      " [-0.25387262 -0.37064065]]\n",
      "SOFTMAX_LAYER\n",
      "[0.80906477320886983, 0.19093522679113026]\n",
      "LOSS PER INSTANCE: 1.655821\n",
      "DERIVATIVE LOSS: -5.237378\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 1.655821\n",
      "EPOCH 4\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.90298622  0.19831474  0.        ]\n",
      " [-0.02688166  0.51179754  0.        ]\n",
      " [-0.07211165 -1.54747142  0.        ]]\n",
      "[]\n",
      "[[ 0.84737555 -0.84654949]\n",
      " [-0.0580721   0.3560919 ]\n",
      " [-0.14528623 -0.3402914 ]]\n",
      "SOFTMAX_LAYER\n",
      "[0.84956080330496764, 0.15043919669503236]\n",
      "LOSS PER INSTANCE: 1.894196\n",
      "DERIVATIVE LOSS: -6.647204\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 1.894196\n",
      "EPOCH 5\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.91746122  0.22804052  0.        ]\n",
      " [-0.04135666  0.54152332  0.        ]\n",
      " [-0.05763665 -1.5771972   0.        ]]\n",
      "[]\n",
      "[[ 0.91795857 -0.82087468]\n",
      " [-0.15741773  0.3199546 ]\n",
      " [-0.06795113 -0.3121605 ]]\n",
      "SOFTMAX_LAYER\n",
      "[0.87002974310729631, 0.12997025689270364]\n",
      "LOSS PER INSTANCE: 2.040450\n",
      "DERIVATIVE LOSS: -7.694068\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.040450\n",
      "EPOCH 6\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92130694  0.22904151  0.        ]\n",
      " [-0.04520238  0.54252431  0.        ]\n",
      " [-0.05379093 -1.57819819  0.        ]]\n",
      "[]\n",
      "[[ 0.94729737 -0.8059424 ]\n",
      " [-0.19760133  0.29950275]\n",
      " [-0.03678205 -0.29629668]]\n",
      "SOFTMAX_LAYER\n",
      "[0.87570640455008864, 0.12429359544991141]\n",
      "LOSS PER INSTANCE: 2.085109\n",
      "DERIVATIVE LOSS: -8.045467\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.085109\n",
      "EPOCH 7\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92273965  0.22753866  0.        ]\n",
      " [-0.0466351   0.54102147  0.        ]\n",
      " [-0.05235822 -1.57669534  0.        ]]\n",
      "[]\n",
      "[[ 0.96066168 -0.79792686]\n",
      " [-0.21576668  0.28860767]\n",
      " [-0.02269333 -0.28784665]]\n",
      "SOFTMAX_LAYER\n",
      "[0.87774026291280327, 0.12225973708719674]\n",
      "LOSS PER INSTANCE: 2.101608\n",
      "DERIVATIVE LOSS: -8.179308\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.101608\n",
      "EPOCH 8\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92346817  0.22631239  0.        ]\n",
      " [-0.04736361  0.5397952   0.        ]\n",
      " [-0.0516297  -1.57546907  0.        ]]\n",
      "[]\n",
      "[[ 0.96827451 -0.79291944]\n",
      " [-0.22608342  0.28182172]\n",
      " [-0.01469053 -0.28258273]]\n",
      "SOFTMAX_LAYER\n",
      "[0.87872393393833281, 0.12127606606166712]\n",
      "LOSS PER INSTANCE: 2.109686\n",
      "DERIVATIVE LOSS: -8.245650\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.109686\n",
      "EPOCH 9\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92390526  0.22542768  0.        ]\n",
      " [-0.0478007   0.53891049  0.        ]\n",
      " [-0.05119261 -1.57458436  0.        ]]\n",
      "[]\n",
      "[[ 0.97321814 -0.7894616 ]\n",
      " [-0.23277244  0.27714307]\n",
      " [-0.00950109 -0.27895296]]\n",
      "SOFTMAX_LAYER\n",
      "[0.87928588140695174, 0.12071411859304826]\n",
      "LOSS PER INSTANCE: 2.114330\n",
      "DERIVATIVE LOSS: -8.284035\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.114330\n",
      "EPOCH 10\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.924195    0.22478368  0.        ]\n",
      " [-0.04809044  0.53826649  0.        ]\n",
      " [-0.05090287 -1.57394036  0.        ]]\n",
      "[]\n",
      "[[ 0.97670118 -0.78691363]\n",
      " [-0.23748071  0.2736988 ]\n",
      " [-0.00584799 -0.27628058]]\n",
      "SOFTMAX_LAYER\n",
      "[0.87964150402533992, 0.12035849597466011]\n",
      "LOSS PER INSTANCE: 2.117281\n",
      "DERIVATIVE LOSS: -8.308512\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.117281\n",
      "EPOCH 11\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92440032  0.22430259  0.        ]\n",
      " [-0.04829576  0.53778539  0.        ]\n",
      " [-0.05069755 -1.57345927  0.        ]]\n",
      "[]\n",
      "[[ 0.9792948  -0.78494946]\n",
      " [-0.24098445  0.2710454 ]\n",
      " [-0.00312927 -0.27422168]]\n",
      "SOFTMAX_LAYER\n",
      "[0.87988270003791103, 0.12011729996208897]\n",
      "LOSS PER INSTANCE: 2.119287\n",
      "DERIVATIVE LOSS: -8.325195\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.119287\n",
      "EPOCH 12\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92455295  0.22393371  0.        ]\n",
      " [-0.04844839  0.53741652  0.        ]\n",
      " [-0.05054492 -1.57309039  0.        ]]\n",
      "[]\n",
      "[[ 0.98130497 -0.78338429]\n",
      " [-0.24369876  0.26893195]\n",
      " [-0.00102299 -0.27258167]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88005469953363868, 0.11994530046636132]\n",
      "LOSS PER INSTANCE: 2.120719\n",
      "DERIVATIVE LOSS: -8.337134\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.120719\n",
      "EPOCH 13\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92467057  0.22364426  0.        ]\n",
      " [-0.04856601  0.53712706  0.        ]\n",
      " [-0.0504273  -1.57280094  0.        ]]\n",
      "[]\n",
      "[[  9.82910878e-01  -7.82104927e-01]\n",
      " [ -2.45866477e-01   2.67205024e-01]\n",
      " [  6.59198922e-04  -2.71241539e-01]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88018211294621973, 0.1198178870537803]\n",
      "LOSS PER INSTANCE: 2.121782\n",
      "DERIVATIVE LOSS: -8.345999\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.121782\n",
      "EPOCH 14\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.9247638   0.22341255  0.        ]\n",
      " [-0.04865924  0.53689535  0.        ]\n",
      " [-0.05033407 -1.57256923  0.        ]]\n",
      "[]\n",
      "[[ 0.98422468 -0.7810379 ]\n",
      " [-0.24763943  0.26576509]\n",
      " [ 0.00203509 -0.27012408]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88027936634755832, 0.11972063365244172]\n",
      "LOSS PER INSTANCE: 2.122594\n",
      "DERIVATIVE LOSS: -8.352779\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.122594\n",
      "EPOCH 15\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.9248394   0.22322386  0.        ]\n",
      " [-0.04873484  0.53670667  0.        ]\n",
      " [-0.05025847 -1.57238054  0.        ]]\n",
      "[]\n",
      "[[ 0.98532028 -0.78013326]\n",
      " [-0.24911762  0.26454455]\n",
      " [ 0.00318227 -0.26917686]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88035541708595033, 0.11964458291404968]\n",
      "LOSS PER INSTANCE: 2.123230\n",
      "DERIVATIVE LOSS: -8.358088\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.123230\n",
      "EPOCH 16\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92490185  0.22306792  0.        ]\n",
      " [-0.04879729  0.53655072  0.        ]\n",
      " [-0.05019602 -1.5722246   0.        ]]\n",
      "[]\n",
      "[[ 0.98624844 -0.77935582]\n",
      " [-0.25036969  0.26349579]\n",
      " [ 0.00415397 -0.26836294]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88041608825207707, 0.11958391174792292]\n",
      "LOSS PER INSTANCE: 2.123737\n",
      "DERIVATIVE LOSS: -8.362329\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.123737\n",
      "EPOCH 17\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92495425  0.22293737  0.        ]\n",
      " [-0.04884969  0.53642018  0.        ]\n",
      " [-0.05014362 -1.57209405  0.        ]]\n",
      "[]\n",
      "[[ 0.9870452  -0.77867998]\n",
      " [-0.25144435  0.26258422]\n",
      " [ 0.00498802 -0.26765547]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88046531015647156, 0.11953468984352834]\n",
      "LOSS PER INSTANCE: 2.124149\n",
      "DERIVATIVE LOSS: -8.365772\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.124149\n",
      "EPOCH 18\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.9249988   0.22282685  0.        ]\n",
      " [-0.04889424  0.53630965  0.        ]\n",
      " [-0.05009907 -1.57198353  0.        ]]\n",
      "[]\n",
      "[[ 0.9877369  -0.77808667]\n",
      " [-0.2523772   0.26178407]\n",
      " [ 0.00571201 -0.26703447]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88050581986285315, 0.11949418013714687]\n",
      "LOSS PER INSTANCE: 2.124488\n",
      "DERIVATIVE LOSS: -8.368608\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.124488\n",
      "EPOCH 19\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92503711  0.22273234  0.        ]\n",
      " [-0.04893255  0.53621515  0.        ]\n",
      " [-0.05006076 -1.57188902  0.        ]]\n",
      "[]\n",
      "[[ 0.98834323 -0.77756138]\n",
      " [-0.25319483  0.26107571]\n",
      " [ 0.00634659 -0.2664847 ]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88053957463191745, 0.11946042536808257]\n",
      "LOSS PER INSTANCE: 2.124770\n",
      "DERIVATIVE LOSS: -8.370973\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.124770\n",
      "EPOCH 20\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92507039  0.22265082  0.        ]\n",
      " [-0.04896583  0.53613363  0.        ]\n",
      " [-0.05002749 -1.5718075   0.        ]]\n",
      "[]\n",
      "[[ 0.98887921 -0.77709284]\n",
      " [-0.25391754  0.26044394]\n",
      " [ 0.0069075  -0.26599437]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88056800628578524, 0.11943199371421472]\n",
      "LOSS PER INSTANCE: 2.125008\n",
      "DERIVATIVE LOSS: -8.372966\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.125008\n",
      "EPOCH 21\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92509954  0.22257995  0.        ]\n",
      " [-0.04899498  0.53606275  0.        ]\n",
      " [-0.04999833 -1.57173663  0.        ]]\n",
      "[]\n",
      "[[ 0.98935652 -0.77667217]\n",
      " [-0.25456109  0.25987677]\n",
      " [ 0.00740699 -0.26555416]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88059218315285837, 0.11940781684714158]\n",
      "LOSS PER INSTANCE: 2.125211\n",
      "DERIVATIVE LOSS: -8.374661\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.125211\n",
      "EPOCH 22\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92512527  0.22251789  0.        ]\n",
      " [-0.04902072  0.53600069  0.        ]\n",
      " [-0.0499726  -1.57167457  0.        ]]\n",
      "[]\n",
      "[[ 0.98978439 -0.77629229]\n",
      " [-0.25513794  0.25936461]\n",
      " [ 0.0078547  -0.26515665]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88061291626731619, 0.11938708373268385]\n",
      "LOSS PER INSTANCE: 2.125384\n",
      "DERIVATIVE LOSS: -8.376115\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.125384\n",
      "EPOCH 23\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92514815  0.22246321  0.        ]\n",
      " [-0.0490436   0.53594601  0.        ]\n",
      " [-0.04994972 -1.57161989  0.        ]]\n",
      "[]\n",
      "[[ 0.99017017 -0.77594743]\n",
      " [-0.25565802  0.2588997 ]\n",
      " [ 0.00825836 -0.26479582]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88063083083358495, 0.11936916916641507]\n",
      "LOSS PER INSTANCE: 2.125534\n",
      "DERIVATIVE LOSS: -8.377373\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.125534\n",
      "EPOCH 24\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92516862  0.22241474  0.        ]\n",
      " [-0.04906406  0.53589755  0.        ]\n",
      " [-0.04992925 -1.57157142  0.        ]]\n",
      "[]\n",
      "[[ 0.99051984 -0.77563291]\n",
      " [-0.2561294   0.2584757 ]\n",
      " [ 0.00862422 -0.26446673]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88064641542296129, 0.11935358457703865]\n",
      "LOSS PER INSTANCE: 2.125665\n",
      "DERIVATIVE LOSS: -8.378466\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.125665\n",
      "EPOCH 25\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92518702  0.22237156  0.        ]\n",
      " [-0.04908246  0.53585437  0.        ]\n",
      " [-0.04991085 -1.57152824  0.        ]]\n",
      "[]\n",
      "[[ 0.99083828 -0.77534482]\n",
      " [-0.25655865  0.25808736]\n",
      " [ 0.00895738 -0.26416532]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88066005653182433, 0.1193399434681756]\n",
      "LOSS PER INSTANCE: 2.125779\n",
      "DERIVATIVE LOSS: -8.379424\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.125779\n",
      "EPOCH 26\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92520366  0.2223329   0.        ]\n",
      " [-0.0490991   0.53581571  0.        ]\n",
      " [-0.04989422 -1.57148958  0.        ]]\n",
      "[]\n",
      "[[ 0.99112952 -0.77507993]\n",
      " [-0.25695123  0.2577303 ]\n",
      " [ 0.00926209 -0.26388819]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88067206329945524, 0.11932793670054472]\n",
      "LOSS PER INSTANCE: 2.125880\n",
      "DERIVATIVE LOSS: -8.380267\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.125880\n",
      "EPOCH 27\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92521876  0.22229814  0.        ]\n",
      " [-0.0491142   0.53578094  0.        ]\n",
      " [-0.04987911 -1.57145482  0.        ]]\n",
      "[]\n",
      "[[ 0.99139694 -0.7748355 ]\n",
      " [-0.25731168  0.25740084]\n",
      " [ 0.00954185 -0.26363247]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88068268547712103, 0.11931731452287904]\n",
      "LOSS PER INSTANCE: 2.125969\n",
      "DERIVATIVE LOSS: -8.381013\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.125969\n",
      "EPOCH 28\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92523253  0.22226675  0.        ]\n",
      " [-0.04912798  0.53574955  0.        ]\n",
      " [-0.04986534 -1.57142343  0.        ]]\n",
      "[]\n",
      "[[ 0.99164336 -0.77460922]\n",
      " [-0.25764381  0.25709585]\n",
      " [ 0.00979965 -0.26339575]]\n",
      "SOFTMAX_LAYER\n",
      "[0.8806921266845017, 0.11930787331549826]\n",
      "LOSS PER INSTANCE: 2.126048\n",
      "DERIVATIVE LOSS: -8.381677\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126048\n",
      "EPOCH 29\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92524514  0.22223829  0.        ]\n",
      " [-0.04914059  0.5357211   0.        ]\n",
      " [-0.04985273 -1.57139497  0.        ]]\n",
      "[]\n",
      "[[ 0.99187118 -0.77439912]\n",
      " [-0.25795087  0.25681268]\n",
      " [ 0.01003797 -0.26317596]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88070055432103878, 0.11929944567896113]\n",
      "LOSS PER INSTANCE: 2.126119\n",
      "DERIVATIVE LOSS: -8.382269\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126119\n",
      "EPOCH 30\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92525672  0.22221241  0.        ]\n",
      " [-0.04915217  0.53569522  0.        ]\n",
      " [-0.04984115 -1.57136909  0.        ]]\n",
      "[]\n",
      "[[ 0.99208244 -0.7742035 ]\n",
      " [-0.2582356   0.25654903]\n",
      " [ 0.01025897 -0.26297132]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88070810706732372, 0.11929189293267627]\n",
      "LOSS PER INSTANCE: 2.126182\n",
      "DERIVATIVE LOSS: -8.382799\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126182\n",
      "EPOCH 31\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.9252674   0.22218879  0.        ]\n",
      " [-0.04916284  0.5356716   0.        ]\n",
      " [-0.04983047 -1.57134547  0.        ]]\n",
      "[]\n",
      "[[ 0.9922789  -0.77402089]\n",
      " [-0.25850038  0.25630292]\n",
      " [ 0.01046449 -0.2627803 ]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88071490062644753, 0.11928509937355247]\n",
      "LOSS PER INSTANCE: 2.126239\n",
      "DERIVATIVE LOSS: -8.383277\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126239\n",
      "EPOCH 32\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92527727  0.22216718  0.        ]\n",
      " [-0.04917271  0.53564998  0.        ]\n",
      " [-0.04982061 -1.57132386  0.        ]]\n",
      "[]\n",
      "[[ 0.99246207 -0.77385003]\n",
      " [-0.25874723  0.25607265]\n",
      " [ 0.01065609 -0.26260157]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88072103216379849, 0.11927896783620147]\n",
      "LOSS PER INSTANCE: 2.126290\n",
      "DERIVATIVE LOSS: -8.383708\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126290\n",
      "EPOCH 33\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92528641  0.22214733  0.        ]\n",
      " [-0.04918185  0.53563013  0.        ]\n",
      " [-0.04981146 -1.57130401  0.        ]]\n",
      "[]\n",
      "[[ 0.99263326 -0.7736898 ]\n",
      " [-0.25897795  0.25585671]\n",
      " [ 0.01083516 -0.26243396]]\n",
      "SOFTMAX_LAYER\n",
      "[0.880726583773215, 0.11927341622678507]\n",
      "LOSS PER INSTANCE: 2.126337\n",
      "DERIVATIVE LOSS: -8.384098\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126337\n",
      "EPOCH 34\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92529491  0.22212907  0.        ]\n",
      " [-0.04919036  0.53561187  0.        ]\n",
      " [-0.04980296 -1.57128575  0.        ]]\n",
      "[]\n",
      "[[ 0.99279362 -0.77353923]\n",
      " [-0.25919405  0.2556538 ]\n",
      " [ 0.0110029  -0.26227647]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88073162520699311, 0.11926837479300681]\n",
      "LOSS PER INSTANCE: 2.126379\n",
      "DERIVATIVE LOSS: -8.384452\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126379\n",
      "EPOCH 35\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92530283  0.22211221  0.        ]\n",
      " [-0.04919828  0.53559501  0.        ]\n",
      " [-0.04979504 -1.57126889  0.        ]]\n",
      "[]\n",
      "[[ 0.99294415 -0.77339747]\n",
      " [-0.25939691  0.25546275]\n",
      " [ 0.01116036 -0.26212818]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88073621604379759, 0.11926378395620245]\n",
      "LOSS PER INSTANCE: 2.126418\n",
      "DERIVATIVE LOSS: -8.384775\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126418\n",
      "EPOCH 36\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92531023  0.22209662  0.        ]\n",
      " [-0.04920567  0.53557943  0.        ]\n",
      " [-0.04978764 -1.5712533   0.        ]]\n",
      "[]\n",
      "[[ 0.99308574 -0.77326374]\n",
      " [-0.25958771  0.25528255]\n",
      " [ 0.01130845 -0.26198831]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88074040742340731, 0.11925959257659265]\n",
      "LOSS PER INSTANCE: 2.126453\n",
      "DERIVATIVE LOSS: -8.385070\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126453\n",
      "EPOCH 37\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92531715  0.22208217  0.        ]\n",
      " [-0.0492126   0.53556498  0.        ]\n",
      " [-0.04978072 -1.57123885  0.        ]]\n",
      "[]\n",
      "[[ 0.99321915 -0.7731374 ]\n",
      " [-0.2597675   0.25511229]\n",
      " [ 0.011448   -0.26185615]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88074424344479296, 0.11925575655520711]\n",
      "LOSS PER INSTANCE: 2.126485\n",
      "DERIVATIVE LOSS: -8.385339\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126485\n",
      "EPOCH 38\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92532365  0.22206875  0.        ]\n",
      " [-0.04921909  0.53555155  0.        ]\n",
      " [-0.04977423 -1.57122543  0.        ]]\n",
      "[]\n",
      "[[ 0.99334509 -0.77301782]\n",
      " [-0.2599372   0.25495115]\n",
      " [ 0.01157972 -0.26173108]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88074776230041296, 0.11925223769958708]\n",
      "LOSS PER INSTANCE: 2.126514\n",
      "DERIVATIVE LOSS: -8.385587\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126514\n",
      "EPOCH 39\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92532975  0.22205626  0.        ]\n",
      " [-0.04922519  0.53553906  0.        ]\n",
      " [-0.04976813 -1.57121294  0.        ]]\n",
      "[]\n",
      "[[ 0.99346416 -0.77290448]\n",
      " [-0.26009766  0.25479843]\n",
      " [ 0.01170427 -0.26161254]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88075099720228955, 0.11924900279771042]\n",
      "LOSS PER INSTANCE: 2.126542\n",
      "DERIVATIVE LOSS: -8.385814\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126542\n",
      "EPOCH 40\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92533549  0.22204461  0.        ]\n",
      " [-0.04923093  0.53552741  0.        ]\n",
      " [-0.04976238 -1.57120129  0.        ]]\n",
      "[]\n",
      "[[ 0.99357693 -0.7727969 ]\n",
      " [-0.26024961  0.25465346]\n",
      " [ 0.01182221 -0.26150002]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88075397714255421, 0.11924602285744582]\n",
      "LOSS PER INSTANCE: 2.126567\n",
      "DERIVATIVE LOSS: -8.386024\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126567\n",
      "EPOCH 41\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.9253409   0.22203372  0.        ]\n",
      " [-0.04923634  0.53551653  0.        ]\n",
      " [-0.04975697 -1.5711904   0.        ]]\n",
      "[]\n",
      "[[ 0.99368387 -0.77269465]\n",
      " [-0.26039372  0.25451567]\n",
      " [ 0.01193406 -0.26139307]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88075672752152867, 0.1192432724784713]\n",
      "LOSS PER INSTANCE: 2.126590\n",
      "DERIVATIVE LOSS: -8.386217\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126590\n",
      "EPOCH 42\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92534601  0.22202354  0.        ]\n",
      " [-0.04924145  0.53550634  0.        ]\n",
      " [-0.04975186 -1.57118022  0.        ]]\n",
      "[]\n",
      "[[ 0.99378543 -0.77259733]\n",
      " [-0.26053057  0.25438453]\n",
      " [ 0.01204028 -0.26129128]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88075927066913917, 0.11924072933086081]\n",
      "LOSS PER INSTANCE: 2.126611\n",
      "DERIVATIVE LOSS: -8.386396\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126611\n",
      "EPOCH 43\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92535085  0.22201399  0.        ]\n",
      " [-0.04924629  0.5354968   0.        ]\n",
      " [-0.04974703 -1.57117067  0.        ]]\n",
      "[]\n",
      "[[ 0.99388201 -0.77250459]\n",
      " [-0.26066071  0.25425957]\n",
      " [ 0.01214129 -0.26119429]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88076162627992671, 0.11923837372007333]\n",
      "LOSS PER INSTANCE: 2.126631\n",
      "DERIVATIVE LOSS: -8.386562\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126631\n",
      "EPOCH 44\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92535542  0.22200503  0.        ]\n",
      " [-0.04925087  0.53548784  0.        ]\n",
      " [-0.04974245 -1.57116171  0.        ]]\n",
      "[]\n",
      "[[ 0.99397397 -0.77241612]\n",
      " [-0.26078462  0.25414036]\n",
      " [ 0.01223747 -0.26110176]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88076381177767837, 0.11923618822232161]\n",
      "LOSS PER INSTANCE: 2.126649\n",
      "DERIVATIVE LOSS: -8.386716\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126649\n",
      "EPOCH 45\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92535977  0.22199661  0.        ]\n",
      " [-0.04925521  0.53547941  0.        ]\n",
      " [-0.0497381  -1.57115329  0.        ]]\n",
      "[]\n",
      "[[ 0.99406163 -0.77233162]\n",
      " [-0.26090274  0.25402651]\n",
      " [ 0.01232915 -0.26101339]]\n",
      "SOFTMAX_LAYER\n",
      "[0.8807658426224283, 0.11923415737757166]\n",
      "LOSS PER INSTANCE: 2.126666\n",
      "DERIVATIVE LOSS: -8.386858\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126666\n",
      "EPOCH 46\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92536389  0.22198868  0.        ]\n",
      " [-0.04925933  0.53547148  0.        ]\n",
      " [-0.04973398 -1.57114536  0.        ]]\n",
      "[]\n",
      "[[ 0.99414529 -0.77225084]\n",
      " [-0.26101546  0.25391766]\n",
      " [ 0.01241665 -0.2609289 ]]\n",
      "SOFTMAX_LAYER\n",
      "[0.8807677325700296, 0.11923226742997049]\n",
      "LOSS PER INSTANCE: 2.126682\n",
      "DERIVATIVE LOSS: -8.386991\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126682\n",
      "EPOCH 47\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92536781  0.2219812   0.        ]\n",
      " [-0.04926326  0.53546401  0.        ]\n",
      " [-0.04973006 -1.57113788  0.        ]]\n",
      "[]\n",
      "[[ 0.99422522 -0.77217352]\n",
      " [-0.26112316  0.25381348]\n",
      " [ 0.01250025 -0.26084804]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88076949389250725, 0.11923050610749275]\n",
      "LOSS PER INSTANCE: 2.126697\n",
      "DERIVATIVE LOSS: -8.387115\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126697\n",
      "EPOCH 48\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92537155  0.22197415  0.        ]\n",
      " [-0.04926699  0.53545695  0.        ]\n",
      " [-0.04972632 -1.57113083  0.        ]]\n",
      "[]\n",
      "[[ 0.99430166 -0.77209946]\n",
      " [-0.26122616  0.25371368]\n",
      " [ 0.01258019 -0.26077057]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88077113756583603, 0.11922886243416393]\n",
      "LOSS PER INSTANCE: 2.126710\n",
      "DERIVATIVE LOSS: -8.387231\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126710\n",
      "EPOCH 49\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92537511  0.22196748  0.        ]\n",
      " [-0.04927055  0.53545028  0.        ]\n",
      " [-0.04972276 -1.57112416  0.        ]]\n",
      "[]\n",
      "[[ 0.99437484 -0.77202844]\n",
      " [-0.26132476  0.25361799]\n",
      " [ 0.01265673 -0.2606963 ]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88077267343053955, 0.11922732656946039]\n",
      "LOSS PER INSTANCE: 2.126723\n",
      "DERIVATIVE LOSS: -8.387339\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126723\n"
     ]
    }
   ],
   "source": [
    "class TanHNN(NN):\n",
    "    \n",
    "    def _activate(self, x):\n",
    "        \"\"\"\n",
    "        Override with TanH\n",
    "        \"\"\"\n",
    "        return np.tanh(x)\n",
    "    \n",
    "    def _derivative_activation(self, x):\n",
    "        \"\"\"\n",
    "        Override with Derivative TanH (1 - tanH squared)\n",
    "        \"\"\"\n",
    "        return 1 - x*x\n",
    "    \n",
    "\"\"\"\n",
    "Run the same test with TanH\n",
    "\"\"\"\n",
    "MLP = TanHNN(2, 1, 2, 2)\n",
    "xor_inputs = [[1, 1], [-1, 1], [-1, -1], [1, -1]]\n",
    "xor_labels = ([1, 0, 1, 0])\n",
    "MLP.train(xor_inputs, xor_labels, epochs=50, lr=.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "def neighborhood2int(n):\n",
    "    \"\"\"\n",
    "    For mapping neighborhoods into integer labels\n",
    "    \"\"\"\n",
    "    return 1 if n == \"Blmngtn\" else 0\n",
    "\n",
    "df = pd.DataFrame.from_csv(\"./data/housing_date_train_2_features.csv\")\n",
    "housing_df = df.loc[df['Neighborhood'].isin([\"BrDale\", \"Blmngtn\"])]\n",
    "\n",
    "# Grab X and its labels as a single matrix\n",
    "dataset = housing_df[[\"LotArea\", \"SalePrice\", \"Neighborhood\"]].as_matrix()\n",
    "\n",
    "# 'shuffle' the matrix to randomize the position of each sample in it\n",
    "np.random.shuffle(dataset)\n",
    "\n",
    "# Not sure why shuffling changed the type, but need to \n",
    "# change the type of each scalar in X for some numpy methods to work\n",
    "X = dataset[:, :2].astype('int64')\n",
    "# Encode the labels\n",
    "y = [neighborhood2int(s) for s in dataset[:, 2]]\n",
    "\n",
    "# Find the length of 80% of the dataset for training data\n",
    "train_length = int(X.shape[0] * 0.8)\n",
    "\n",
    "# split 80%/20% for train and test\n",
    "train_X = X[:train_length]\n",
    "test_X = X[train_length:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
