{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "INPUT ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.63089808 -1.76408292  0.        ]\n",
      " [ 0.1052466  -1.41465687  0.        ]\n",
      " [-0.18614852 -0.07818527  0.        ]]\n",
      "[]\n",
      "[[-0.42839324  1.41877988]\n",
      " [ 0.03603064  0.92414088]\n",
      " [-1.61292464  1.52648076]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0014712650071702122, 0.9985287349928299]\n",
      "LOSS PER INSTANCE: 0.001472\n",
      "DERIVATIVE LOSS: -1.001473\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.001472\n",
      "EPOCH 1\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "INPUT ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.64510679 -1.77333795  0.        ]\n",
      " [ 0.0910379  -1.42391189  0.        ]\n",
      " [-0.17193981 -0.06893025  0.        ]]\n",
      "[]\n",
      "[[-0.42839324  1.42217991]\n",
      " [ 0.03603064  0.95519211]\n",
      " [-1.61292464  1.53649549]]\n",
      "SOFTMAX_LAYER\n",
      "[0.001190716340136376, 0.99880928365986354]\n",
      "LOSS PER INSTANCE: 0.001191\n",
      "DERIVATIVE LOSS: -1.001192\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.001191\n",
      "EPOCH 2\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "INPUT ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.65934554 -1.78290126  0.        ]\n",
      " [ 0.07679915 -1.4334752   0.        ]\n",
      " [-0.15770106 -0.05936694  0.        ]]\n",
      "[]\n",
      "[[-0.42839324  1.42600576]\n",
      " [ 0.03603064  0.9865126 ]\n",
      " [-1.61292464  1.54650741]]\n",
      "SOFTMAX_LAYER\n",
      "[0.00095968491344143798, 0.99904031508655855]\n",
      "LOSS PER INSTANCE: 0.000960\n",
      "DERIVATIVE LOSS: -1.000961\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000960\n",
      "EPOCH 3\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "INPUT ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.6736193  -1.79277586  0.        ]\n",
      " [ 0.06252539 -1.4433498   0.        ]\n",
      " [-0.1434273  -0.04949233  0.        ]]\n",
      "[]\n",
      "[[-0.42839324  1.43025829]\n",
      " [ 0.03603064  1.01811302]\n",
      " [-1.61292464  1.55651702]]\n",
      "SOFTMAX_LAYER\n",
      "[0.00077010957788204999, 0.99922989042211796]\n",
      "LOSS PER INSTANCE: 0.000770\n",
      "DERIVATIVE LOSS: -1.000771\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000770\n",
      "EPOCH 4\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "INPUT ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.6879329  -1.80296484  0.        ]\n",
      " [ 0.04821178 -1.45353878  0.        ]\n",
      " [-0.1291137  -0.03930336  0.        ]]\n",
      "[]\n",
      "[[-0.42839324  1.43493856]\n",
      " [ 0.03603064  1.05000392]\n",
      " [-1.61292464  1.56652472]]\n",
      "SOFTMAX_LAYER\n",
      "[0.00061514606759842134, 0.99938485393240162]\n",
      "LOSS PER INSTANCE: 0.000615\n",
      "DERIVATIVE LOSS: -1.000616\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000615\n",
      "EPOCH 5\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "INPUT ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.70229112 -1.81347134  0.        ]\n",
      " [ 0.03385357 -1.46404528  0.        ]\n",
      " [-0.11475548 -0.02879686  0.        ]]\n",
      "[]\n",
      "[[-0.42839324  1.44004778]\n",
      " [ 0.03603064  1.08219572]\n",
      " [-1.61292464  1.57653088]]\n",
      "SOFTMAX_LAYER\n",
      "[0.00048899216689504157, 0.99951100783310498]\n",
      "LOSS PER INSTANCE: 0.000489\n",
      "DERIVATIVE LOSS: -1.000489\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000489\n",
      "EPOCH 6\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "INPUT ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.71669864 -1.82429859  0.        ]\n",
      " [ 0.01944604 -1.47487253  0.        ]\n",
      " [-0.10034796 -0.0179696   0.        ]]\n",
      "[]\n",
      "[[-0.42839324  1.44558731]\n",
      " [ 0.03603064  1.11469881]\n",
      " [-1.61292464  1.58653577]]\n",
      "SOFTMAX_LAYER\n",
      "[0.00038673821434658765, 0.99961326178565346]\n",
      "LOSS PER INSTANCE: 0.000387\n",
      "DERIVATIVE LOSS: -1.000387\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000387\n",
      "EPOCH 7\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "INPUT ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.73116011 -1.83544989  0.        ]\n",
      " [ 0.00498458 -1.48602383  0.        ]\n",
      " [-0.08588649 -0.0068183   0.        ]]\n",
      "[]\n",
      "[[-0.42839324  1.45155866]\n",
      " [ 0.03603064  1.14752352]\n",
      " [-1.61292464  1.59653964]]\n",
      "SOFTMAX_LAYER\n",
      "[0.0003042389772523754, 0.99969576102274771]\n",
      "LOSS PER INSTANCE: 0.000304\n",
      "DERIVATIVE LOSS: -1.000304\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000304\n",
      "EPOCH 8\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "INPUT ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.74568011 -1.84692862  0.        ]\n",
      " [-0.00953543 -1.49750256  0.        ]\n",
      " [-0.07136649  0.00466042  0.        ]]\n",
      "[]\n",
      "[[-0.42839324  1.4579635 ]\n",
      " [ 0.03603064  1.18068016]\n",
      " [-1.61292464  1.60654268]]\n",
      "SOFTMAX_LAYER\n",
      "[0.00023800360925606094, 0.99976199639074392]\n",
      "LOSS PER INSTANCE: 0.000238\n",
      "DERIVATIVE LOSS: -1.000238\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000238\n",
      "EPOCH 9\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "INPUT ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.76026322 -1.85873823  0.        ]\n",
      " [-0.02411853 -1.50931217  0.        ]\n",
      " [-0.05678338  0.01647004  0.        ]]\n",
      "[]\n",
      "[[-0.42839324  1.46480362]\n",
      " [ 0.03603064  1.21417905]\n",
      " [-1.61292464  1.61654506]]\n",
      "SOFTMAX_LAYER\n",
      "[0.00018510096206790315, 0.99981489903793219]\n",
      "LOSS PER INSTANCE: 0.000185\n",
      "DERIVATIVE LOSS: -1.000185\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000185\n",
      "EPOCH 10\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "INPUT ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.77491397 -1.87088227  0.        ]\n",
      " [-0.03876928 -1.52145621  0.        ]\n",
      " [-0.04213263  0.02861408  0.        ]]\n",
      "[]\n",
      "[[-0.42839324  1.47208095]\n",
      " [ 0.03603064  1.24803052]\n",
      " [-1.61292464  1.62654692]]\n",
      "SOFTMAX_LAYER\n",
      "[0.00014307798102686822, 0.99985692201897303]\n",
      "LOSS PER INSTANCE: 0.000143\n",
      "DERIVATIVE LOSS: -1.000143\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000143\n",
      "EPOCH 11\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "INPUT ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.78963688 -1.88336436  0.        ]\n",
      " [-0.0534922  -1.5339383   0.        ]\n",
      " [-0.02740972  0.04109617  0.        ]]\n",
      "[]\n",
      "[[-0.42839324  1.47979756]\n",
      " [ 0.03603064  1.28224494]\n",
      " [-1.61292464  1.63654835]]\n",
      "SOFTMAX_LAYER\n",
      "[0.000109889291637251, 0.99989011070836287]\n",
      "LOSS PER INSTANCE: 0.000110\n",
      "DERIVATIVE LOSS: -1.000110\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000110\n",
      "EPOCH 12\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "INPUT ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.80443649 -1.89618822  0.        ]\n",
      " [-0.0682918  -1.54676216  0.        ]\n",
      " [-0.01261012  0.05392002  0.        ]]\n",
      "[]\n",
      "[[-0.42839324  1.48795565]\n",
      " [ 0.03603064  1.31683273]\n",
      " [-1.61292464  1.64654945]]\n",
      "SOFTMAX_LAYER\n",
      "[8.3836394686329817e-05, 0.99991616360531366]\n",
      "LOSS PER INSTANCE: 0.000084\n",
      "DERIVATIVE LOSS: -1.000084\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000084\n",
      "EPOCH 13\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "INPUT ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.81931729 -1.90935765  0.        ]\n",
      " [-0.0831726  -1.55993159  0.        ]\n",
      " [ 0.00227069  0.06708946  0.        ]]\n",
      "[]\n",
      "[[-0.42839324  1.49655755]\n",
      " [ 0.03603064  1.35180437]\n",
      " [-1.61292464  1.65655028]]\n",
      "SOFTMAX_LAYER\n",
      "[6.3515142868692047e-05, 0.99993648485713127]\n",
      "LOSS PER INSTANCE: 0.000064\n",
      "DERIVATIVE LOSS: -1.000064\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000064\n",
      "EPOCH 14\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "INPUT ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.83428382 -1.92287655  0.        ]\n",
      " [-0.09813913 -1.5734505   0.        ]\n",
      " [ 0.01723721  0.08060836  0.        ]]\n",
      "[]\n",
      "[[-0.42839324  1.50560573]\n",
      " [ 0.03603064  1.3871704 ]\n",
      " [-1.61292464  1.66655092]]\n",
      "SOFTMAX_LAYER\n",
      "[4.7770381648293845e-05, 0.99995222961835162]\n",
      "LOSS PER INSTANCE: 0.000048\n",
      "DERIVATIVE LOSS: -1.000048\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000048\n",
      "EPOCH 15\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "INPUT ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.84934059 -1.93674892  0.        ]\n",
      " [-0.1131959  -1.58732286  0.        ]\n",
      " [ 0.03229399  0.09448073  0.        ]]\n",
      "[]\n",
      "[[-0.42839324  1.51510279]\n",
      " [ 0.03603064  1.42294146]\n",
      " [-1.61292464  1.6765514 ]]\n",
      "SOFTMAX_LAYER\n",
      "[3.5656809328333103e-05, 0.99996434319067173]\n",
      "LOSS PER INSTANCE: 0.000036\n",
      "DERIVATIVE LOSS: -1.000036\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000036\n",
      "EPOCH 16\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "INPUT ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.86449216 -1.95097884  0.        ]\n",
      " [-0.12834747 -1.60155279  0.        ]\n",
      " [ 0.04744556  0.10871065  0.        ]]\n",
      "[]\n",
      "[[-0.42839324  1.52505145]\n",
      " [ 0.03603064  1.45912828]\n",
      " [-1.61292464  1.68655175]]\n",
      "SOFTMAX_LAYER\n",
      "[2.6405252568757093e-05, 0.9999735947474313]\n",
      "LOSS PER INSTANCE: 0.000026\n",
      "DERIVATIVE LOSS: -1.000026\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000026\n",
      "EPOCH 17\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "INPUT ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.87974308 -1.96557051  0.        ]\n",
      " [-0.14359839 -1.61614445  0.        ]\n",
      " [ 0.06269648  0.12330232  0.        ]]\n",
      "[]\n",
      "[[-0.42839324  1.53545458]\n",
      " [ 0.03603064  1.49574167]\n",
      " [-1.61292464  1.69655202]]\n",
      "SOFTMAX_LAYER\n",
      "[1.9393669402263637e-05, 0.99998060633059771]\n",
      "LOSS PER INSTANCE: 0.000019\n",
      "DERIVATIVE LOSS: -1.000019\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000019\n",
      "EPOCH 18\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "INPUT ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.89509792 -1.98052822  0.        ]\n",
      " [-0.15895323 -1.63110216  0.        ]\n",
      " [ 0.07805132  0.13826002  0.        ]]\n",
      "[]\n",
      "[[-0.42839324  1.54631517]\n",
      " [ 0.03603064  1.53279256]\n",
      " [-1.61292464  1.70655221]]\n",
      "SOFTMAX_LAYER\n",
      "[1.4122286777968402e-05, 0.999985877713222]\n",
      "LOSS PER INSTANCE: 0.000014\n",
      "DERIVATIVE LOSS: -1.000014\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000014\n",
      "EPOCH 19\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "INPUT ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.91056129 -1.99585636  0.        ]\n",
      " [-0.1744166  -1.6464303   0.        ]\n",
      " [ 0.09351469  0.15358816  0.        ]]\n",
      "[]\n",
      "[[-0.42839324  1.55763635]\n",
      " [ 0.03603064  1.57029199]\n",
      " [-1.61292464  1.71655235]]\n",
      "SOFTMAX_LAYER\n",
      "[1.019235770318732e-05, 0.99998980764229672]\n",
      "LOSS PER INSTANCE: 0.000010\n",
      "DERIVATIVE LOSS: -1.000010\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000010\n",
      "EPOCH 20\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "INPUT ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92613781 -2.01155944  0.        ]\n",
      " [-0.18999313 -1.66213338  0.        ]\n",
      " [ 0.10909121  0.16929124  0.        ]]\n",
      "[]\n",
      "[[-0.42839324  1.5694214 ]\n",
      " [ 0.03603064  1.60825113]\n",
      " [-1.61292464  1.72655245]]\n",
      "SOFTMAX_LAYER\n",
      "[7.2880874406824001e-06, 0.99999271191255934]\n",
      "LOSS PER INSTANCE: 0.000007\n",
      "DERIVATIVE LOSS: -1.000007\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000007\n",
      "EPOCH 21\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "INPUT ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.94183214 -2.02764207  0.        ]\n",
      " [-0.20568745 -1.67821601  0.        ]\n",
      " [ 0.12478554  0.18537387  0.        ]]\n",
      "[]\n",
      "[[-0.42839324  1.58167371]\n",
      " [ 0.03603064  1.64668125]\n",
      " [-1.61292464  1.73655253]]\n",
      "SOFTMAX_LAYER\n",
      "[5.1613317101181027e-06, 0.99999483866828998]\n",
      "LOSS PER INSTANCE: 0.000005\n",
      "DERIVATIVE LOSS: -1.000005\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000005\n",
      "EPOCH 22\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "INPUT ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.95764896 -2.04410896  0.        ]\n",
      " [-0.22150427 -1.69468291  0.        ]\n",
      " [ 0.14060236  0.20184077  0.        ]]\n",
      "[]\n",
      "[[-0.42839324  1.59439682]\n",
      " [ 0.03603064  1.68559377]\n",
      " [-1.61292464  1.74655258]]\n",
      "SOFTMAX_LAYER\n",
      "[3.6187147420875566e-06, 0.99999638128525792]\n",
      "LOSS PER INSTANCE: 0.000004\n",
      "DERIVATIVE LOSS: -1.000004\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000004\n",
      "EPOCH 23\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "INPUT ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.97359299 -2.06096496  0.        ]\n",
      " [-0.2374483  -1.71153891  0.        ]\n",
      " [ 0.15654639  0.21869677  0.        ]]\n",
      "[]\n",
      "[[-0.42839324  1.60759443]\n",
      " [ 0.03603064  1.72500024]\n",
      " [-1.61292464  1.75655262]]\n",
      "SOFTMAX_LAYER\n",
      "[2.5108532434465323e-06, 0.99999748914675646]\n",
      "LOSS PER INSTANCE: 0.000003\n",
      "DERIVATIVE LOSS: -1.000003\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000003\n",
      "EPOCH 24\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "INPUT ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.98966897 -2.07821501  0.        ]\n",
      " [-0.25352428 -1.72878895  0.        ]\n",
      " [ 0.17262237  0.23594681  0.        ]]\n",
      "[]\n",
      "[[-0.42839324  1.62127034]\n",
      " [ 0.03603064  1.76491235]\n",
      " [-1.61292464  1.76655264]]\n",
      "SOFTMAX_LAYER\n",
      "[1.7234053996459021e-06, 0.99999827659460039]\n",
      "LOSS PER INSTANCE: 0.000002\n",
      "DERIVATIVE LOSS: -1.000002\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000002\n",
      "EPOCH 25\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "INPUT ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.0058817  -2.09586416  0.        ]\n",
      " [-0.26973702 -1.74643811  0.        ]\n",
      " [ 0.1888351   0.25359597  0.        ]]\n",
      "[]\n",
      "[[-0.42839324  1.63542852]\n",
      " [ 0.03603064  1.80534192]\n",
      " [-1.61292464  1.77655266]]\n",
      "SOFTMAX_LAYER\n",
      "[1.1696931910000457e-06, 0.99999883030680903]\n",
      "LOSS PER INSTANCE: 0.000001\n",
      "DERIVATIVE LOSS: -1.000001\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000001\n",
      "EPOCH 26\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "INPUT ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.02223601 -2.1139176   0.        ]\n",
      " [-0.28609132 -1.76449155  0.        ]\n",
      " [ 0.20518941  0.27164941  0.        ]]\n",
      "[]\n",
      "[[-0.42839324  1.65007308]\n",
      " [ 0.03603064  1.84630095]\n",
      " [-1.61292464  1.78655267]]\n",
      "SOFTMAX_LAYER\n",
      "[7.8467248087093187e-07, 0.99999921532751912]\n",
      "LOSS PER INSTANCE: 0.000001\n",
      "DERIVATIVE LOSS: -1.000001\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000001\n",
      "EPOCH 27\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "INPUT ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.03873675 -2.13238063  0.        ]\n",
      " [-0.30259206 -1.78295457  0.        ]\n",
      " [ 0.22169015  0.29011243  0.        ]]\n",
      "[]\n",
      "[[-0.42839324  1.66520825]\n",
      " [ 0.03603064  1.88780157]\n",
      " [-1.61292464  1.79655268]]\n",
      "SOFTMAX_LAYER\n",
      "[5.2004924287609201e-07, 0.99999947995075711]\n",
      "LOSS PER INSTANCE: 0.000001\n",
      "DERIVATIVE LOSS: -1.000001\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000001\n",
      "EPOCH 28\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "INPUT ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.05538884 -2.15125865  0.        ]\n",
      " [-0.31924415 -1.8018326   0.        ]\n",
      " [ 0.23834224  0.30899046  0.        ]]\n",
      "[]\n",
      "[[-0.42839324  1.68083845]\n",
      " [ 0.03603064  1.92985607]\n",
      " [-1.61292464  1.80655268]]\n",
      "SOFTMAX_LAYER\n",
      "[3.4036241778340838e-07, 0.99999965963758231]\n",
      "LOSS PER INSTANCE: 0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 29\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "INPUT ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.07219723 -2.17055722  0.        ]\n",
      " [-0.33605254 -1.82113116  0.        ]\n",
      " [ 0.25515063  0.32828903  0.        ]]\n",
      "[]\n",
      "[[-0.42839324  1.69696821]\n",
      " [ 0.03603064  1.9724769 ]\n",
      " [-1.61292464  1.81655269]]\n",
      "SOFTMAX_LAYER\n",
      "[2.198745389317797e-07, 0.99999978012546109]\n",
      "LOSS PER INSTANCE: 0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 30\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "INPUT ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.08916692 -2.19028199  0.        ]\n",
      " [-0.35302223 -1.84085594  0.        ]\n",
      " [ 0.27212032  0.3480138   0.        ]]\n",
      "[]\n",
      "[[-0.42839324  1.71360222]\n",
      " [ 0.03603064  2.01567669]\n",
      " [-1.61292464  1.82655269]]\n",
      "SOFTMAX_LAYER\n",
      "[1.4013060786119756e-07, 0.99999985986939222]\n",
      "LOSS PER INSTANCE: 0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 31\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "INPUT ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.10630294 -2.21043876  0.        ]\n",
      " [-0.37015825 -1.86101271  0.        ]\n",
      " [ 0.28925634  0.36817057  0.        ]]\n",
      "[]\n",
      "[[-0.42839324  1.73074531]\n",
      " [ 0.03603064  2.05946821]\n",
      " [-1.61292464  1.83655269]]\n",
      "SOFTMAX_LAYER\n",
      "[8.8063804586858311e-08, 0.99999991193619553]\n",
      "LOSS PER INSTANCE: 0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 32\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "INPUT ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.1236104  -2.23103345  0.        ]\n",
      " [-0.38746571 -1.88160739  0.        ]\n",
      " [ 0.3065638   0.38876525  0.        ]]\n",
      "[]\n",
      "[[-0.42839324  1.74840249]\n",
      " [ 0.03603064  2.10386443]\n",
      " [-1.61292464  1.84655269]]\n",
      "SOFTMAX_LAYER\n",
      "[5.4543473565076024e-08, 0.99999994545652648]\n",
      "LOSS PER INSTANCE: 0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 33\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "INPUT ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.14109442 -2.25207209  0.        ]\n",
      " [-0.40494974 -1.90264604  0.        ]\n",
      " [ 0.32404782  0.4098039   0.        ]]\n",
      "[]\n",
      "[[-0.42839324  1.76657889]\n",
      " [ 0.03603064  2.1488785 ]\n",
      " [-1.61292464  1.85655269]]\n",
      "SOFTMAX_LAYER\n",
      "[3.3276389997518357e-08, 0.99999996672361002]\n",
      "LOSS PER INSTANCE: 0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 34\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "INPUT ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.15876021 -2.27356088  0.        ]\n",
      " [-0.42261553 -1.92413482  0.        ]\n",
      " [ 0.34171361  0.43129268  0.        ]]\n",
      "[]\n",
      "[[-0.42839324  1.78527981]\n",
      " [ 0.03603064  2.19452372]\n",
      " [-1.61292464  1.86655269]]\n",
      "SOFTMAX_LAYER\n",
      "[1.9986520200066302e-08, 0.99999998001347978]\n",
      "LOSS PER INSTANCE: 0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 35\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "INPUT ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.17661301 -2.29550611  0.        ]\n",
      " [-0.44046832 -1.94608006  0.        ]\n",
      " [ 0.35956641  0.45323792  0.        ]]\n",
      "[]\n",
      "[[-0.42839324  1.80451071]\n",
      " [ 0.03603064  2.2408136 ]\n",
      " [-1.61292464  1.87655269]]\n",
      "SOFTMAX_LAYER\n",
      "[1.1811289225733786e-08, 0.99999998818871083]\n",
      "LOSS PER INSTANCE: 0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 36\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "INPUT ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.19465812 -2.31791425  0.        ]\n",
      " [-0.45851343 -1.9684882   0.        ]\n",
      " [ 0.37761152  0.47564606  0.        ]]\n",
      "[]\n",
      "[[-0.42839324  1.82427718]\n",
      " [ 0.03603064  2.28776184]\n",
      " [-1.61292464  1.88655269]]\n",
      "SOFTMAX_LAYER\n",
      "[6.8637254088062025e-09, 0.99999999313627463]\n",
      "LOSS PER INSTANCE: 0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 37\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "INPUT ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.21290089 -2.34079187  0.        ]\n",
      " [-0.4767562  -1.99136581  0.        ]\n",
      " [ 0.39585429  0.49852368  0.        ]]\n",
      "[]\n",
      "[[-0.42839324  1.84458501]\n",
      " [ 0.03603064  2.33538233]\n",
      " [-1.61292464  1.89655269]]\n",
      "SOFTMAX_LAYER\n",
      "[3.9197628525201821e-09, 0.99999999608023715]\n",
      "LOSS PER INSTANCE: 0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 38\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "INPUT ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.23134674 -2.36414569  0.        ]\n",
      " [-0.49520205 -2.01471964  0.        ]\n",
      " [ 0.41430014  0.5218775   0.        ]]\n",
      "[]\n",
      "[[-0.42839324  1.86544013]\n",
      " [ 0.03603064  2.38368914]\n",
      " [-1.61292464  1.90655269]]\n",
      "SOFTMAX_LAYER\n",
      "[2.1984822335395561e-09, 0.99999999780151783]\n",
      "LOSS PER INSTANCE: 0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 39\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "INPUT ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.25000114 -2.38798258  0.        ]\n",
      " [-0.51385645 -2.03855653  0.        ]\n",
      " [ 0.43295454  0.54571439  0.        ]]\n",
      "[]\n",
      "[[-0.42839324  1.88684862]\n",
      " [ 0.03603064  2.43269657]\n",
      " [-1.61292464  1.91655269]]\n",
      "SOFTMAX_LAYER\n",
      "[1.210225293354735e-09, 0.99999999878977475]\n",
      "LOSS PER INSTANCE: 0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 40\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "INPUT ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.26886963 -2.41230955  0.        ]\n",
      " [-0.53272494 -2.06288349  0.        ]\n",
      " [ 0.45182303  0.57004136  0.        ]]\n",
      "[]\n",
      "[[-0.42839324  1.90881674]\n",
      " [ 0.03603064  2.48241911]\n",
      " [-1.61292464  1.92655269]]\n",
      "SOFTMAX_LAYER\n",
      "[6.5342676554820087e-10, 0.99999999934657324]\n",
      "LOSS PER INSTANCE: 0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 41\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "INPUT ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.2879578  -2.43713374  0.        ]\n",
      " [-0.55181311 -2.08770769  0.        ]\n",
      " [ 0.47091119  0.59486555  0.        ]]\n",
      "[]\n",
      "[[-0.42839324  1.93135092]\n",
      " [ 0.03603064  2.53287145]\n",
      " [-1.61292464  1.93655269]]\n",
      "SOFTMAX_LAYER\n",
      "[3.4579009094618496e-10, 0.99999999965420994]\n",
      "LOSS PER INSTANCE: 0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 42\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "INPUT ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.3072713  -2.46246246  0.        ]\n",
      " [-0.57112662 -2.1130364   0.        ]\n",
      " [ 0.4902247   0.62019426  0.        ]]\n",
      "[]\n",
      "[[-0.42839324  1.95445774]\n",
      " [ 0.03603064  2.58406852]\n",
      " [-1.61292464  1.94655269]]\n",
      "SOFTMAX_LAYER\n",
      "[1.7922575108884475e-10, 0.99999999982077425]\n",
      "LOSS PER INSTANCE: 0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 43\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "INPUT ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.32681588 -2.48830314  0.        ]\n",
      " [-0.59067119 -2.13887709  0.        ]\n",
      " [ 0.50976928  0.64603495  0.        ]]\n",
      "[]\n",
      "[[-0.42839324  1.97814396]\n",
      " [ 0.03603064  2.63602545]\n",
      " [-1.61292464  1.95655269]]\n",
      "SOFTMAX_LAYER\n",
      "[9.0915362343312517e-11, 0.99999999990908461]\n",
      "LOSS PER INSTANCE: 0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 44\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "INPUT ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.34659732 -2.5146634   0.        ]\n",
      " [-0.61045263 -2.16523734  0.        ]\n",
      " [ 0.52955072  0.6723952   0.        ]]\n",
      "[]\n",
      "[[-0.42839324  2.00241653]\n",
      " [ 0.03603064  2.6887576 ]\n",
      " [-1.61292464  1.96655269]]\n",
      "SOFTMAX_LAYER\n",
      "[4.5101290003583727e-11, 0.99999999995489863]\n",
      "LOSS PER INSTANCE: 0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 45\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "INPUT ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.36662149 -2.54155097  0.        ]\n",
      " [-0.6304768  -2.19212492  0.        ]\n",
      " [ 0.54957489  0.69928278  0.        ]]\n",
      "[]\n",
      "[[-0.42839324  2.02728253]\n",
      " [ 0.03603064  2.74228056]\n",
      " [-1.61292464  1.97655269]]\n",
      "SOFTMAX_LAYER\n",
      "[2.1863011321302227e-11, 0.99999999997813693]\n",
      "LOSS PER INSTANCE: 0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 46\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "INPUT ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.38689431 -2.56897378  0.        ]\n",
      " [-0.65074962 -2.21954772  0.        ]\n",
      " [ 0.56984771  0.72670558  0.        ]]\n",
      "[]\n",
      "[[-0.42839324  2.05274926]\n",
      " [ 0.03603064  2.79661015]\n",
      " [-1.61292464  1.98655269]]\n",
      "SOFTMAX_LAYER\n",
      "[1.0347682438038671e-11, 0.99999999998965228]\n",
      "LOSS PER INSTANCE: 0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 47\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "INPUT ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.4074218  -2.59693988  0.        ]\n",
      " [-0.67127712 -2.24751382  0.        ]\n",
      " [ 0.5903752   0.75467169  0.        ]]\n",
      "[]\n",
      "[[-0.42839324  2.07882418]\n",
      " [ 0.03603064  2.85176242]\n",
      " [-1.61292464  1.99655269]]\n",
      "SOFTMAX_LAYER\n",
      "[4.7777005176611785e-12, 0.99999999999522238]\n",
      "LOSS PER INSTANCE: 0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 48\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "INPUT ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.42821005 -2.6254575   0.        ]\n",
      " [-0.69206536 -2.27603145  0.        ]\n",
      " [ 0.61116345  0.78318931  0.        ]]\n",
      "[]\n",
      "[[-0.42839324  2.10551492]\n",
      " [ 0.03603064  2.90775367]\n",
      " [-1.61292464  2.00655269]]\n",
      "SOFTMAX_LAYER\n",
      "[2.1500844237266191e-12, 0.99999999999785005]\n",
      "LOSS PER INSTANCE: 0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n",
      "EPOCH 49\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "INPUT ACTIVATIONS\n",
      "[-1. -1.  1.]\n",
      "WEIGHTS:\n",
      "[[-1.4492652  -2.65453504  0.        ]\n",
      " [-0.71312051 -2.30510898  0.        ]\n",
      " [ 0.63221859  0.81226685  0.        ]]\n",
      "[]\n",
      "[[-0.42839324  2.13282931]\n",
      " [ 0.03603064  2.96460046]\n",
      " [-1.61292464  2.01655269]]\n",
      "SOFTMAX_LAYER\n",
      "[9.422320464414493e-13, 0.99999999999905775]\n",
      "LOSS PER INSTANCE: 0.000000\n",
      "DERIVATIVE LOSS: -1.000000\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nclass Node(Object):\\n    def __init__(self):\\n        \\n    def \\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class NN():\n",
    "    \"\"\"\n",
    "    Class for a neural network. Requires input/output sizes, number of hidden layers, and number of neurons\n",
    "    at each layer (we assume all hidden layers are of the same size)\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, num_HL, hidden_size, output_size):\n",
    "        # Initialize by setting random \n",
    "        self.input_size = input_size\n",
    "        self.hidden_layers = num_HL\n",
    "        # NOTE we are assuming all hidden layers are the same size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        # Activations for each neuron\n",
    "        # + 1 for bias neuron\n",
    "        self.activations_in = np.ones(self.input_size + 1)\n",
    "        # Hidden can comprise multiple layers, so we have a matrix\n",
    "        # + 1 for bias neuron\n",
    "        self.activations_hidden = np.ones((self.hidden_layers, self.hidden_size + 1))\n",
    "        self.activations_out = np.ones(self.output_size)\n",
    "        # Weights of all the edges, randomized for good results\n",
    "        # PLUS ONE FOR BIASES\n",
    "        self.weights_in = np.random.randn(self.input_size + 1, self.hidden_size)\n",
    "        self.weights_in = np.column_stack((self.weights_in, np.zeros(self.input_size + 1)))\n",
    "        # We will only have hidden weights if there are multiple hidden layers\n",
    "        if self.hidden_layers > 1:\n",
    "            self.weights_hidden = np.random.randn(self.hidden_layers - 1, self.hidden_size + 1, self.hidden_size + 1)\n",
    "            # Set the weights corresponding with next layers biases to 0\n",
    "            for weights in self.weights_hidden:\n",
    "                weights[-1] = 0.0\n",
    "        else:\n",
    "            self.weights_hidden = []\n",
    "        # No plus one for output, as it should not have a bias parameter\n",
    "        self.weights_out = np.random.randn(self.hidden_size + 1, self.output_size)\n",
    "        # To be valued when train() is called\n",
    "        self.learning_rate = 0.0\n",
    "\n",
    "        # Instantiate deltas for holding gradients\n",
    "        self.Deltas_hidden = []\n",
    "        self.deltas_out = []\n",
    "    \n",
    "    def _sigmoid(self, x):\n",
    "        \"\"\"\n",
    "        Sigmoid function for calculating a distribution over 2 classes\n",
    "        \"\"\"\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def _derivative_sigmoid(self, x):\n",
    "        \"\"\"\n",
    "        Derivative of the sigmoid function where x = the output of the sigmoid\n",
    "        \n",
    "        This can be used in backpropogation, wherein we would have \n",
    "        already computed the sigmoid in the forward pass, and we can draw upon its cached value\n",
    "        \"\"\"\n",
    "        return self._sigmoid(x) * (1.0 - self._sigmoid(x))\n",
    "    \n",
    "    def _softmax(self, x):\n",
    "        exponentials = [np.exp(p) for p in x]\n",
    "        denominator = sum(exponentials)\n",
    "        return [p / denominator for p in exponentials]\n",
    "    \n",
    "    def _relu(self, x):\n",
    "        \"\"\"\n",
    "        relu function used for activation\n",
    "        \"\"\"\n",
    "        return max(x, 0.0)\n",
    "    \n",
    "    def _derivative_relu(self, x):\n",
    "        \"\"\"\n",
    "        Derivative of the relu function, the input will be the output of the relu function.\n",
    "        This is because in practice we will have already performed this computation in the forward pass\n",
    "        so in the backward pass, we need to find its derivative drawing upon the cached relu(x).\n",
    "        \"\"\"\n",
    "        return 1 if x > 0.0 else 0.0\n",
    "    \n",
    "    def _binary_cross_ent(self, y_hat, y):\n",
    "        \"\"\"\n",
    "        This basically finds the negative of the log probability of class1 - its inverse\n",
    "        \"\"\"\n",
    "        return (-y * np.log(y_hat)) - ((1 - y) * np.log(1 - y_hat))\n",
    "    \n",
    "    def _negative_log_likelihood(self, y_hat):\n",
    "        return -np.log(y_hat)\n",
    "    \n",
    "    def _derivative_negative_log_likelihood(self, y_hat):\n",
    "        return -1/y_hat\n",
    "    \n",
    "    def _derivative_binary_cross_ent(self, y_hat, y):\n",
    "        \"\"\"\n",
    "        Derivative of binary cross-entropy\n",
    "        \n",
    "        This description is misleading. \n",
    "        This is the part of the partial derivative of binary cross-entropy \n",
    "        w.r.t the parameters of our function. In practice, the other part is \n",
    "        the dot product of this and the activations (activate(w, x))\n",
    "        \"\"\"\n",
    "        #return -(y / y_hat) - ((1 - y) / (1 - y_hat))\n",
    "        return (y_hat - y)\n",
    "\n",
    "    def _activate(self, x):\n",
    "        \"\"\"\n",
    "        RELU for non-linear activation function\n",
    "        \"\"\"\n",
    "        return self._relu(x)\n",
    "    \n",
    "    def _activate_vector(self, X):\n",
    "        \"\"\"\n",
    "        Run on a numpy vector\n",
    "        \"\"\"\n",
    "        activations = np.vectorize(self._activate)\n",
    "        return activations(X)\n",
    "    \n",
    "    def _derivative_activation(self, x):\n",
    "        \"\"\"\n",
    "        Compute the derivative of the activation function given the activation output\n",
    "        \n",
    "        x: activate(node)\n",
    "        \"\"\"\n",
    "        return self._derivative_relu(x)\n",
    "    \n",
    "    def _derivative_vector_activation(self, X):\n",
    "        \"\"\"\n",
    "        Derivative for each scalar in a numpy vector\n",
    "        \"\"\"\n",
    "        derivative_activations = np.vectorize(self._derivative_activation)\n",
    "        return derivative_activations(X)\n",
    "\n",
    "    def _loss(self, y_hat, y):\n",
    "        \"\"\"\n",
    "        y_hat: sofmax vector\n",
    "        y:     one-hot vector for the target\n",
    "        \n",
    "        Here we will plug in the negative_log_likelihood\n",
    "        in order to be able to compare the proability of our output at\n",
    "        the correct class, to 1.\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        Get the index of the correct class \n",
    "        (numpy will return a tuple of the index in each dimension)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Get the first (and only) dim, and the first (and only) index\n",
    "        i = np.where(y==1)[0][0]\n",
    "        return self._negative_log_likelihood(y_hat[i])\n",
    "    \n",
    "    def _derivative_loss(self, y_hat, y):\n",
    "        \"\"\"\n",
    "        This will be used in backprop for finding L'(output_layer_node)\n",
    "        \"\"\"\n",
    "        # Get the first (and only) dim, and the first (and only) index\n",
    "        i = np.where(y==1)[0][0]\n",
    "        return self._derivative_negative_log_likelihood(y_hat[i])\n",
    "    \n",
    "    def _targets_to_one_hots(self, targets):\n",
    "        \"\"\"\n",
    "        Interpret a vector of targets into a matrix\n",
    "        of one-hot representations\n",
    "        \"\"\"\n",
    "        # Get the number of unique target classes\n",
    "        num_classes = len(set(targets))\n",
    "        # Instantiate a matrix of one-hot vectors\n",
    "        # with one row per target, and one col per class\n",
    "        one_hots = np.zeros((len(targets), num_classes))\n",
    "        for i, one_hot in enumerate(one_hots):\n",
    "            # Set the one-hot vector to hae a 1 at its corresponding target slot\n",
    "            t = targets[i]\n",
    "            one_hot[t] = 1\n",
    "            \n",
    "        return one_hots\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Forward pass: Calculate the activations of each neuron\n",
    "        \"\"\"\n",
    "        if len(inputs) != self.input_size:\n",
    "          raise Exception(\"That is not the size of the input layer... try %i\" % self.input_size)\n",
    "        \n",
    "        # Set input activations, no need to actually calculate anything\n",
    "        for i, inp in enumerate(inputs):\n",
    "            self.activations_in[i] = inp\n",
    "        print(\"INPUT ACTIVATIONS\")\n",
    "        print(self.activations_in)\n",
    "        # calculate the activations for each hidden layer\n",
    "        for h_layer_i in range(self.hidden_layers):\n",
    "            # Need to take previous layer activation value * weights for a given layer\n",
    "            # Starting with input layer X first hidden layer\n",
    "            if h_layer_i == 0:\n",
    "                # multiply the previous layer's activations by its weight vector for this layer's activations\n",
    "                self.activations_hidden[h_layer_i] = self.activations_in.T.dot(self.weights_in)\n",
    "                # Reset bias activation to 1.0\n",
    "                self.activations_hidden[h_layer_i][-1] = 1.0\n",
    "            else:\n",
    "                # multiply the previous layer's activations by its weight vector for this layer's activations\n",
    "                self.activations_hidden[h_layer_i] = self._activate_vector(self.activations_hidden[h_layer_i - 1]).T.dot(self.weights_hidden[h_layer_i - 1])\n",
    "                # Reset bias activation to 1.0\n",
    "                self.activations_hidden[h_layer_i][-1] = 1.0\n",
    "\n",
    "                \n",
    "        # Output activations will be the dot product of the final hidden layer, and the output weights\n",
    "        # Activate the vector before, but do not activate the activations_out\n",
    "        self.activations_out = self._activate_vector(self.activations_hidden[-1]).T.dot(self.weights_out)\n",
    "        \n",
    "        #Print all of the weights, to see updates\n",
    "        \"\"\"\n",
    "        print(\"ACTIVATIONS\")\n",
    "        print(self.activations_in)\n",
    "        print(self.activations_hidden)\n",
    "        print(self.activations_out)\n",
    "        \"\"\"\n",
    "        print(\"WEIGHTS:\")\n",
    "        print(self.weights_in)\n",
    "        print(self.weights_hidden)\n",
    "        print(self.weights_out)\n",
    "\n",
    "    def backward(self, targets):\n",
    "        \"\"\"\n",
    "        Backpropogation for finding the partial derivative of the each node w.r.t the loss function,\n",
    "        and updating weights based on those gradients\n",
    "        \"\"\"\n",
    "        if len(targets) != len(self.activations_out):\n",
    "            raise Exception(\"Your labels are not the same size as your output layer!\")\n",
    "        # Calculate loss - there will be a value for each node in the output layer\n",
    "        # Take the simoid of the activations of the output layer, because we are doing 2 class classification\n",
    "        # ***If we have >2 classes, we would use softmax***\n",
    "        \"\"\"\n",
    "        print(\"ACTIVATIONS IN\")\n",
    "        print(self.activations_in)\n",
    "        \n",
    "        print(\"ACTIVATIONS HIDDEN\")\n",
    "        print(self.activations_hidden)\n",
    "        \n",
    "        print(\"ACTIVATIONS OUT\")\n",
    "        print(self.activations_out)\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"SOFTMAX_LAYER\")\n",
    "        print(self._softmax(self.activations_out))\n",
    "        \"\"\"\n",
    "        print(\"TARGETS\")\n",
    "        print(targets)\n",
    "        \"\"\"\n",
    "        loss = self._loss(self._softmax(self.activations_out), targets)\n",
    "        \n",
    "        \"\"\"\n",
    "        Now we need to calculate the partial derivative of the loss w.r.t each weight.\n",
    "        Think of this as finding the amount that each node contributes to a change in the final loss.\n",
    "        \n",
    "        Each node has a value \"delta\", which represents the partial derivative of the loss w.r.t. its value:\n",
    "        Use the partial derivative of the loss function, in our case binary cross-entropy\n",
    "        \"\"\"\n",
    "        self.deltas_out = np.zeros([self.output_size])\n",
    "        derivative_loss = self._derivative_loss(self._softmax(self.activations_out), targets)\n",
    "        print(\"LOSS PER INSTANCE: %2f\" % loss)\n",
    "        print(\"DERIVATIVE LOSS: %2f\" % derivative_loss)\n",
    "        for i, activation_out in enumerate(self.activations_out):\n",
    "            self.deltas_out[i] = derivative_loss * self._derivative_activation(activation_out)\n",
    "        \n",
    "        \"\"\"\n",
    "        Find derivative of activation (activation was found in the forward pass) * derivative of the inner function,\n",
    "        which is the parameter w\n",
    "        \"\"\"\n",
    "        self.Deltas_hidden = np.zeros([self.hidden_layers, self.hidden_size + 1])\n",
    "        ##############\n",
    "        #####TODO Needs to go in reverse if we have multiple hidden\n",
    "        for h_layer_i in range(self.hidden_layers):\n",
    "            # If it is the last hidden layer, then we look at the activations and deltas\n",
    "            # of the output layer, not the next hidden layer\n",
    "            if h_layer_i == self.hidden_layers - 1:\n",
    "                # Loop over each in hidden activation, +1 for bias\n",
    "                for h_dim_j in range(self.hidden_size + 1):\n",
    "                    for k, delta_out in enumerate(self.deltas_out):\n",
    "                        self.Deltas_hidden[h_layer_i][h_dim_j] += delta_out * self._derivative_activation(self.activations_out[k]) * self.weights_out[h_dim_j][k]\n",
    "            else:\n",
    "                # Do the same to find the hidden deltas\n",
    "                for h_dim_j in range(self.hidden_size + 1):\n",
    "                    for k, delta_h in enumerate(self.Deltas_hidden[h_layer_i + 1]):\n",
    "                        self.Deltas_hidden[h_layer_i][h_dim_j] += delta_h * self._derivative_activation(self.activations_hidden[h_layer_i + 1][k]) * self.weights_hidden[h_layer_i][h_dim_j][k]        \n",
    "        \n",
    "        self.update_weights()\n",
    "        return loss\n",
    "        \n",
    "    def update_weights(self):\n",
    "        print(\"UPDATING WEIGHTS\")\n",
    "        # Now we can use the deltas to adjust each weight by L'(w_i_j)\n",
    "        # These weights are the edges shared between last hidden layer, and output layer\n",
    "        # Rows of weights_out correponds with length of last hidden layer\n",
    "        for i in range(len(self.weights_out)):\n",
    "            # Cols of weights_out correspinds with length of output layer\n",
    "            for j in range(len(self.weights_out[i])):\n",
    "                self.weights_out[i][j] -= self._activate(self.activations_hidden[-1][i])\\\n",
    "                * self._derivative_activation(self.activations_out[j])\\\n",
    "                * self.deltas_out[j]\\\n",
    "                * self.learning_rate\n",
    "                    \n",
    "        # Loop over each hidden layer\n",
    "        for w_i in reversed(range(len(self.weights_hidden))):\n",
    "            # Rows (i) in the weights for this layer will correspond to the size of the layer BEFORE (hidden or input)\n",
    "            for i in range(len(self.weights_hidden[w_i])):\n",
    "                # Cols (j) in these weights will correspond to the size of hidden layer w_i\n",
    "                for j in range(len(self.weights_hidden[w_i][i])):\n",
    "                    # We do not want to update the dummy 0 weight going TO the extra bias dimension\n",
    "                    if j == len(self.weights_hidden[w_i][i]) - 1:\n",
    "                        continue\n",
    "                    else:\n",
    "                        # + 1 for layer before, because we are looping in reverse\n",
    "                        self.weights_hidden[w_i][i][j] -= self._activate(self.activations_hidden[w_i + 1][i])\\\n",
    "                        * self._derivative_activation(self.activations_hidden[w_i][j])\\\n",
    "                        * self.Deltas_hidden[w_i][j]\\\n",
    "                        * self.learning_rate\n",
    "                        \n",
    "        # Rows (i) of weights_in corresponds to size of the input layer\n",
    "        for i in range(len(self.weights_in)):\n",
    "            # Cols (j) corresponds to size of the first hidden layer (layer above input layer)\n",
    "            for j in range(len(self.weights_in[i])):\n",
    "                # We do not want to update the dummy 0 weight going TO the extra bias dimension\n",
    "                if j == len(self.weights_in[i]) - 1:\n",
    "                    continue\n",
    "                else:\n",
    "                    self.weights_in[i][j] -= self.activations_in[i]\\\n",
    "                    * self._derivative_activation(self.activations_hidden[0][j])\\\n",
    "                    * self.Deltas_hidden[0][j]\\\n",
    "                    * self.learning_rate\n",
    "    \n",
    "    def train(self, inputs, targets, epochs=50, lr=.01):\n",
    "        self.learning_rate = lr\n",
    "        one_hot_targets = self._targets_to_one_hots(targets)\n",
    "        for e in range(epochs):\n",
    "            print(\"EPOCH %i\" % e)\n",
    "            \"\"\"\n",
    "            SGD - randomize the order of the training samples, and \n",
    "            \"\"\"\n",
    "            in_out = list(zip(inputs, one_hot_targets))\n",
    "            random.shuffle(in_out)\n",
    "            # For tracking average loss over SGD, just for logging\n",
    "            losses = []\n",
    "            \n",
    "            for inp, target in in_out:\n",
    "                if inp == [-1, -1]:\n",
    "                    print(\"TARGET: \")\n",
    "                    print(target)\n",
    "                    self.forward(inp)\n",
    "                    losses.append(self.backward(target))\n",
    "\n",
    "            print(\"LOSS: %2f\" % (sum(losses)/len(losses)))\n",
    "            \n",
    "\"\"\"\n",
    "Note that the 4th param, the size of the output layer, should be the\n",
    "number of classes\n",
    "\"\"\"\n",
    "MLP = NN(2, 1, 2, 2)\n",
    "xor_inputs = [[1, 1], [-1, 1], [-1, -1], [1, -1]]\n",
    "xor_labels = ([1, 0, 1, 0])\n",
    "MLP.train(xor_inputs, xor_labels)\n",
    "\"\"\"\n",
    "class Node(Object):\n",
    "    def __init__(self):\n",
    "        \n",
    "    def \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.49999114  0.07880444  0.        ]\n",
      " [-0.28616675 -1.268467    0.        ]\n",
      " [ 2.41048899  1.01062492  0.        ]]\n",
      "[]\n",
      "[[-1.09087155  0.31398398]\n",
      " [ 0.71542081  0.35944917]\n",
      " [-0.02296056 -0.45859542]]\n",
      "SOFTMAX_LAYER\n",
      "[0.34856518373851364, 0.65143481626148636]\n",
      "LOSS PER INSTANCE: 0.428578\n",
      "DERIVATIVE LOSS: -1.535073\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.428578\n",
      "EPOCH 1\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.5018625   0.07617223  0.        ]\n",
      " [-0.28429539 -1.27109922  0.        ]\n",
      " [ 2.40861763  1.01325713  0.        ]]\n",
      "[]\n",
      "[[-1.06653772  0.33895635]\n",
      " [ 0.73976345  0.38443058]\n",
      " [-0.00319339 -0.43830955]]\n",
      "SOFTMAX_LAYER\n",
      "[0.34843673481798815, 0.6515632651820118]\n",
      "LOSS PER INSTANCE: 0.428381\n",
      "DERIVATIVE LOSS: -1.534770\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.428381\n",
      "EPOCH 2\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.5036851   0.07341906  0.        ]\n",
      " [-0.28247279 -1.27385239  0.        ]\n",
      " [ 2.40679503  1.0160103   0.        ]]\n",
      "[]\n",
      "[[-1.04175351  0.36346745]\n",
      " [ 0.76459007  0.40898362]\n",
      " [ 0.01695097 -0.41838716]]\n",
      "SOFTMAX_LAYER\n",
      "[0.3488028050742657, 0.65119719492573425]\n",
      "LOSS PER INSTANCE: 0.428943\n",
      "DERIVATIVE LOSS: -1.535633\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.428943\n",
      "EPOCH 3\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.50545449  0.07055308  0.        ]\n",
      " [-0.2807034  -1.27671837  0.        ]\n",
      " [ 2.40502564  1.01887628  0.        ]]\n",
      "[]\n",
      "[[-1.01657126  0.38747009]\n",
      " [ 0.78984989  0.43306019]\n",
      " [ 0.03743015 -0.39886729]]\n",
      "SOFTMAX_LAYER\n",
      "[0.34966143887183204, 0.6503385611281679]\n",
      "LOSS PER INSTANCE: 0.430262\n",
      "DERIVATIVE LOSS: -1.537661\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.430262\n",
      "EPOCH 4\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.50716566  0.06758353  0.        ]\n",
      " [-0.27899223 -1.27968792  0.        ]\n",
      " [ 2.40331447  1.02184583  0.        ]]\n",
      "[]\n",
      "[[-0.99105254  0.41092655]\n",
      " [ 0.81548256  0.45662139]\n",
      " [ 0.05819412 -0.37978134]]\n",
      "SOFTMAX_LAYER\n",
      "[0.3510013900879263, 0.6489986099120737]\n",
      "LOSS PER INSTANCE: 0.432325\n",
      "DERIVATIVE LOSS: -1.540835\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.432325\n",
      "EPOCH 5\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.5088132   0.06452067  0.        ]\n",
      " [-0.27734469 -1.28275078  0.        ]\n",
      " [ 2.40166693  1.02490869  0.        ]]\n",
      "[]\n",
      "[[-0.96526763  0.43380815]\n",
      " [ 0.84141857  0.47963708]\n",
      " [ 0.07918564 -0.3611534 ]]\n",
      "SOFTMAX_LAYER\n",
      "[0.35280242193876837, 0.64719757806123157]\n",
      "LOSS PER INSTANCE: 0.435104\n",
      "DERIVATIVE LOSS: -1.545123\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.435104\n",
      "EPOCH 6\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.51039137  0.06137567  0.        ]\n",
      " [-0.27576652 -1.28589578  0.        ]\n",
      " [ 2.40008876  1.02805369  0.        ]]\n",
      "[]\n",
      "[[-0.93929458  0.45609457]\n",
      " [ 0.86758017  0.50208529]\n",
      " [ 0.10034101 -0.34300083]]\n",
      "SOFTMAX_LAYER\n",
      "[0.35503594670816285, 0.64496405329183704]\n",
      "LOSS PER INSTANCE: 0.438561\n",
      "DERIVATIVE LOSS: -1.550474\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.438561\n",
      "EPOCH 7\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.5118943   0.05816052  0.        ]\n",
      " [-0.27426359 -1.28911093  0.        ]\n",
      " [ 2.39858583  1.03126884  0.        ]]\n",
      "[]\n",
      "[[-0.91321773  0.47777296]\n",
      " [ 0.8938828   0.52395137]\n",
      " [ 0.12159126 -0.32533493]]\n",
      "SOFTMAX_LAYER\n",
      "[0.35766598899981689, 0.64233401100018317]\n",
      "LOSS PER INSTANCE: 0.442647\n",
      "DERIVATIVE LOSS: -1.556822\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.442647\n",
      "EPOCH 8\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.51331626  0.05488783  0.        ]\n",
      " [-0.27284163 -1.29238362  0.        ]\n",
      " [ 2.39716387  1.03454153  0.        ]]\n",
      "[]\n",
      "[[-0.88712582  0.49883693]\n",
      " [ 0.92023692  0.54522702]\n",
      " [ 0.14286367 -0.30816174]]\n",
      "SOFTMAX_LAYER\n",
      "[0.36065043739667502, 0.63934956260332498]\n",
      "LOSS PER INSTANCE: 0.447304\n",
      "DERIVATIVE LOSS: -1.564090\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.447304\n",
      "EPOCH 9\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.51465191  0.05157063  0.        ]\n",
      " [-0.27150597 -1.29570082  0.        ]\n",
      " [ 2.39582821  1.03785873  0.        ]]\n",
      "[]\n",
      "[[-0.86110973  0.51928557]\n",
      " [ 0.94655031  0.56590934]\n",
      " [ 0.16408364 -0.29148285]]\n",
      "SOFTMAX_LAYER\n",
      "[0.36394252749515532, 0.63605747250484468]\n",
      "LOSS PER INSTANCE: 0.452466\n",
      "DERIVATIVE LOSS: -1.572185\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.452466\n",
      "EPOCH 10\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.51589655  0.04822219  0.        ]\n",
      " [-0.27026134 -1.29904926  0.        ]\n",
      " [ 2.39458358  1.04120717  0.        ]]\n",
      "[]\n",
      "[[-0.83526007  0.5391225 ]\n",
      " [ 0.97273048  0.5859999 ]\n",
      " [ 0.18517662 -0.27529617]]\n",
      "SOFTMAX_LAYER\n",
      "[0.36749247748640218, 0.63250752251359776]\n",
      "LOSS PER INSTANCE: 0.458063\n",
      "DERIVATIVE LOSS: -1.581009\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.458063\n",
      "EPOCH 11\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.51704634  0.04485568  0.        ]\n",
      " [-0.26911155 -1.30241576  0.        ]\n",
      " [ 2.39343379  1.04457368  0.        ]]\n",
      "[]\n",
      "[[-0.80966472  0.55835491]\n",
      " [ 0.99868721  0.60550386]\n",
      " [ 0.20607023 -0.25959666]]\n",
      "SOFTMAX_LAYER\n",
      "[0.37124918044235733, 0.62875081955764267]\n",
      "LOSS PER INSTANCE: 0.464020\n",
      "DERIVATIVE LOSS: -1.590455\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.464020\n",
      "EPOCH 12\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.51809848  0.04148399  0.        ]\n",
      " [-0.26805941 -1.30578746  0.        ]\n",
      " [ 2.39238165  1.04794537  0.        ]]\n",
      "[]\n",
      "[[-0.78440652  0.57699287]\n",
      " [ 1.02433494  0.62442925]\n",
      " [ 0.22669607 -0.24437691]]\n",
      "SOFTMAX_LAYER\n",
      "[0.37516184976585454, 0.62483815023414546]\n",
      "LOSS PER INSTANCE: 0.470263\n",
      "DERIVATIVE LOSS: -1.600414\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.470263\n",
      "EPOCH 13\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.51905135  0.03811939  0.        ]\n",
      " [-0.26710654 -1.30915205  0.        ]\n",
      " [ 2.39142878  1.05130996  0.        ]]\n",
      "[]\n",
      "[[-0.75956128  0.59504859]\n",
      " [ 1.04959481  0.64278629]\n",
      " [ 0.2469914  -0.22962774]]\n",
      "SOFTMAX_LAYER\n",
      "[0.37918151869944405, 0.62081848130055606]\n",
      "LOSS PER INSTANCE: 0.476717\n",
      "DERIVATIVE LOSS: -1.610777\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.476717\n",
      "EPOCH 14\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.51990453  0.0347734   0.        ]\n",
      " [-0.26625336 -1.31249805  0.        ]\n",
      " [ 2.3905756   1.05465596  0.        ]]\n",
      "[]\n",
      "[[-0.7351962   0.61253588]\n",
      " [ 1.07439639  0.66058688]\n",
      " [ 0.26690048 -0.21533859]]\n",
      "SOFTMAX_LAYER\n",
      "[0.38326231141508665, 0.6167376885849134]\n",
      "LOSS PER INSTANCE: 0.483311\n",
      "DERIVATIVE LOSS: -1.621435\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.483311\n",
      "EPOCH 15\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.52065877  0.03145652  0.        ]\n",
      " [-0.26549912 -1.31581493  0.        ]\n",
      " [ 2.38982136  1.05797284  0.        ]]\n",
      "[]\n",
      "[[-0.71136888  0.62946975]\n",
      " [ 1.0986788   0.67784416]\n",
      " [ 0.28637541 -0.20149794]]\n",
      "SOFTMAX_LAYER\n",
      "[0.38736242923950887, 0.61263757076049108]\n",
      "LOSS PER INSTANCE: 0.489982\n",
      "DERIVATIVE LOSS: -1.632286\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.489982\n",
      "EPOCH 16\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.52131592  0.02817814  0.        ]\n",
      " [-0.26484196 -1.31909331  0.        ]\n",
      " [ 2.38916421  1.06125122  0.        ]]\n",
      "[]\n",
      "[[-0.68812668  0.64586596]\n",
      " [ 1.12239134  0.69457218]\n",
      " [ 0.30537665 -0.18809351]]\n",
      "SOFTMAX_LAYER\n",
      "[0.39144482624875904, 0.60855517375124102]\n",
      "LOSS PER INSTANCE: 0.496668\n",
      "DERIVATIVE LOSS: -1.643236\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.496668\n",
      "EPOCH 17\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.52187882  0.02494645  0.        ]\n",
      " [-0.26427907 -1.322325    0.        ]\n",
      " [ 2.38860131  1.06448291  0.        ]]\n",
      "[]\n",
      "[[-0.66550671  0.66174085]\n",
      " [ 1.1454937   0.71078561]\n",
      " [ 0.32387304 -0.17511258]]\n",
      "SOFTMAX_LAYER\n",
      "[0.39547757848354337, 0.60452242151645652]\n",
      "LOSS PER INSTANCE: 0.503317\n",
      "DERIVATIVE LOSS: -1.654198\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.503317\n",
      "EPOCH 18\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.5223511   0.02176841  0.        ]\n",
      " [-0.26380679 -1.32550304  0.        ]\n",
      " [ 2.38812903  1.06766095  0.        ]]\n",
      "[]\n",
      "[[-0.64353618  0.67711104]\n",
      " [ 1.16795561  0.72649957]\n",
      " [ 0.34184161 -0.16254209]]\n",
      "SOFTMAX_LAYER\n",
      "[0.39943397593913793, 0.60056602406086212]\n",
      "LOSS PER INSTANCE: 0.509883\n",
      "DERIVATIVE LOSS: -1.665096\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.509883\n",
      "EPOCH 19\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.52273706  0.01864975  0.        ]\n",
      " [-0.26342083 -1.32862169  0.        ]\n",
      " [ 2.38774307  1.07077961  0.        ]]\n",
      "[]\n",
      "[[-0.62223305  0.6919933 ]\n",
      " [ 1.1897563   0.74172941]\n",
      " [ 0.35926696 -0.15036883]]\n",
      "SOFTMAX_LAYER\n",
      "[0.40329238357097191, 0.59670761642902803]\n",
      "LOSS PER INSTANCE: 0.516328\n",
      "DERIVATIVE LOSS: -1.675863\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.516328\n",
      "EPOCH 20\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.52304146  0.01559506  0.        ]\n",
      " [-0.26311643 -1.33167639  0.        ]\n",
      " [ 2.38743867  1.0738343   0.        ]]\n",
      "[]\n",
      "[[-0.60160693  0.70640439]\n",
      " [ 1.21088356  0.75649065]\n",
      " [ 0.37614063 -0.13857951]]\n",
      "SOFTMAX_LAYER\n",
      "[0.40703592611204703, 0.59296407388795302]\n",
      "LOSS PER INSTANCE: 0.522621\n",
      "DERIVATIVE LOSS: -1.686443\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.522621\n",
      "EPOCH 21\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.52326939  0.01260783  0.        ]\n",
      " [-0.2628885  -1.33466362  0.        ]\n",
      " [ 2.38721074  1.07682153  0.        ]]\n",
      "[]\n",
      "[[-0.58166009  0.72036102]\n",
      " [ 1.23133282  0.77079881]\n",
      " [ 0.39246017 -0.12716087]]\n",
      "SOFTMAX_LAYER\n",
      "[0.41065205243938779, 0.58934794756061226]\n",
      "LOSS PER INSTANCE: 0.528739\n",
      "DERIVATIVE LOSS: -1.696791\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.528739\n",
      "EPOCH 22\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.52342609  0.00969056  0.        ]\n",
      " [-0.2627318  -1.33758089  0.        ]\n",
      " [ 2.38705404  1.0797388   0.        ]]\n",
      "[]\n",
      "[[-0.56238856  0.73387967]\n",
      " [ 1.25110599  0.78466936]\n",
      " [ 0.40822835 -0.11609975]]\n",
      "SOFTMAX_LAYER\n",
      "[0.41413203045884084, 0.58586796954115916]\n",
      "LOSS PER INSTANCE: 0.534661\n",
      "DERIVATIVE LOSS: -1.706869\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.534661\n",
      "EPOCH 23\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.52351687  0.00684489  0.        ]\n",
      " [-0.26264102 -1.34042656  0.        ]\n",
      " [ 2.38696326  1.08258447  0.        ]]\n",
      "[]\n",
      "[[-0.54378319  0.74697662]\n",
      " [ 1.27021049  0.79811766]\n",
      " [ 0.42345224 -0.10538314]]\n",
      "SOFTMAX_LAYER\n",
      "[0.41747041522078676, 0.58252958477921335]\n",
      "LOSS PER INSTANCE: 0.540375\n",
      "DERIVATIVE LOSS: -1.716651\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.540375\n",
      "EPOCH 24\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.52354695  0.0040717   0.        ]\n",
      " [-0.26261093 -1.34319975  0.        ]\n",
      " [ 2.38693318  1.08535766  0.        ]]\n",
      "[]\n",
      "[[-0.52583065  0.75966781]\n",
      " [ 1.28865813  0.81115885]\n",
      " [ 0.43814238 -0.09499825]]\n",
      "SOFTMAX_LAYER\n",
      "[0.42066452325859127, 0.57933547674140873]\n",
      "LOSS PER INSTANCE: 0.545874\n",
      "DERIVATIVE LOSS: -1.726116\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.545874\n",
      "EPOCH 25\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[  5.23521449e-01   1.37120522e-03   0.00000000e+00]\n",
      " [ -2.62636438e-01  -1.34590024e+00   0.00000000e+00]\n",
      " [  2.38695868e+00   1.08805815e+00   0.00000000e+00]]\n",
      "[]\n",
      "[[-0.50851433  0.77196885]\n",
      " [ 1.30646426  0.82380784]\n",
      " [ 0.45231205 -0.0849325 ]]\n",
      "SOFTMAX_LAYER\n",
      "[0.42371393650463413, 0.57628606349536582]\n",
      "LOSS PER INSTANCE: 0.551151\n",
      "DERIVATIVE LOSS: -1.735249\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.551151\n",
      "EPOCH 26\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[  5.23445255e-01  -1.25689874e-03   0.00000000e+00]\n",
      " [ -2.62712632e-01  -1.34852835e+00   0.00000000e+00]\n",
      " [  2.38703487e+00   1.09068626e+00   0.00000000e+00]]\n",
      "[]\n",
      "[[-0.4918152   0.78389496]\n",
      " [ 1.32364688  0.83607925]\n",
      " [ 0.46597657 -0.07517364]]\n",
      "SOFTMAX_LAYER\n",
      "[0.42662005057787489, 0.57337994942212511]\n",
      "LOSS PER INSTANCE: 0.556207\n",
      "DERIVATIVE LOSS: -1.744044\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.556207\n",
      "EPOCH 27\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.52332303 -0.00381338  0.        ]\n",
      " [-0.26283486 -1.35108483  0.        ]\n",
      " [ 2.3871571   1.09324274  0.        ]]\n",
      "[]\n",
      "[[-0.47571248  0.79546094]\n",
      " [ 1.34022593  0.84798736]\n",
      " [ 0.47915274 -0.06570968]]\n",
      "SOFTMAX_LAYER\n",
      "[0.42938567524721916, 0.57061432475278084]\n",
      "LOSS PER INSTANCE: 0.561042\n",
      "DERIVATIVE LOSS: -1.752497\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.561042\n",
      "EPOCH 28\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.52315915 -0.00629936  0.        ]\n",
      " [-0.26299873 -1.35357081  0.        ]\n",
      " [ 2.38732098  1.09572872  0.        ]]\n",
      "[]\n",
      "[[-0.46018424  0.80668116]\n",
      " [ 1.35622268  0.85954611]\n",
      " [ 0.49185834 -0.05652901]]\n",
      "SOFTMAX_LAYER\n",
      "[0.43201468957723882, 0.56798531042276112]\n",
      "LOSS PER INSTANCE: 0.565660\n",
      "DERIVATIVE LOSS: -1.760609\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.565660\n",
      "EPOCH 29\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.52295773 -0.00871626  0.        ]\n",
      " [-0.26320015 -1.35598771  0.        ]\n",
      " [ 2.3875224   1.09814562  0.        ]]\n",
      "[]\n",
      "[[-0.4452079   0.81756951]\n",
      " [ 1.3716592   0.87076902]\n",
      " [ 0.50411173 -0.04762036]]\n",
      "SOFTMAX_LAYER\n",
      "[0.43451175053796465, 0.56548824946203535]\n",
      "LOSS PER INSTANCE: 0.570066\n",
      "DERIVATIVE LOSS: -1.768383\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.570066\n",
      "EPOCH 30\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.52272257 -0.01106569  0.        ]\n",
      " [-0.26343531 -1.35833714  0.        ]\n",
      " [ 2.38775756  1.10049505  0.        ]]\n",
      "[]\n",
      "[[-0.43076061  0.82813941]\n",
      " [ 1.38655795  0.88166922]\n",
      " [ 0.51593149 -0.0389728 ]]\n",
      "SOFTMAX_LAYER\n",
      "[0.43688205146411296, 0.56311794853588704]\n",
      "LOSS PER INSTANCE: 0.574266\n",
      "DERIVATIVE LOSS: -1.775827\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.574266\n",
      "EPOCH 31\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.52245719 -0.01334945  0.        ]\n",
      " [-0.2637007  -1.3606209   0.        ]\n",
      " [ 2.38802294  1.10277881  0.        ]]\n",
      "[]\n",
      "[[-0.4168196   0.83840381]\n",
      " [ 1.40094146  0.89225942]\n",
      " [ 0.52733619 -0.03057582]]\n",
      "SOFTMAX_LAYER\n",
      "[0.43913112539493043, 0.56086887460506962]\n",
      "LOSS PER INSTANCE: 0.578268\n",
      "DERIVATIVE LOSS: -1.782948\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.578268\n",
      "EPOCH 32\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.52216482 -0.01556944  0.        ]\n",
      " [-0.26399306 -1.36284088  0.        ]\n",
      " [ 2.38831531  1.1049988   0.        ]]\n",
      "[]\n",
      "[[-0.40336242  0.84837515]\n",
      " [ 1.414832    0.90255187]\n",
      " [ 0.53834415 -0.02241927]]\n",
      "SOFTMAX_LAYER\n",
      "[0.44126468773782657, 0.55873531226217343]\n",
      "LOSS PER INSTANCE: 0.582079\n",
      "DERIVATIVE LOSS: -1.789756\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.582079\n",
      "EPOCH 33\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.52184843 -0.01772763  0.        ]\n",
      " [-0.26430945 -1.36499907  0.        ]\n",
      " [ 2.3886317   1.10715698  0.        ]]\n",
      "[]\n",
      "[[-0.39036709  0.85806541]\n",
      " [ 1.42825147  0.91255841]\n",
      " [ 0.54897333 -0.01449338]]\n",
      "SOFTMAX_LAYER\n",
      "[0.44328851263880076, 0.55671148736119924]\n",
      "LOSS PER INSTANCE: 0.585708\n",
      "DERIVATIVE LOSS: -1.796263\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.585708\n",
      "EPOCH 34\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.52151073 -0.01982604  0.        ]\n",
      " [-0.26464716 -1.36709749  0.        ]\n",
      " [ 2.3889694   1.1092554   0.        ]]\n",
      "[]\n",
      "[[-0.3778123   0.86748607]\n",
      " [ 1.44122117  0.92229039]\n",
      " [ 0.55924115 -0.00678878]]\n",
      "SOFTMAX_LAYER\n",
      "[0.44520833771968044, 0.55479166228031962]\n",
      "LOSS PER INSTANCE: 0.589163\n",
      "DERIVATIVE LOSS: -1.802478\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.589163\n",
      "EPOCH 35\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.52115417 -0.02186671  0.        ]\n",
      " [-0.26500372 -1.36913816  0.        ]\n",
      " [ 2.38932596  1.11129607  0.        ]]\n",
      "[]\n",
      "[[ -3.65677448e-01   8.76648130e-01]\n",
      " [  1.45376173e+00   9.31758767e-01]\n",
      " [  5.69164462e-01   7.03516285e-04]]\n",
      "SOFTMAX_LAYER\n",
      "[0.44702979231294965, 0.55297020768705041]\n",
      "LOSS PER INSTANCE: 0.592451\n",
      "DERIVATIVE LOSS: -1.808416\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.592451\n",
      "EPOCH 36\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.520781   -0.02385166  0.        ]\n",
      " [-0.26537688 -1.37112311  0.        ]\n",
      " [ 2.38969913  1.11328102  0.        ]]\n",
      "[]\n",
      "[[-0.35394276  0.88556212]\n",
      " [ 1.46589301  0.94097402]\n",
      " [ 0.57875945  0.00799213]]\n",
      "SOFTMAX_LAYER\n",
      "[0.44875834488732658, 0.55124165511267342]\n",
      "LOSS PER INSTANCE: 0.595582\n",
      "DERIVATIVE LOSS: -1.814086\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.595582\n",
      "EPOCH 37\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.52039325 -0.02578291  0.        ]\n",
      " [-0.26576463 -1.37305436  0.        ]\n",
      " [ 2.39008688  1.11521227  0.        ]]\n",
      "[]\n",
      "[[-0.34258929  0.89423813]\n",
      " [ 1.47763407  0.94994621]\n",
      " [ 0.58804163  0.01508532]]\n",
      "SOFTMAX_LAYER\n",
      "[0.45039926594251101, 0.54960073405748888]\n",
      "LOSS PER INSTANCE: 0.598563\n",
      "DERIVATIVE LOSS: -1.819503\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.598563\n",
      "EPOCH 38\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.51999276 -0.02766243  0.        ]\n",
      " [-0.26616513 -1.37493388  0.        ]\n",
      " [ 2.39048737  1.11709179  0.        ]]\n",
      "[]\n",
      "[[-0.33159896  0.90268577]\n",
      " [ 1.48900314  0.95868497]\n",
      " [ 0.59702581  0.02199095]]\n",
      "SOFTMAX_LAYER\n",
      "[0.45195760321641087, 0.54804239678358924]\n",
      "LOSS PER INSTANCE: 0.601403\n",
      "DERIVATIVE LOSS: -1.824676\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.601403\n",
      "EPOCH 39\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.51958118 -0.02949214  0.        ]\n",
      " [-0.2665767  -1.37676359  0.        ]\n",
      " [ 2.39089895  1.1189215   0.        ]]\n",
      "[]\n",
      "[[-0.32095455  0.91091425]\n",
      " [ 1.50001761  0.96719952]\n",
      " [ 0.60572611  0.02871657]]\n",
      "SOFTMAX_LAYER\n",
      "[0.45343816656780284, 0.54656183343219711]\n",
      "LOSS PER INSTANCE: 0.604108\n",
      "DERIVATIVE LOSS: -1.829619\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.604108\n",
      "EPOCH 40\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.51916003 -0.03127392  0.        ]\n",
      " [-0.26699786 -1.37854537  0.        ]\n",
      " [ 2.3913201   1.12070328  0.        ]]\n",
      "[]\n",
      "[[-0.31063971  0.91893235]\n",
      " [ 1.51069402  0.97549868]\n",
      " [ 0.61415595  0.03526938]]\n",
      "SOFTMAX_LAYER\n",
      "[0.45484552035973902, 0.54515447964026087]\n",
      "LOSS PER INSTANCE: 0.606686\n",
      "DERIVATIVE LOSS: -1.834342\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.606686\n",
      "EPOCH 41\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.51873065 -0.03300959  0.        ]\n",
      " [-0.26742724 -1.38028104  0.        ]\n",
      " [ 2.39174948  1.12243895  0.        ]]\n",
      "[]\n",
      "[[-0.3006389   0.92674844]\n",
      " [ 1.5210481   0.98359086]\n",
      " [ 0.62232805  0.04165625]]\n",
      "SOFTMAX_LAYER\n",
      "[0.4561839815703439, 0.5438160184296561]\n",
      "LOSS PER INSTANCE: 0.609144\n",
      "DERIVATIVE LOSS: -1.838857\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.609144\n",
      "EPOCH 42\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.51829426 -0.0347009   0.        ]\n",
      " [-0.26786363 -1.38197235  0.        ]\n",
      " [ 2.39218587  1.12413026  0.        ]]\n",
      "[]\n",
      "[[-0.29093741  0.9343705 ]\n",
      " [ 1.53109477  0.99148412]\n",
      " [ 0.63025448  0.04788372]]\n",
      "SOFTMAX_LAYER\n",
      "[0.45745762219949931, 0.54254237780050063]\n",
      "LOSS PER INSTANCE: 0.611489\n",
      "DERIVATIVE LOSS: -1.843174\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.611489\n",
      "EPOCH 43\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.51785197 -0.03634955  0.        ]\n",
      " [-0.26830592 -1.383621    0.        ]\n",
      " [ 2.39262816  1.12577891  0.        ]]\n",
      "[]\n",
      "[[-0.28152132  0.94180616]\n",
      " [ 1.54084817  0.99918614]\n",
      " [ 0.63794667  0.05395806]]\n",
      "SOFTMAX_LAYER\n",
      "[0.45867027482672462, 0.54132972517327549]\n",
      "LOSS PER INSTANCE: 0.613727\n",
      "DERIVATIVE LOSS: -1.847303\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.613727\n",
      "EPOCH 44\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.51740475 -0.03795717  0.        ]\n",
      " [-0.26875314 -1.38522862  0.        ]\n",
      " [ 2.39307538  1.12738653  0.        ]]\n",
      "[]\n",
      "[[-0.27237745  0.94906267]\n",
      " [ 1.55032168  1.00670426]\n",
      " [ 0.64541544  0.05988523]]\n",
      "SOFTMAX_LAYER\n",
      "[0.45982554041325407, 0.54017445958674593]\n",
      "LOSS PER INSTANCE: 0.615863\n",
      "DERIVATIVE LOSS: -1.851254\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.615863\n",
      "EPOCH 45\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.5169535  -0.03952533  0.        ]\n",
      " [-0.26920438 -1.38679678  0.        ]\n",
      " [ 2.39352663  1.12895469  0.        ]]\n",
      "[]\n",
      "[[-0.26349334  0.95614695]\n",
      " [ 1.55952801  1.01404548]\n",
      " [ 0.65267102  0.0656709 ]]\n",
      "SOFTMAX_LAYER\n",
      "[0.46092679763628347, 0.53907320236371647]\n",
      "LOSS PER INSTANCE: 0.617904\n",
      "DERIVATIVE LOSS: -1.855036\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.617904\n",
      "EPOCH 46\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.51649902 -0.04105552  0.        ]\n",
      " [-0.26965886 -1.38832697  0.        ]\n",
      " [ 2.39398111  1.13048488  0.        ]]\n",
      "[]\n",
      "[[-0.25485722  0.9630656 ]\n",
      " [ 1.56847912  1.02121648]\n",
      " [ 0.65972307  0.0713205 ]]\n",
      "SOFTMAX_LAYER\n",
      "[0.46197721320184765, 0.53802278679815241]\n",
      "LOSS PER INSTANCE: 0.619854\n",
      "DERIVATIVE LOSS: -1.858657\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.619854\n",
      "EPOCH 47\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.51604203 -0.04254919  0.        ]\n",
      " [-0.27011586 -1.38982064  0.        ]\n",
      " [ 2.3944381   1.13197855  0.        ]]\n",
      "[]\n",
      "[[-0.24645794  0.9698249 ]\n",
      " [ 1.57718638  1.02822362]\n",
      " [ 0.66658074  0.0768392 ]]\n",
      "SOFTMAX_LAYER\n",
      "[0.46297975271063141, 0.53702024728936848]\n",
      "LOSS PER INSTANCE: 0.621719\n",
      "DERIVATIVE LOSS: -1.862127\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.621719\n",
      "EPOCH 48\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.51558316 -0.04400772  0.        ]\n",
      " [-0.27057473 -1.39127917  0.        ]\n",
      " [ 2.39489697  1.13343708  0.        ]]\n",
      "[]\n",
      "[[-0.23828499  0.97643084]\n",
      " [ 1.58566051  1.03507301]\n",
      " [ 0.67325266  0.0822319 ]]\n",
      "SOFTMAX_LAYER\n",
      "[0.46393719175338649, 0.53606280824661345]\n",
      "LOSS PER INSTANCE: 0.623504\n",
      "DERIVATIVE LOSS: -1.865453\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.623504\n",
      "EPOCH 49\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.515123   -0.04543242  0.        ]\n",
      " [-0.27103489 -1.39270387  0.        ]\n",
      " [ 2.39535713  1.13486178  0.        ]]\n",
      "[]\n",
      "[[-0.23032844  0.98288914]\n",
      " [ 1.59391167  1.04177043]\n",
      " [ 0.679747    0.08750332]]\n",
      "SOFTMAX_LAYER\n",
      "[0.46485212699403622, 0.53514787300596378]\n",
      "LOSS PER INSTANCE: 0.625212\n",
      "DERIVATIVE LOSS: -1.868642\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.625212\n",
      "EPOCH 50\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.51466206 -0.04682456  0.        ]\n",
      " [-0.27149583 -1.394096    0.        ]\n",
      " [ 2.39581807  1.13625392  0.        ]]\n",
      "[]\n",
      "[[-0.22257888  0.98920522]\n",
      " [ 1.60194945  1.04832142]\n",
      " [ 0.68607147  0.09265793]]\n",
      "SOFTMAX_LAYER\n",
      "[0.46572698706287591, 0.53427301293712415]\n",
      "LOSS PER INSTANCE: 0.626848\n",
      "DERIVATIVE LOSS: -1.871702\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.626848\n",
      "EPOCH 51\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.5142008  -0.04818533  0.        ]\n",
      " [-0.27195708 -1.39545678  0.        ]\n",
      " [ 2.39627933  1.13761469  0.        ]]\n",
      "[]\n",
      "[[-0.21502744  0.9953843 ]\n",
      " [ 1.60978293  1.05473128]\n",
      " [ 0.69223337  0.09769999]]\n",
      "SOFTMAX_LAYER\n",
      "[0.46656404313273492, 0.53343595686726508]\n",
      "LOSS PER INSTANCE: 0.628416\n",
      "DERIVATIVE LOSS: -1.874639\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.628416\n",
      "EPOCH 52\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.51373965 -0.04951589  0.        ]\n",
      " [-0.27241824 -1.39678734  0.        ]\n",
      " [ 2.39674048  1.13894525  0.        ]]\n",
      "[]\n",
      "[[-0.20766572  1.0014313 ]\n",
      " [ 1.61742071  1.06100503]\n",
      " [ 0.69823959  0.10263357]]\n",
      "SOFTMAX_LAYER\n",
      "[0.46736541909028739, 0.53263458090971261]\n",
      "LOSS PER INSTANCE: 0.629920\n",
      "DERIVATIVE LOSS: -1.877460\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.629920\n",
      "EPOCH 53\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.51327896 -0.05081735  0.        ]\n",
      " [-0.27287893 -1.3980888   0.        ]\n",
      " [ 2.39720117  1.14024671  0.        ]]\n",
      "[]\n",
      "[[-0.20048577  1.00735095]\n",
      " [ 1.62487091  1.06714751]\n",
      " [ 0.70409667  0.10746256]]\n",
      "SOFTMAX_LAYER\n",
      "[0.46813310124507124, 0.53186689875492876]\n",
      "LOSS PER INSTANCE: 0.631362\n",
      "DERIVATIVE LOSS: -1.880170\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.631362\n",
      "EPOCH 54\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.51281908 -0.05209074  0.        ]\n",
      " [-0.27333881 -1.39936219  0.        ]\n",
      " [ 2.39766105  1.1415201   0.        ]]\n",
      "[]\n",
      "[[-0.19348009  1.01314777]\n",
      " [ 1.63214123  1.07316329]\n",
      " [ 0.70981077  0.11219066]]\n",
      "SOFTMAX_LAYER\n",
      "[0.46886894754203928, 0.53113105245796077]\n",
      "LOSS PER INSTANCE: 0.632746\n",
      "DERIVATIVE LOSS: -1.882774\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.632746\n",
      "EPOCH 55\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.51236028 -0.05333708  0.        ]\n",
      " [-0.2737976  -1.40060853  0.        ]\n",
      " [ 2.39811984  1.14276644  0.        ]]\n",
      "[]\n",
      "[[-0.18664155  1.01882603]\n",
      " [ 1.63923897  1.07905678]\n",
      " [ 0.71538775  0.11682141]]\n",
      "SOFTMAX_LAYER\n",
      "[0.46957469626109372, 0.5304253037389064]\n",
      "LOSS PER INSTANCE: 0.634076\n",
      "DERIVATIVE LOSS: -1.885280\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.634076\n",
      "EPOCH 56\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.51190285 -0.05455732  0.        ]\n",
      " [-0.27425504 -1.40182876  0.        ]\n",
      " [ 2.39857728  1.14398667  0.        ]]\n",
      "[]\n",
      "[[-0.17996343  1.02438985]\n",
      " [ 1.64617102  1.08483216]\n",
      " [ 0.72083312  0.12135818]]\n",
      "SOFTMAX_LAYER\n",
      "[0.47025197420021886, 0.52974802579978109]\n",
      "LOSS PER INSTANCE: 0.635354\n",
      "DERIVATIVE LOSS: -1.887690\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.635354\n",
      "EPOCH 57\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.51144701 -0.05575237  0.        ]\n",
      " [-0.27471088 -1.40302382  0.        ]\n",
      " [ 2.39903312  1.14518173  0.        ]]\n",
      "[]\n",
      "[[-0.17343934  1.02984315]\n",
      " [ 1.65294394  1.09049345]\n",
      " [ 0.72615215  0.1258042 ]]\n",
      "SOFTMAX_LAYER\n",
      "[0.47090230434851582, 0.52909769565148412]\n",
      "LOSS PER INSTANCE: 0.636582\n",
      "DERIVATIVE LOSS: -1.890010\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.636582\n",
      "EPOCH 58\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.51099296 -0.05692311  0.        ]\n",
      " [-0.27516493 -1.40419456  0.        ]\n",
      " [ 2.39948717  1.14635247  0.        ]]\n",
      "[]\n",
      "[[-0.16706323  1.03518967]\n",
      " [ 1.65956394  1.09604447]\n",
      " [ 0.73134978  0.13016254]]\n",
      "SOFTMAX_LAYER\n",
      "[0.47152711306239226, 0.52847288693760774]\n",
      "LOSS PER INSTANCE: 0.637764\n",
      "DERIVATIVE LOSS: -1.892245\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.637764\n",
      "EPOCH 59\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.51054089 -0.05807038  0.        ]\n",
      " [-0.27561699 -1.40534183  0.        ]\n",
      " [ 2.39993924  1.14749974  0.        ]]\n",
      "[]\n",
      "[[-0.16082938  1.04043297]\n",
      " [ 1.66603689  1.10148889]\n",
      " [ 0.73643075  0.13443615]]\n",
      "SOFTMAX_LAYER\n",
      "[0.47212773676300551, 0.52787226323699454]\n",
      "LOSS PER INSTANCE: 0.638901\n",
      "DERIVATIVE LOSS: -1.894398\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.638901\n",
      "EPOCH 60\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.51009097 -0.05919497  0.        ]\n",
      " [-0.27606692 -1.40646642  0.        ]\n",
      " [ 2.40038916  1.14862433  0.        ]]\n",
      "[]\n",
      "[[-0.15473235  1.04557649]\n",
      " [ 1.67236839  1.1068302 ]\n",
      " [ 0.74139951  0.13862784]]\n",
      "SOFTMAX_LAYER\n",
      "[0.47270542817626804, 0.52729457182373196]\n",
      "LOSS PER INSTANCE: 0.639996\n",
      "DERIVATIVE LOSS: -1.896473\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.639996\n",
      "EPOCH 61\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.50964333 -0.06029765  0.        ]\n",
      " [-0.27651456 -1.40756909  0.        ]\n",
      " [ 2.4008368   1.14972701  0.        ]]\n",
      "[]\n",
      "[[-0.14876696  1.05062348]\n",
      " [ 1.67856375  1.11207176]\n",
      " [ 0.7462603   0.14274029]]\n",
      "SOFTMAX_LAYER\n",
      "[0.47326136213869247, 0.52673863786130759]\n",
      "LOSS PER INSTANCE: 0.641051\n",
      "DERIVATIVE LOSS: -1.898475\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.641051\n",
      "EPOCH 62\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.5091981  -0.06137914  0.        ]\n",
      " [-0.27695979 -1.40865059  0.        ]\n",
      " [ 2.40128203  1.1508085   0.        ]]\n",
      "[]\n",
      "[[-0.14292831  1.05557708]\n",
      " [ 1.68462801  1.11721677]\n",
      " [ 0.75101717  0.14677609]]\n",
      "SOFTMAX_LAYER\n",
      "[0.47379664099337859, 0.52620335900662141]\n",
      "LOSS PER INSTANCE: 0.642068\n",
      "DERIVATIVE LOSS: -1.900406\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.642068\n",
      "EPOCH 63\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.50875538 -0.06244014  0.        ]\n",
      " [-0.2774025  -1.40971159  0.        ]\n",
      " [ 2.40172475  1.1518695   0.        ]]\n",
      "[]\n",
      "[[-0.13721175  1.06044027]\n",
      " [ 1.69056596  1.1222683 ]\n",
      " [ 0.75567393  0.15073769]]\n",
      "SOFTMAX_LAYER\n",
      "[0.47431229960077032, 0.52568770039922963]\n",
      "LOSS PER INSTANCE: 0.643048\n",
      "DERIVATIVE LOSS: -1.902270\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.643048\n",
      "EPOCH 64\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.50831528 -0.06348133  0.        ]\n",
      " [-0.2778426  -1.41075278  0.        ]\n",
      " [ 2.40216485  1.15291069  0.        ]]\n",
      "[]\n",
      "[[-0.13161285  1.06521592]\n",
      " [ 1.69638215  1.12722929]\n",
      " [ 0.76023422  0.15462745]]\n",
      "SOFTMAX_LAYER\n",
      "[0.47480930998860932, 0.52519069001139063]\n",
      "LOSS PER INSTANCE: 0.643994\n",
      "DERIVATIVE LOSS: -1.904070\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.643994\n",
      "EPOCH 65\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.50787788 -0.06450333  0.        ]\n",
      " [-0.27828001 -1.41177478  0.        ]\n",
      " [ 2.40260225  1.15393269  0.        ]]\n",
      "[]\n",
      "[[-0.12612739  1.06990677]\n",
      " [ 1.70208094  1.13210256]\n",
      " [ 0.76470151  0.15844762]]\n",
      "SOFTMAX_LAYER\n",
      "[0.47528858566494786, 0.5247114143350522]\n",
      "LOSS PER INSTANCE: 0.644907\n",
      "DERIVATIVE LOSS: -1.905810\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.644907\n",
      "EPOCH 66\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.50744324 -0.06550676  0.        ]\n",
      " [-0.27871465 -1.41277821  0.        ]\n",
      " [ 2.40303689  1.15493612  0.        ]]\n",
      "[]\n",
      "[[-0.12075137  1.07451544]\n",
      " [ 1.70766643  1.13689081]\n",
      " [ 0.76907909  0.16220036]]\n",
      "SOFTMAX_LAYER\n",
      "[0.47575098561724716, 0.52424901438275273]\n",
      "LOSS PER INSTANCE: 0.645788\n",
      "DERIVATIVE LOSS: -1.907490\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.645788\n",
      "EPOCH 67\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.50701143 -0.06649221  0.        ]\n",
      " [-0.27914646 -1.41376366  0.        ]\n",
      " [ 2.4034687   1.15592157  0.        ]]\n",
      "[]\n",
      "[[-0.11548096  1.07904445]\n",
      " [ 1.71314257  1.14159662]\n",
      " [ 0.77337011  0.16588775]]\n",
      "SOFTMAX_LAYER\n",
      "[0.47619731801959225, 0.5238026819804078]\n",
      "LOSS PER INSTANCE: 0.646640\n",
      "DERIVATIVE LOSS: -1.909116\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.646640\n",
      "EPOCH 68\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.50658249 -0.06746023  0.        ]\n",
      " [-0.2795754  -1.41473168  0.        ]\n",
      " [ 2.40389764  1.15688959  0.        ]]\n",
      "[]\n",
      "[[-0.11031253  1.08349622]\n",
      " [ 1.71851311  1.14622247]\n",
      " [ 0.77757753  0.16951177]]\n",
      "SOFTMAX_LAYER\n",
      "[0.47662834366892154, 0.52337165633107852]\n",
      "LOSS PER INSTANCE: 0.647463\n",
      "DERIVATIVE LOSS: -1.910688\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.647463\n",
      "EPOCH 69\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.50615647 -0.06841136  0.        ]\n",
      " [-0.28000142 -1.41568281  0.        ]\n",
      " [ 2.40432366  1.15784072  0.        ]]\n",
      "[]\n",
      "[[-0.10524261  1.08787306]\n",
      " [ 1.72378162  1.15077074]\n",
      " [ 0.78170422  0.17307432]]\n",
      "SOFTMAX_LAYER\n",
      "[0.4770447791700177, 0.52295522082998214]\n",
      "LOSS PER INSTANCE: 0.648259\n",
      "DERIVATIVE LOSS: -1.912210\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.648259\n",
      "EPOCH 70\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.5057334  -0.06934612  0.        ]\n",
      " [-0.28042448 -1.41661757  0.        ]\n",
      " [ 2.40474673  1.15877548  0.        ]]\n",
      "[]\n",
      "[[-0.10026789  1.09217719]\n",
      " [ 1.7289515   1.15524372]\n",
      " [ 0.7857529   0.17657724]]\n",
      "SOFTMAX_LAYER\n",
      "[0.47744729988778889, 0.522552700112211]\n",
      "LOSS PER INSTANCE: 0.649029\n",
      "DERIVATIVE LOSS: -1.913683\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.649029\n",
      "EPOCH 71\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.50531332 -0.07026501  0.        ]\n",
      " [-0.28084457 -1.41753645  0.        ]\n",
      " [ 2.40516681  1.15969436  0.        ]]\n",
      "[]\n",
      "[[-0.09538522  1.09641073]\n",
      " [ 1.734026    1.1596436 ]\n",
      " [ 0.78972614  0.18002226]]\n",
      "SOFTMAX_LAYER\n",
      "[0.47783654268419196, 0.52216345731580804]\n",
      "LOSS PER INSTANCE: 0.649775\n",
      "DERIVATIVE LOSS: -1.915109\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.649775\n",
      "EPOCH 72\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.50489623 -0.07116848  0.        ]\n",
      " [-0.28126165 -1.41843993  0.        ]\n",
      " [ 2.4055839   1.16059784  0.        ]]\n",
      "[]\n",
      "[[-0.0905916   1.10057573]\n",
      " [ 1.73900825  1.16397249]\n",
      " [ 0.79362643  0.18341108]]\n",
      "SOFTMAX_LAYER\n",
      "[0.47821310845597792, 0.52178689154402214]\n",
      "LOSS PER INSTANCE: 0.650496\n",
      "DERIVATIVE LOSS: -1.916491\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.650496\n",
      "EPOCH 73\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.50448217 -0.072057    0.        ]\n",
      " [-0.28167572 -1.41932845  0.        ]\n",
      " [ 2.40599796  1.16148636  0.        ]]\n",
      "[]\n",
      "[[-0.08588413  1.10467417]\n",
      " [ 1.74390119  1.16823241]\n",
      " [ 0.79745613  0.18674531]]\n",
      "SOFTMAX_LAYER\n",
      "[0.4785775644883114, 0.52142243551168854]\n",
      "LOSS PER INSTANCE: 0.651195\n",
      "DERIVATIVE LOSS: -1.917831\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.651195\n",
      "EPOCH 74\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.50407113 -0.07293101  0.        ]\n",
      " [-0.28208676 -1.42020246  0.        ]\n",
      " [ 2.406409    1.16236037  0.        ]]\n",
      "[]\n",
      "[[-0.08126008  1.10870792]\n",
      " [ 1.74870768  1.1724253 ]\n",
      " [ 0.8012175   0.1900265 ]]\n",
      "SOFTMAX_LAYER\n",
      "[0.47893044663824108, 0.52106955336175897]\n",
      "LOSS PER INSTANCE: 0.651872\n",
      "DERIVATIVE LOSS: -1.919130\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.651872\n",
      "EPOCH 75\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.50366312 -0.07379092  0.        ]\n",
      " [-0.28249477 -1.42106237  0.        ]\n",
      " [ 2.40681701  1.16322028  0.        ]]\n",
      "[]\n",
      "[[-0.07671681  1.11267879]\n",
      " [ 1.75343042  1.17655304]\n",
      " [ 0.8049127   0.19325615]]\n",
      "SOFTMAX_LAYER\n",
      "[0.47927226136096962, 0.52072773863903044]\n",
      "LOSS PER INSTANCE: 0.652528\n",
      "DERIVATIVE LOSS: -1.920389\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.652528\n",
      "EPOCH 76\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.50325815 -0.07463713  0.        ]\n",
      " [-0.28289974 -1.42190858  0.        ]\n",
      " [ 2.40722198  1.16406649  0.        ]]\n",
      "[]\n",
      "[[-0.07225181  1.11658854]\n",
      " [ 1.75807202  1.18061742]\n",
      " [ 0.80854378  0.19643569]]\n",
      "SOFTMAX_LAYER\n",
      "[0.47960348759090793, 0.52039651240909213]\n",
      "LOSS PER INSTANCE: 0.653164\n",
      "DERIVATIVE LOSS: -1.921612\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.653164\n",
      "EPOCH 77\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.50285621 -0.07547004  0.        ]\n",
      " [-0.28330167 -1.42274149  0.        ]\n",
      " [ 2.40762392  1.1648994   0.        ]]\n",
      "[]\n",
      "[[-0.06786267  1.12043884]\n",
      " [ 1.76263494  1.18462017]\n",
      " [ 0.81211274  0.1995665 ]]\n",
      "SOFTMAX_LAYER\n",
      "[0.47992457848859005, 0.52007542151141006]\n",
      "LOSS PER INSTANCE: 0.653781\n",
      "DERIVATIVE LOSS: -1.922798\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.653781\n",
      "EPOCH 78\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.50245731 -0.07629001  0.        ]\n",
      " [-0.28370058 -1.42356146  0.        ]\n",
      " [ 2.40802282  1.16571937  0.        ]]\n",
      "[]\n",
      "[[-0.06354709  1.12423131]\n",
      " [ 1.76712158  1.18856297]\n",
      " [ 0.81562145  0.2026499 ]]\n",
      "SOFTMAX_LAYER\n",
      "[0.48023596306367383, 0.51976403693632622]\n",
      "LOSS PER INSTANCE: 0.654380\n",
      "DERIVATIVE LOSS: -1.923950\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.654380\n",
      "EPOCH 79\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.50206142 -0.0770974   0.        ]\n",
      " [-0.28409647 -1.42436885  0.        ]\n",
      " [ 2.40841871  1.16652676  0.        ]]\n",
      "[]\n",
      "[[-0.05930286  1.1279675 ]\n",
      " [ 1.77153422  1.1924474 ]\n",
      " [ 0.81907174  0.20568718]]\n",
      "SOFTMAX_LAYER\n",
      "[0.48053804768346631, 0.51946195231653358]\n",
      "LOSS PER INSTANCE: 0.654962\n",
      "DERIVATIVE LOSS: -1.925069\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.654962\n",
      "EPOCH 80\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.50166854 -0.07789256  0.        ]\n",
      " [-0.28448934 -1.425164    0.        ]\n",
      " [ 2.40881159  1.16732192  0.        ]]\n",
      "[]\n",
      "[[-0.05512787  1.1316489 ]\n",
      " [ 1.77587504  1.19627502]\n",
      " [ 0.82246534  0.20867957]]\n",
      "SOFTMAX_LAYER\n",
      "[0.48083121747567453, 0.51916878252432552]\n",
      "LOSS PER INSTANCE: 0.655526\n",
      "DERIVATIVE LOSS: -1.926156\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.655526\n",
      "EPOCH 81\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.50127866 -0.07867581  0.        ]\n",
      " [-0.28487922 -1.42594725  0.        ]\n",
      " [ 2.40920147  1.16810517  0.        ]]\n",
      "[]\n",
      "[[-0.05102008  1.13527695]\n",
      " [ 1.78014613  1.20004731]\n",
      " [ 0.82580391  0.21162824]]\n",
      "SOFTMAX_LAYER\n",
      "[0.4811158376333986, 0.51888416236660151]\n",
      "LOSS PER INSTANCE: 0.656075\n",
      "DERIVATIVE LOSS: -1.927212\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.656075\n",
      "EPOCH 82\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.50089176 -0.07944747  0.        ]\n",
      " [-0.28526612 -1.42671892  0.        ]\n",
      " [ 2.40958837  1.16887683  0.        ]]\n",
      "[]\n",
      "[[-0.04697756  1.13885305]\n",
      " [ 1.78434952  1.20376572]\n",
      " [ 0.82908906  0.21453435]]\n",
      "SOFTMAX_LAYER\n",
      "[0.48139225462976343, 0.51860774537023668]\n",
      "LOSS PER INSTANCE: 0.656607\n",
      "DERIVATIVE LOSS: -1.928240\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.656607\n",
      "EPOCH 83\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.50050783 -0.08020785  0.        ]\n",
      " [-0.28565006 -1.4274793   0.        ]\n",
      " [ 2.4099723   1.16963721  0.        ]]\n",
      "[]\n",
      "[[-0.04299843  1.14237854]\n",
      " [ 1.78848712  1.20743161]\n",
      " [ 0.83232231  0.217399  ]]\n",
      "SOFTMAX_LAYER\n",
      "[0.48166079734898831, 0.51833920265101163]\n",
      "LOSS PER INSTANCE: 0.657125\n",
      "DERIVATIVE LOSS: -1.929239\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.657125\n",
      "EPOCH 84\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.50012684 -0.08095725  0.        ]\n",
      " [-0.28603104 -1.4282287   0.        ]\n",
      " [ 2.41035329  1.17038661  0.        ]]\n",
      "[]\n",
      "[[-0.0390809   1.1458547 ]\n",
      " [ 1.7925608   1.21104632]\n",
      " [ 0.83550514  0.22022324]]\n",
      "SOFTMAX_LAYER\n",
      "[0.48192177814017079, 0.51807822185982921]\n",
      "LOSS PER INSTANCE: 0.657629\n",
      "DERIVATIVE LOSS: -1.930210\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.657629\n",
      "EPOCH 85\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.49974878 -0.08169595  0.        ]\n",
      " [-0.2864091  -1.4289674   0.        ]\n",
      " [ 2.41073135  1.17112531  0.        ]]\n",
      "[]\n",
      "[[-0.03522324  1.14928278]\n",
      " [ 1.79657233  1.21461115]\n",
      " [ 0.83863897  0.22300809]]\n",
      "SOFTMAX_LAYER\n",
      "[0.4821754937995546, 0.5178245062004454]\n",
      "LOSS PER INSTANCE: 0.658119\n",
      "DERIVATIVE LOSS: -1.931156\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.658119\n",
      "EPOCH 86\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.49937363 -0.08242422  0.        ]\n",
      " [-0.28678426 -1.42969567  0.        ]\n",
      " [ 2.4111065   1.17185358  0.        ]]\n",
      "[]\n",
      "[[-0.03142382  1.15266398]\n",
      " [ 1.80052343  1.21812733]\n",
      " [ 0.84172514  0.22575455]]\n",
      "SOFTMAX_LAYER\n",
      "[0.48242222648660349, 0.51757777351339651]\n",
      "LOSS PER INSTANCE: 0.658595\n",
      "DERIVATIVE LOSS: -1.932077\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.658595\n",
      "EPOCH 87\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.49900135 -0.08314234  0.        ]\n",
      " [-0.28715654 -1.43041378  0.        ]\n",
      " [ 2.41147878  1.1725717   0.        ]]\n",
      "[]\n",
      "[[-0.02768102  1.15599947]\n",
      " [ 1.80441575  1.22159606]\n",
      " [ 0.84476498  0.22846357]]\n",
      "SOFTMAX_LAYER\n",
      "[0.48266224457877732, 0.51733775542122273]\n",
      "LOSS PER INSTANCE: 0.659059\n",
      "DERIVATIVE LOSS: -1.932973\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.659059\n",
      "EPOCH 88\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.49863194 -0.08385054  0.        ]\n",
      " [-0.28752595 -1.43112199  0.        ]\n",
      " [ 2.41184819  1.1732799   0.        ]]\n",
      "[]\n",
      "[[-0.02399333  1.15929035]\n",
      " [ 1.80825086  1.22501849]\n",
      " [ 0.84775972  0.23113607]]\n",
      "SOFTMAX_LAYER\n",
      "[0.48289580346952482, 0.51710419653047512]\n",
      "LOSS PER INSTANCE: 0.659511\n",
      "DERIVATIVE LOSS: -1.933846\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.659511\n",
      "EPOCH 89\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.49826535 -0.08454909  0.        ]\n",
      " [-0.28789253 -1.43182054  0.        ]\n",
      " [ 2.41221478  1.17397845  0.        ]]\n",
      "[]\n",
      "[[-0.02035926  1.16253771]\n",
      " [ 1.81203029  1.22839575]\n",
      " [ 0.85071059  0.23377294]]\n",
      "SOFTMAX_LAYER\n",
      "[0.48312314631365061, 0.51687685368634939]\n",
      "LOSS PER INSTANCE: 0.659951\n",
      "DERIVATIVE LOSS: -1.934697\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.659951\n",
      "EPOCH 90\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.49790158 -0.08523822  0.        ]\n",
      " [-0.28825631 -1.43250967  0.        ]\n",
      " [ 2.41257855  1.17466758  0.        ]]\n",
      "[]\n",
      "[[-0.01677741  1.1657426 ]\n",
      " [ 1.81575551  1.23172892]\n",
      " [ 0.85361874  0.23637503]]\n",
      "SOFTMAX_LAYER\n",
      "[0.48334450472388835, 0.51665549527611165]\n",
      "LOSS PER INSTANCE: 0.660379\n",
      "DERIVATIVE LOSS: -1.935526\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.660379\n",
      "EPOCH 91\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.49754059 -0.08591815  0.        ]\n",
      " [-0.2886173  -1.4331896   0.        ]\n",
      " [ 2.41293954  1.17534751  0.        ]]\n",
      "[]\n",
      "[[-0.01324641  1.16890602]\n",
      " [ 1.81942792  1.23501904]\n",
      " [ 0.8564853   0.23894317]]\n",
      "SOFTMAX_LAYER\n",
      "[0.48356009942221273, 0.51643990057778721]\n",
      "LOSS PER INSTANCE: 0.660796\n",
      "DERIVATIVE LOSS: -1.936334\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.660796\n",
      "EPOCH 92\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.49718236 -0.08658912  0.        ]\n",
      " [-0.28897553 -1.43386057  0.        ]\n",
      " [ 2.41329777  1.17601848  0.        ]]\n",
      "[]\n",
      "[[-0.00976494  1.17202895]\n",
      " [ 1.8230489   1.23826711]\n",
      " [ 0.85931134  0.24147817]]\n",
      "SOFTMAX_LAYER\n",
      "[0.48377014084914916, 0.51622985915085073]\n",
      "LOSS PER INSTANCE: 0.661203\n",
      "DERIVATIVE LOSS: -1.937122\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.661203\n",
      "EPOCH 93\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.49682686 -0.08725133  0.        ]\n",
      " [-0.28933103 -1.43452278  0.        ]\n",
      " [ 2.41365327  1.17668069  0.        ]]\n",
      "[]\n",
      "[[-0.00633173  1.17511234]\n",
      " [ 1.82661976  1.24147412]\n",
      " [ 0.8620979   0.24398081]]\n",
      "SOFTMAX_LAYER\n",
      "[0.48397482973408151, 0.51602517026591854]\n",
      "LOSS PER INSTANCE: 0.661600\n",
      "DERIVATIVE LOSS: -1.937890\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.661600\n",
      "EPOCH 94\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.49647406 -0.08790499  0.        ]\n",
      " [-0.28968383 -1.43517644  0.        ]\n",
      " [ 2.41400607  1.17733435  0.        ]]\n",
      "[]\n",
      "[[-0.00294557  1.1781571 ]\n",
      " [ 1.83014175  1.24464101]\n",
      " [ 0.86484599  0.24645182]]\n",
      "SOFTMAX_LAYER\n",
      "[0.48417435762933514, 0.51582564237066486]\n",
      "LOSS PER INSTANCE: 0.661986\n",
      "DERIVATIVE LOSS: -1.938640\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.661986\n",
      "EPOCH 95\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.49612393 -0.0885503   0.        ]\n",
      " [-0.29003395 -1.43582175  0.        ]\n",
      " [ 2.4143562   1.17797966  0.        ]]\n",
      "[]\n",
      "[[  3.94716663e-04   1.18116410e+00]\n",
      " [  1.83361609e+00   1.24776870e+00]\n",
      " [  8.67556568e-01   2.48891947e-01]]\n",
      "SOFTMAX_LAYER\n",
      "[0.4843689074105913, 0.51563109258940876]\n",
      "LOSS PER INSTANCE: 0.662364\n",
      "DERIVATIVE LOSS: -1.939371\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.662364\n",
      "EPOCH 96\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.49577646 -0.08918746  0.        ]\n",
      " [-0.29038143 -1.43645891  0.        ]\n",
      " [ 2.41470367  1.17861682  0.        ]]\n",
      "[]\n",
      "[[ 0.00369028  1.18413421]\n",
      " [ 1.83704397  1.25085806]\n",
      " [ 0.87023057  0.25130188]]\n",
      "SOFTMAX_LAYER\n",
      "[0.48455865374599649, 0.5154413462540034]\n",
      "LOSS PER INSTANCE: 0.662732\n",
      "DERIVATIVE LOSS: -1.940085\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.662732\n",
      "EPOCH 97\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.4954316  -0.08981665  0.        ]\n",
      " [-0.29072629 -1.4370881   0.        ]\n",
      " [ 2.41504853  1.17924601  0.        ]]\n",
      "[]\n",
      "[[ 0.0069422   1.18706825]\n",
      " [ 1.84042652  1.25390996]\n",
      " [ 0.87286889  0.2536823 ]]\n",
      "SOFTMAX_LAYER\n",
      "[0.48474376353614834, 0.51525623646385166]\n",
      "LOSS PER INSTANCE: 0.663091\n",
      "DERIVATIVE LOSS: -1.940782\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.663091\n",
      "EPOCH 98\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.49508933 -0.09043806  0.        ]\n",
      " [-0.29106855 -1.43770951  0.        ]\n",
      " [ 2.4153908   1.17986742  0.        ]]\n",
      "[]\n",
      "[[ 0.01015155  1.18996703]\n",
      " [ 1.84376484  1.25692523]\n",
      " [ 0.87547241  0.25603388]]\n",
      "SOFTMAX_LAYER\n",
      "[0.48492439632697848, 0.51507560367302141]\n",
      "LOSS PER INSTANCE: 0.663442\n",
      "DERIVATIVE LOSS: -1.941463\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.663442\n",
      "EPOCH 99\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[ 0.49474963 -0.09105185  0.        ]\n",
      " [-0.29140825 -1.4383233   0.        ]\n",
      " [ 2.4157305   1.18048121  0.        ]]\n",
      "[]\n",
      "[[ 0.01331934  1.19283132]\n",
      " [ 1.84705998  1.25990466]\n",
      " [ 0.87804195  0.25835723]]\n",
      "SOFTMAX_LAYER\n",
      "[0.48510070469739314, 0.51489929530260681]\n",
      "LOSS PER INSTANCE: 0.663784\n",
      "DERIVATIVE LOSS: -1.942127\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 0.663784\n"
     ]
    }
   ],
   "source": [
    "class SigmoidNN(NN):\n",
    "    def _activate(self, x):\n",
    "        \"\"\"\n",
    "        override RelU with sigmoid\n",
    "        \"\"\"\n",
    "        return self._sigmoid(x)\n",
    "    \n",
    "    def _derivative_activation(self, x):\n",
    "        \"\"\"\n",
    "        Override RelU' with Sigmoid'\n",
    "        \"\"\"\n",
    "        return self._derivative_sigmoid(x)\n",
    "    \n",
    "\"\"\"\n",
    "Run the same test with sigmoid\n",
    "\"\"\"\n",
    "MLP = SigmoidNN(2, 1, 2, 2)\n",
    "xor_inputs = [[1, 1], [-1, 1], [-1, -1], [1, -1]]\n",
    "xor_labels = ([1, 0, 1, 0])\n",
    "MLP.train(xor_inputs, xor_labels, epochs=100, lr=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.79098598 -0.05572377  0.        ]\n",
      " [ 0.08511857  0.25775903  0.        ]\n",
      " [-0.18411189 -1.29343291  0.        ]]\n",
      "[]\n",
      "[[ 0.59895566 -0.9057812 ]\n",
      " [ 0.34696668  0.45134984]\n",
      " [-0.47357902 -0.41719315]]\n",
      "SOFTMAX_LAYER\n",
      "[0.68401889935143889, 0.31598110064856111]\n",
      "LOSS PER INSTANCE: 1.152073\n",
      "DERIVATIVE LOSS: -3.164746\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 1.152073\n",
      "EPOCH 1\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.81341844 -0.01999502  0.        ]\n",
      " [ 0.06268612  0.29348778  0.        ]\n",
      " [-0.16167943 -1.32916166  0.        ]]\n",
      "[]\n",
      "[[ 0.63180385 -0.90036212]\n",
      " [ 0.28495804  0.44112007]\n",
      " [-0.42135735 -0.40857797]]\n",
      "SOFTMAX_LAYER\n",
      "[0.72012928543371213, 0.27987071456628787]\n",
      "LOSS PER INSTANCE: 1.273428\n",
      "DERIVATIVE LOSS: -3.573078\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 1.273428\n",
      "EPOCH 2\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.84084877  0.03564171  0.        ]\n",
      " [ 0.03525579  0.34912451  0.        ]\n",
      " [-0.1342491  -1.38479839  0.        ]]\n",
      "[]\n",
      "[[ 0.68169967 -0.89003912]\n",
      " [ 0.19802291  0.42313397]\n",
      " [-0.34955207 -0.3937221 ]]\n",
      "SOFTMAX_LAYER\n",
      "[0.76257873597637182, 0.23742126402362818]\n",
      "LOSS PER INSTANCE: 1.437919\n",
      "DERIVATIVE LOSS: -4.211923\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 1.437919\n",
      "EPOCH 3\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.87307498  0.11599721  0.        ]\n",
      " [ 0.00302957  0.42948002  0.        ]\n",
      " [-0.10202289 -1.46515389  0.        ]]\n",
      "[]\n",
      "[[ 0.75530196 -0.87228351]\n",
      " [ 0.07948279  0.39453767]\n",
      " [-0.25387262 -0.37064065]]\n",
      "SOFTMAX_LAYER\n",
      "[0.80906477320886983, 0.19093522679113026]\n",
      "LOSS PER INSTANCE: 1.655821\n",
      "DERIVATIVE LOSS: -5.237378\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 1.655821\n",
      "EPOCH 4\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.90298622  0.19831474  0.        ]\n",
      " [-0.02688166  0.51179754  0.        ]\n",
      " [-0.07211165 -1.54747142  0.        ]]\n",
      "[]\n",
      "[[ 0.84737555 -0.84654949]\n",
      " [-0.0580721   0.3560919 ]\n",
      " [-0.14528623 -0.3402914 ]]\n",
      "SOFTMAX_LAYER\n",
      "[0.84956080330496764, 0.15043919669503236]\n",
      "LOSS PER INSTANCE: 1.894196\n",
      "DERIVATIVE LOSS: -6.647204\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 1.894196\n",
      "EPOCH 5\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.91746122  0.22804052  0.        ]\n",
      " [-0.04135666  0.54152332  0.        ]\n",
      " [-0.05763665 -1.5771972   0.        ]]\n",
      "[]\n",
      "[[ 0.91795857 -0.82087468]\n",
      " [-0.15741773  0.3199546 ]\n",
      " [-0.06795113 -0.3121605 ]]\n",
      "SOFTMAX_LAYER\n",
      "[0.87002974310729631, 0.12997025689270364]\n",
      "LOSS PER INSTANCE: 2.040450\n",
      "DERIVATIVE LOSS: -7.694068\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.040450\n",
      "EPOCH 6\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92130694  0.22904151  0.        ]\n",
      " [-0.04520238  0.54252431  0.        ]\n",
      " [-0.05379093 -1.57819819  0.        ]]\n",
      "[]\n",
      "[[ 0.94729737 -0.8059424 ]\n",
      " [-0.19760133  0.29950275]\n",
      " [-0.03678205 -0.29629668]]\n",
      "SOFTMAX_LAYER\n",
      "[0.87570640455008864, 0.12429359544991141]\n",
      "LOSS PER INSTANCE: 2.085109\n",
      "DERIVATIVE LOSS: -8.045467\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.085109\n",
      "EPOCH 7\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92273965  0.22753866  0.        ]\n",
      " [-0.0466351   0.54102147  0.        ]\n",
      " [-0.05235822 -1.57669534  0.        ]]\n",
      "[]\n",
      "[[ 0.96066168 -0.79792686]\n",
      " [-0.21576668  0.28860767]\n",
      " [-0.02269333 -0.28784665]]\n",
      "SOFTMAX_LAYER\n",
      "[0.87774026291280327, 0.12225973708719674]\n",
      "LOSS PER INSTANCE: 2.101608\n",
      "DERIVATIVE LOSS: -8.179308\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.101608\n",
      "EPOCH 8\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92346817  0.22631239  0.        ]\n",
      " [-0.04736361  0.5397952   0.        ]\n",
      " [-0.0516297  -1.57546907  0.        ]]\n",
      "[]\n",
      "[[ 0.96827451 -0.79291944]\n",
      " [-0.22608342  0.28182172]\n",
      " [-0.01469053 -0.28258273]]\n",
      "SOFTMAX_LAYER\n",
      "[0.87872393393833281, 0.12127606606166712]\n",
      "LOSS PER INSTANCE: 2.109686\n",
      "DERIVATIVE LOSS: -8.245650\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.109686\n",
      "EPOCH 9\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92390526  0.22542768  0.        ]\n",
      " [-0.0478007   0.53891049  0.        ]\n",
      " [-0.05119261 -1.57458436  0.        ]]\n",
      "[]\n",
      "[[ 0.97321814 -0.7894616 ]\n",
      " [-0.23277244  0.27714307]\n",
      " [-0.00950109 -0.27895296]]\n",
      "SOFTMAX_LAYER\n",
      "[0.87928588140695174, 0.12071411859304826]\n",
      "LOSS PER INSTANCE: 2.114330\n",
      "DERIVATIVE LOSS: -8.284035\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.114330\n",
      "EPOCH 10\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.924195    0.22478368  0.        ]\n",
      " [-0.04809044  0.53826649  0.        ]\n",
      " [-0.05090287 -1.57394036  0.        ]]\n",
      "[]\n",
      "[[ 0.97670118 -0.78691363]\n",
      " [-0.23748071  0.2736988 ]\n",
      " [-0.00584799 -0.27628058]]\n",
      "SOFTMAX_LAYER\n",
      "[0.87964150402533992, 0.12035849597466011]\n",
      "LOSS PER INSTANCE: 2.117281\n",
      "DERIVATIVE LOSS: -8.308512\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.117281\n",
      "EPOCH 11\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92440032  0.22430259  0.        ]\n",
      " [-0.04829576  0.53778539  0.        ]\n",
      " [-0.05069755 -1.57345927  0.        ]]\n",
      "[]\n",
      "[[ 0.9792948  -0.78494946]\n",
      " [-0.24098445  0.2710454 ]\n",
      " [-0.00312927 -0.27422168]]\n",
      "SOFTMAX_LAYER\n",
      "[0.87988270003791103, 0.12011729996208897]\n",
      "LOSS PER INSTANCE: 2.119287\n",
      "DERIVATIVE LOSS: -8.325195\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.119287\n",
      "EPOCH 12\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92455295  0.22393371  0.        ]\n",
      " [-0.04844839  0.53741652  0.        ]\n",
      " [-0.05054492 -1.57309039  0.        ]]\n",
      "[]\n",
      "[[ 0.98130497 -0.78338429]\n",
      " [-0.24369876  0.26893195]\n",
      " [-0.00102299 -0.27258167]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88005469953363868, 0.11994530046636132]\n",
      "LOSS PER INSTANCE: 2.120719\n",
      "DERIVATIVE LOSS: -8.337134\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.120719\n",
      "EPOCH 13\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92467057  0.22364426  0.        ]\n",
      " [-0.04856601  0.53712706  0.        ]\n",
      " [-0.0504273  -1.57280094  0.        ]]\n",
      "[]\n",
      "[[  9.82910878e-01  -7.82104927e-01]\n",
      " [ -2.45866477e-01   2.67205024e-01]\n",
      " [  6.59198922e-04  -2.71241539e-01]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88018211294621973, 0.1198178870537803]\n",
      "LOSS PER INSTANCE: 2.121782\n",
      "DERIVATIVE LOSS: -8.345999\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.121782\n",
      "EPOCH 14\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.9247638   0.22341255  0.        ]\n",
      " [-0.04865924  0.53689535  0.        ]\n",
      " [-0.05033407 -1.57256923  0.        ]]\n",
      "[]\n",
      "[[ 0.98422468 -0.7810379 ]\n",
      " [-0.24763943  0.26576509]\n",
      " [ 0.00203509 -0.27012408]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88027936634755832, 0.11972063365244172]\n",
      "LOSS PER INSTANCE: 2.122594\n",
      "DERIVATIVE LOSS: -8.352779\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.122594\n",
      "EPOCH 15\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.9248394   0.22322386  0.        ]\n",
      " [-0.04873484  0.53670667  0.        ]\n",
      " [-0.05025847 -1.57238054  0.        ]]\n",
      "[]\n",
      "[[ 0.98532028 -0.78013326]\n",
      " [-0.24911762  0.26454455]\n",
      " [ 0.00318227 -0.26917686]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88035541708595033, 0.11964458291404968]\n",
      "LOSS PER INSTANCE: 2.123230\n",
      "DERIVATIVE LOSS: -8.358088\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.123230\n",
      "EPOCH 16\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92490185  0.22306792  0.        ]\n",
      " [-0.04879729  0.53655072  0.        ]\n",
      " [-0.05019602 -1.5722246   0.        ]]\n",
      "[]\n",
      "[[ 0.98624844 -0.77935582]\n",
      " [-0.25036969  0.26349579]\n",
      " [ 0.00415397 -0.26836294]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88041608825207707, 0.11958391174792292]\n",
      "LOSS PER INSTANCE: 2.123737\n",
      "DERIVATIVE LOSS: -8.362329\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.123737\n",
      "EPOCH 17\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92495425  0.22293737  0.        ]\n",
      " [-0.04884969  0.53642018  0.        ]\n",
      " [-0.05014362 -1.57209405  0.        ]]\n",
      "[]\n",
      "[[ 0.9870452  -0.77867998]\n",
      " [-0.25144435  0.26258422]\n",
      " [ 0.00498802 -0.26765547]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88046531015647156, 0.11953468984352834]\n",
      "LOSS PER INSTANCE: 2.124149\n",
      "DERIVATIVE LOSS: -8.365772\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.124149\n",
      "EPOCH 18\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.9249988   0.22282685  0.        ]\n",
      " [-0.04889424  0.53630965  0.        ]\n",
      " [-0.05009907 -1.57198353  0.        ]]\n",
      "[]\n",
      "[[ 0.9877369  -0.77808667]\n",
      " [-0.2523772   0.26178407]\n",
      " [ 0.00571201 -0.26703447]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88050581986285315, 0.11949418013714687]\n",
      "LOSS PER INSTANCE: 2.124488\n",
      "DERIVATIVE LOSS: -8.368608\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.124488\n",
      "EPOCH 19\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92503711  0.22273234  0.        ]\n",
      " [-0.04893255  0.53621515  0.        ]\n",
      " [-0.05006076 -1.57188902  0.        ]]\n",
      "[]\n",
      "[[ 0.98834323 -0.77756138]\n",
      " [-0.25319483  0.26107571]\n",
      " [ 0.00634659 -0.2664847 ]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88053957463191745, 0.11946042536808257]\n",
      "LOSS PER INSTANCE: 2.124770\n",
      "DERIVATIVE LOSS: -8.370973\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.124770\n",
      "EPOCH 20\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92507039  0.22265082  0.        ]\n",
      " [-0.04896583  0.53613363  0.        ]\n",
      " [-0.05002749 -1.5718075   0.        ]]\n",
      "[]\n",
      "[[ 0.98887921 -0.77709284]\n",
      " [-0.25391754  0.26044394]\n",
      " [ 0.0069075  -0.26599437]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88056800628578524, 0.11943199371421472]\n",
      "LOSS PER INSTANCE: 2.125008\n",
      "DERIVATIVE LOSS: -8.372966\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.125008\n",
      "EPOCH 21\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92509954  0.22257995  0.        ]\n",
      " [-0.04899498  0.53606275  0.        ]\n",
      " [-0.04999833 -1.57173663  0.        ]]\n",
      "[]\n",
      "[[ 0.98935652 -0.77667217]\n",
      " [-0.25456109  0.25987677]\n",
      " [ 0.00740699 -0.26555416]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88059218315285837, 0.11940781684714158]\n",
      "LOSS PER INSTANCE: 2.125211\n",
      "DERIVATIVE LOSS: -8.374661\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.125211\n",
      "EPOCH 22\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92512527  0.22251789  0.        ]\n",
      " [-0.04902072  0.53600069  0.        ]\n",
      " [-0.0499726  -1.57167457  0.        ]]\n",
      "[]\n",
      "[[ 0.98978439 -0.77629229]\n",
      " [-0.25513794  0.25936461]\n",
      " [ 0.0078547  -0.26515665]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88061291626731619, 0.11938708373268385]\n",
      "LOSS PER INSTANCE: 2.125384\n",
      "DERIVATIVE LOSS: -8.376115\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.125384\n",
      "EPOCH 23\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92514815  0.22246321  0.        ]\n",
      " [-0.0490436   0.53594601  0.        ]\n",
      " [-0.04994972 -1.57161989  0.        ]]\n",
      "[]\n",
      "[[ 0.99017017 -0.77594743]\n",
      " [-0.25565802  0.2588997 ]\n",
      " [ 0.00825836 -0.26479582]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88063083083358495, 0.11936916916641507]\n",
      "LOSS PER INSTANCE: 2.125534\n",
      "DERIVATIVE LOSS: -8.377373\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.125534\n",
      "EPOCH 24\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92516862  0.22241474  0.        ]\n",
      " [-0.04906406  0.53589755  0.        ]\n",
      " [-0.04992925 -1.57157142  0.        ]]\n",
      "[]\n",
      "[[ 0.99051984 -0.77563291]\n",
      " [-0.2561294   0.2584757 ]\n",
      " [ 0.00862422 -0.26446673]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88064641542296129, 0.11935358457703865]\n",
      "LOSS PER INSTANCE: 2.125665\n",
      "DERIVATIVE LOSS: -8.378466\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.125665\n",
      "EPOCH 25\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92518702  0.22237156  0.        ]\n",
      " [-0.04908246  0.53585437  0.        ]\n",
      " [-0.04991085 -1.57152824  0.        ]]\n",
      "[]\n",
      "[[ 0.99083828 -0.77534482]\n",
      " [-0.25655865  0.25808736]\n",
      " [ 0.00895738 -0.26416532]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88066005653182433, 0.1193399434681756]\n",
      "LOSS PER INSTANCE: 2.125779\n",
      "DERIVATIVE LOSS: -8.379424\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.125779\n",
      "EPOCH 26\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92520366  0.2223329   0.        ]\n",
      " [-0.0490991   0.53581571  0.        ]\n",
      " [-0.04989422 -1.57148958  0.        ]]\n",
      "[]\n",
      "[[ 0.99112952 -0.77507993]\n",
      " [-0.25695123  0.2577303 ]\n",
      " [ 0.00926209 -0.26388819]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88067206329945524, 0.11932793670054472]\n",
      "LOSS PER INSTANCE: 2.125880\n",
      "DERIVATIVE LOSS: -8.380267\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.125880\n",
      "EPOCH 27\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92521876  0.22229814  0.        ]\n",
      " [-0.0491142   0.53578094  0.        ]\n",
      " [-0.04987911 -1.57145482  0.        ]]\n",
      "[]\n",
      "[[ 0.99139694 -0.7748355 ]\n",
      " [-0.25731168  0.25740084]\n",
      " [ 0.00954185 -0.26363247]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88068268547712103, 0.11931731452287904]\n",
      "LOSS PER INSTANCE: 2.125969\n",
      "DERIVATIVE LOSS: -8.381013\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.125969\n",
      "EPOCH 28\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92523253  0.22226675  0.        ]\n",
      " [-0.04912798  0.53574955  0.        ]\n",
      " [-0.04986534 -1.57142343  0.        ]]\n",
      "[]\n",
      "[[ 0.99164336 -0.77460922]\n",
      " [-0.25764381  0.25709585]\n",
      " [ 0.00979965 -0.26339575]]\n",
      "SOFTMAX_LAYER\n",
      "[0.8806921266845017, 0.11930787331549826]\n",
      "LOSS PER INSTANCE: 2.126048\n",
      "DERIVATIVE LOSS: -8.381677\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126048\n",
      "EPOCH 29\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92524514  0.22223829  0.        ]\n",
      " [-0.04914059  0.5357211   0.        ]\n",
      " [-0.04985273 -1.57139497  0.        ]]\n",
      "[]\n",
      "[[ 0.99187118 -0.77439912]\n",
      " [-0.25795087  0.25681268]\n",
      " [ 0.01003797 -0.26317596]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88070055432103878, 0.11929944567896113]\n",
      "LOSS PER INSTANCE: 2.126119\n",
      "DERIVATIVE LOSS: -8.382269\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126119\n",
      "EPOCH 30\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92525672  0.22221241  0.        ]\n",
      " [-0.04915217  0.53569522  0.        ]\n",
      " [-0.04984115 -1.57136909  0.        ]]\n",
      "[]\n",
      "[[ 0.99208244 -0.7742035 ]\n",
      " [-0.2582356   0.25654903]\n",
      " [ 0.01025897 -0.26297132]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88070810706732372, 0.11929189293267627]\n",
      "LOSS PER INSTANCE: 2.126182\n",
      "DERIVATIVE LOSS: -8.382799\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126182\n",
      "EPOCH 31\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.9252674   0.22218879  0.        ]\n",
      " [-0.04916284  0.5356716   0.        ]\n",
      " [-0.04983047 -1.57134547  0.        ]]\n",
      "[]\n",
      "[[ 0.9922789  -0.77402089]\n",
      " [-0.25850038  0.25630292]\n",
      " [ 0.01046449 -0.2627803 ]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88071490062644753, 0.11928509937355247]\n",
      "LOSS PER INSTANCE: 2.126239\n",
      "DERIVATIVE LOSS: -8.383277\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126239\n",
      "EPOCH 32\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92527727  0.22216718  0.        ]\n",
      " [-0.04917271  0.53564998  0.        ]\n",
      " [-0.04982061 -1.57132386  0.        ]]\n",
      "[]\n",
      "[[ 0.99246207 -0.77385003]\n",
      " [-0.25874723  0.25607265]\n",
      " [ 0.01065609 -0.26260157]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88072103216379849, 0.11927896783620147]\n",
      "LOSS PER INSTANCE: 2.126290\n",
      "DERIVATIVE LOSS: -8.383708\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126290\n",
      "EPOCH 33\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92528641  0.22214733  0.        ]\n",
      " [-0.04918185  0.53563013  0.        ]\n",
      " [-0.04981146 -1.57130401  0.        ]]\n",
      "[]\n",
      "[[ 0.99263326 -0.7736898 ]\n",
      " [-0.25897795  0.25585671]\n",
      " [ 0.01083516 -0.26243396]]\n",
      "SOFTMAX_LAYER\n",
      "[0.880726583773215, 0.11927341622678507]\n",
      "LOSS PER INSTANCE: 2.126337\n",
      "DERIVATIVE LOSS: -8.384098\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126337\n",
      "EPOCH 34\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92529491  0.22212907  0.        ]\n",
      " [-0.04919036  0.53561187  0.        ]\n",
      " [-0.04980296 -1.57128575  0.        ]]\n",
      "[]\n",
      "[[ 0.99279362 -0.77353923]\n",
      " [-0.25919405  0.2556538 ]\n",
      " [ 0.0110029  -0.26227647]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88073162520699311, 0.11926837479300681]\n",
      "LOSS PER INSTANCE: 2.126379\n",
      "DERIVATIVE LOSS: -8.384452\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126379\n",
      "EPOCH 35\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92530283  0.22211221  0.        ]\n",
      " [-0.04919828  0.53559501  0.        ]\n",
      " [-0.04979504 -1.57126889  0.        ]]\n",
      "[]\n",
      "[[ 0.99294415 -0.77339747]\n",
      " [-0.25939691  0.25546275]\n",
      " [ 0.01116036 -0.26212818]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88073621604379759, 0.11926378395620245]\n",
      "LOSS PER INSTANCE: 2.126418\n",
      "DERIVATIVE LOSS: -8.384775\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126418\n",
      "EPOCH 36\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92531023  0.22209662  0.        ]\n",
      " [-0.04920567  0.53557943  0.        ]\n",
      " [-0.04978764 -1.5712533   0.        ]]\n",
      "[]\n",
      "[[ 0.99308574 -0.77326374]\n",
      " [-0.25958771  0.25528255]\n",
      " [ 0.01130845 -0.26198831]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88074040742340731, 0.11925959257659265]\n",
      "LOSS PER INSTANCE: 2.126453\n",
      "DERIVATIVE LOSS: -8.385070\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126453\n",
      "EPOCH 37\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92531715  0.22208217  0.        ]\n",
      " [-0.0492126   0.53556498  0.        ]\n",
      " [-0.04978072 -1.57123885  0.        ]]\n",
      "[]\n",
      "[[ 0.99321915 -0.7731374 ]\n",
      " [-0.2597675   0.25511229]\n",
      " [ 0.011448   -0.26185615]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88074424344479296, 0.11925575655520711]\n",
      "LOSS PER INSTANCE: 2.126485\n",
      "DERIVATIVE LOSS: -8.385339\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126485\n",
      "EPOCH 38\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92532365  0.22206875  0.        ]\n",
      " [-0.04921909  0.53555155  0.        ]\n",
      " [-0.04977423 -1.57122543  0.        ]]\n",
      "[]\n",
      "[[ 0.99334509 -0.77301782]\n",
      " [-0.2599372   0.25495115]\n",
      " [ 0.01157972 -0.26173108]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88074776230041296, 0.11925223769958708]\n",
      "LOSS PER INSTANCE: 2.126514\n",
      "DERIVATIVE LOSS: -8.385587\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126514\n",
      "EPOCH 39\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92532975  0.22205626  0.        ]\n",
      " [-0.04922519  0.53553906  0.        ]\n",
      " [-0.04976813 -1.57121294  0.        ]]\n",
      "[]\n",
      "[[ 0.99346416 -0.77290448]\n",
      " [-0.26009766  0.25479843]\n",
      " [ 0.01170427 -0.26161254]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88075099720228955, 0.11924900279771042]\n",
      "LOSS PER INSTANCE: 2.126542\n",
      "DERIVATIVE LOSS: -8.385814\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126542\n",
      "EPOCH 40\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92533549  0.22204461  0.        ]\n",
      " [-0.04923093  0.53552741  0.        ]\n",
      " [-0.04976238 -1.57120129  0.        ]]\n",
      "[]\n",
      "[[ 0.99357693 -0.7727969 ]\n",
      " [-0.26024961  0.25465346]\n",
      " [ 0.01182221 -0.26150002]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88075397714255421, 0.11924602285744582]\n",
      "LOSS PER INSTANCE: 2.126567\n",
      "DERIVATIVE LOSS: -8.386024\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126567\n",
      "EPOCH 41\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.9253409   0.22203372  0.        ]\n",
      " [-0.04923634  0.53551653  0.        ]\n",
      " [-0.04975697 -1.5711904   0.        ]]\n",
      "[]\n",
      "[[ 0.99368387 -0.77269465]\n",
      " [-0.26039372  0.25451567]\n",
      " [ 0.01193406 -0.26139307]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88075672752152867, 0.1192432724784713]\n",
      "LOSS PER INSTANCE: 2.126590\n",
      "DERIVATIVE LOSS: -8.386217\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126590\n",
      "EPOCH 42\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92534601  0.22202354  0.        ]\n",
      " [-0.04924145  0.53550634  0.        ]\n",
      " [-0.04975186 -1.57118022  0.        ]]\n",
      "[]\n",
      "[[ 0.99378543 -0.77259733]\n",
      " [-0.26053057  0.25438453]\n",
      " [ 0.01204028 -0.26129128]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88075927066913917, 0.11924072933086081]\n",
      "LOSS PER INSTANCE: 2.126611\n",
      "DERIVATIVE LOSS: -8.386396\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126611\n",
      "EPOCH 43\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92535085  0.22201399  0.        ]\n",
      " [-0.04924629  0.5354968   0.        ]\n",
      " [-0.04974703 -1.57117067  0.        ]]\n",
      "[]\n",
      "[[ 0.99388201 -0.77250459]\n",
      " [-0.26066071  0.25425957]\n",
      " [ 0.01214129 -0.26119429]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88076162627992671, 0.11923837372007333]\n",
      "LOSS PER INSTANCE: 2.126631\n",
      "DERIVATIVE LOSS: -8.386562\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126631\n",
      "EPOCH 44\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92535542  0.22200503  0.        ]\n",
      " [-0.04925087  0.53548784  0.        ]\n",
      " [-0.04974245 -1.57116171  0.        ]]\n",
      "[]\n",
      "[[ 0.99397397 -0.77241612]\n",
      " [-0.26078462  0.25414036]\n",
      " [ 0.01223747 -0.26110176]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88076381177767837, 0.11923618822232161]\n",
      "LOSS PER INSTANCE: 2.126649\n",
      "DERIVATIVE LOSS: -8.386716\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126649\n",
      "EPOCH 45\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92535977  0.22199661  0.        ]\n",
      " [-0.04925521  0.53547941  0.        ]\n",
      " [-0.0497381  -1.57115329  0.        ]]\n",
      "[]\n",
      "[[ 0.99406163 -0.77233162]\n",
      " [-0.26090274  0.25402651]\n",
      " [ 0.01232915 -0.26101339]]\n",
      "SOFTMAX_LAYER\n",
      "[0.8807658426224283, 0.11923415737757166]\n",
      "LOSS PER INSTANCE: 2.126666\n",
      "DERIVATIVE LOSS: -8.386858\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126666\n",
      "EPOCH 46\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92536389  0.22198868  0.        ]\n",
      " [-0.04925933  0.53547148  0.        ]\n",
      " [-0.04973398 -1.57114536  0.        ]]\n",
      "[]\n",
      "[[ 0.99414529 -0.77225084]\n",
      " [-0.26101546  0.25391766]\n",
      " [ 0.01241665 -0.2609289 ]]\n",
      "SOFTMAX_LAYER\n",
      "[0.8807677325700296, 0.11923226742997049]\n",
      "LOSS PER INSTANCE: 2.126682\n",
      "DERIVATIVE LOSS: -8.386991\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126682\n",
      "EPOCH 47\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92536781  0.2219812   0.        ]\n",
      " [-0.04926326  0.53546401  0.        ]\n",
      " [-0.04973006 -1.57113788  0.        ]]\n",
      "[]\n",
      "[[ 0.99422522 -0.77217352]\n",
      " [-0.26112316  0.25381348]\n",
      " [ 0.01250025 -0.26084804]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88076949389250725, 0.11923050610749275]\n",
      "LOSS PER INSTANCE: 2.126697\n",
      "DERIVATIVE LOSS: -8.387115\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126697\n",
      "EPOCH 48\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92537155  0.22197415  0.        ]\n",
      " [-0.04926699  0.53545695  0.        ]\n",
      " [-0.04972632 -1.57113083  0.        ]]\n",
      "[]\n",
      "[[ 0.99430166 -0.77209946]\n",
      " [-0.26122616  0.25371368]\n",
      " [ 0.01258019 -0.26077057]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88077113756583603, 0.11922886243416393]\n",
      "LOSS PER INSTANCE: 2.126710\n",
      "DERIVATIVE LOSS: -8.387231\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126710\n",
      "EPOCH 49\n",
      "TARGET: \n",
      "[ 0.  1.]\n",
      "WEIGHTS:\n",
      "[[-0.92537511  0.22196748  0.        ]\n",
      " [-0.04927055  0.53545028  0.        ]\n",
      " [-0.04972276 -1.57112416  0.        ]]\n",
      "[]\n",
      "[[ 0.99437484 -0.77202844]\n",
      " [-0.26132476  0.25361799]\n",
      " [ 0.01265673 -0.2606963 ]]\n",
      "SOFTMAX_LAYER\n",
      "[0.88077267343053955, 0.11922732656946039]\n",
      "LOSS PER INSTANCE: 2.126723\n",
      "DERIVATIVE LOSS: -8.387339\n",
      "UPDATING WEIGHTS\n",
      "LOSS: 2.126723\n"
     ]
    }
   ],
   "source": [
    "class TanHNN(NN):\n",
    "    \n",
    "    def _activate(self, x):\n",
    "        \"\"\"\n",
    "        Override with TanH\n",
    "        \"\"\"\n",
    "        return np.tanh(x)\n",
    "    \n",
    "    def _derivative_activation(self, x):\n",
    "        \"\"\"\n",
    "        Override with Derivative TanH (1 - tanH squared)\n",
    "        \"\"\"\n",
    "        return 1 - x*x\n",
    "    \n",
    "\"\"\"\n",
    "Run the same test with TanH\n",
    "\"\"\"\n",
    "MLP = TanHNN(2, 1, 2, 2)\n",
    "xor_inputs = [[1, 1], [-1, 1], [-1, -1], [1, -1]]\n",
    "xor_labels = ([1, 0, 1, 0])\n",
    "MLP.train(xor_inputs, xor_labels, epochs=50, lr=.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "def neighborhood2int(n):\n",
    "    \"\"\"\n",
    "    For mapping neighborhoods into integer labels\n",
    "    \"\"\"\n",
    "    return 1 if n == \"Blmngtn\" else 0\n",
    "\n",
    "df = pd.DataFrame.from_csv(\"./data/housing_date_train_2_features.csv\")\n",
    "housing_df = df.loc[df['Neighborhood'].isin([\"BrDale\", \"Blmngtn\"])]\n",
    "\n",
    "# Grab X and its labels as a single matrix\n",
    "dataset = housing_df[[\"LotArea\", \"SalePrice\", \"Neighborhood\"]].as_matrix()\n",
    "\n",
    "# 'shuffle' the matrix to randomize the position of each sample in it\n",
    "np.random.shuffle(dataset)\n",
    "\n",
    "# Not sure why shuffling changed the type, but need to \n",
    "# change the type of each scalar in X for some numpy methods to work\n",
    "X = dataset[:, :2].astype('int64')\n",
    "# Encode the labels\n",
    "y = [neighborhood2int(s) for s in dataset[:, 2]]\n",
    "\n",
    "# Find the length of 80% of the dataset for training data\n",
    "train_length = int(X.shape[0] * 0.8)\n",
    "\n",
    "# split 80%/20% for train and test\n",
    "train_X = X[:train_length]\n",
    "test_X = X[train_length:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
