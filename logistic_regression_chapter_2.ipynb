{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "      LotArea  SalePrice Neighborhood\n",
      "Id                                   \n",
      "220      3010     167240      Blmngtn\n",
      "230      3182     192500      Blmngtn\n",
      "386      3182     192000      Blmngtn\n",
      "444      3922     172500      Blmngtn\n",
      "466      3072     178740      Blmngtn\n",
      "560      3196     234000      Blmngtn\n",
      "598      3922     194201      Blmngtn\n",
      "640      3982     264561      Blmngtn\n",
      "791      3182     160200      Blmngtn\n",
      "852      3196     215000      Blmngtn\n",
      "983      3182     159895      Blmngtn\n",
      "1005     3182     181000      Blmngtn\n",
      "1020     3013     213490      Blmngtn\n",
      "1024     3182     191000      Blmngtn\n",
      "1127     3684     174000      Blmngtn\n",
      "1395     4045     246578      Blmngtn\n",
      "1416     3635     175900      Blmngtn\n",
      "226      1680     112000       BrDale\n",
      "228      1869     106000       BrDale\n",
      "233      1680      94500       BrDale\n",
      "236      1680      89500       BrDale\n",
      "364      1680     118000       BrDale\n",
      "431      1680      85400       BrDale\n",
      "433      1920     122500       BrDale\n",
      "501      1890     113000       BrDale\n",
      "656      1680      88000       BrDale\n",
      "838      1680     100000       BrDale\n",
      "1030     1680     118000       BrDale\n",
      "1105     2016     106000       BrDale\n",
      "1220     1680      91500       BrDale\n",
      "1292     1680     119500       BrDale\n",
      "1335     2368     125000       BrDale\n",
      "1379     1953      83000       BrDale\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.DataFrame.from_csv(\"./data/housing_date_train_2_features.csv\")\n",
    "housing_df = df.loc[df['Neighborhood'].isin([\"BrDale\", \"Blmngtn\"])]\n",
    "\n",
    "# Show me what were working with\n",
    "print(len(housing_df))\n",
    "print(housing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnkYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x107c2a828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(housing_df.LotArea, housing_df.SalePrice)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see how these data points seperate by the neighborhood of each house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEBGRhClpiIhIwv4/QX/8dMwS4YQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b5a97b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "color= ['green' if n == \"BrDale\" else 'red' for n in housing_df.Neighborhood]\n",
    "plt.scatter(housing_df.LotArea, housing_df.SalePrice, color=color)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This data is very easily linearly seperable. Houses in green are in the BrDale neighborhood, and tend to be smaller and cheaper, whereas houses in red are in the Blmngton neighborhood, and tend to be larger and more pricey.\n",
    "\n",
    "### I can draw a quick line through the data to see this easily:\n",
    "\n",
    "## <img src=\"./img/linear_seperability.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid: 0.5\n",
      "loss: 0.69314718056\n",
      "sigmoid: 0.5\n",
      "loss: 0.69314718056\n",
      "sigmoid: 0.5\n",
      "loss: 0.69314718056\n",
      "sigmoid: 0.5\n",
      "loss: 0.69314718056\n",
      "sigmoid: 0.5\n",
      "loss: 0.69314718056\n",
      "sigmoid: 0.5\n",
      "loss: 0.69314718056\n",
      "sigmoid: 0.5\n",
      "loss: 0.69314718056\n",
      "sigmoid: 0.5\n",
      "loss: 0.69314718056\n",
      "sigmoid: 0.5\n",
      "loss: 0.69314718056\n",
      "sigmoid: 0.5\n",
      "loss: 0.69314718056\n",
      "sigmoid: 0.5\n",
      "loss: 0.69314718056\n",
      "sigmoid: 0.5\n",
      "loss: 0.69314718056\n",
      "sigmoid: 0.5\n",
      "loss: 0.69314718056\n",
      "sigmoid: 0.5\n",
      "loss: 0.69314718056\n",
      "sigmoid: 0.5\n",
      "loss: 0.69314718056\n",
      "sigmoid: 0.5\n",
      "loss: 0.69314718056\n",
      "sigmoid: 0.5\n",
      "loss: 0.69314718056\n",
      "sigmoid: 0.5\n",
      "loss: 0.69314718056\n",
      "sigmoid: 0.5\n",
      "loss: 0.69314718056\n",
      "sigmoid: 0.5\n",
      "loss: 0.69314718056\n",
      "sigmoid: 0.5\n",
      "loss: 0.69314718056\n",
      "sigmoid: 0.5\n",
      "loss: 0.69314718056\n",
      "sigmoid: 0.5\n",
      "loss: 0.69314718056\n",
      "sigmoid: 0.5\n",
      "loss: 0.69314718056\n",
      "sigmoid: 0.5\n",
      "loss: 0.69314718056\n",
      "sigmoid: 0.5\n",
      "loss: 0.69314718056\n",
      "sigmoid: 0.5\n",
      "loss: 0.69314718056\n",
      "sigmoid: 0.5\n",
      "loss: 0.69314718056\n",
      "sigmoid: 0.5\n",
      "loss: 0.69314718056\n",
      "sigmoid: 0.5\n",
      "loss: 0.69314718056\n",
      "sigmoid: 0.5\n",
      "loss: 0.69314718056\n",
      "sigmoid: 0.5\n",
      "loss: 0.69314718056\n",
      "sigmoid: 0.5\n",
      "loss: 0.69314718056\n"
     ]
    }
   ],
   "source": [
    "def neighborhood2int(n):\n",
    "    \"\"\"\n",
    "    For mapping neighborhoods into integer labels\n",
    "    \"\"\"\n",
    "    return 1 if n == \"Blmngtn\" else 0\n",
    "\n",
    "def sigmoid(x, w):\n",
    "    \"\"\"\n",
    "    Sigmoid function for \"squashing\" the output into a distribution\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-x.dot(w)))\n",
    "\n",
    "def logistic_loss(y_hat, y):\n",
    "    \"\"\"\n",
    "    Compute the logistic loss\n",
    "    This basically finds the negative of the log probability of class1 - its inverse\n",
    "    \"\"\"\n",
    "    return (-y * np.log(y_hat)) - ((1 - y) * np.log(1 - y_hat))\n",
    "\n",
    "def total_loss(w, X, y):\n",
    "    \"\"\"\n",
    "    Average loss over all examples in a dataset\n",
    "    \"\"\"\n",
    "    y = np.array(y)\n",
    "    return 1/len(X) * sum(logistic_loss(sigmoid(X, w), y))\n",
    "\n",
    "def regularize_feature_space(X):\n",
    "    \"\"\"\n",
    "    Regularize X into smaller numbers in a space where the range of all feature values is comparable,\n",
    "    while retaining their relative distance from one another\n",
    "    \"\"\"\n",
    "    return (X - np.mean(X, axis=0)) / np.std(X, axis=0)\n",
    "\n",
    "\"\"\"\n",
    "Set weights to 0 and 0, this will always return .5 when passed into the sigmoid function\n",
    "Since e^0 is 1, i.e. 1 / 1 + 1\n",
    "Note that no bias parameter has been implemented, this should be inconsequential for this task, but \n",
    "is good to do as a general rule of thumb\n",
    "\"\"\"\n",
    "w = np.zeros(2)\n",
    "for ID, house in housing_df.iterrows():\n",
    "    x = house[[\"LotArea\", \"SalePrice\"]]\n",
    "    y = neighborhood2int(house.Neighborhood)\n",
    "    print(\"sigmoid: \" + str(sigmoid(x, w)))\n",
    "    print(\"loss: \" + str(logistic_loss(sigmoid(x, w), y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.69314718056\n"
     ]
    }
   ],
   "source": [
    "cost = total_loss(w, housing_df[[\"LotArea\", \"SalePrice\"]], [neighborhood2int(y) for y in housing_df.Neighborhood])\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We need to tune the weight parameters w to minimize the cost above.\n",
    "## Now that we have defined a training objective, we need an optimization function, e.g.  gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Cost: 0.69314718056 with weights: [ 0.  0.]\n",
      "Epoch: 2 Cost: 0.56590748825 with weights: [ 0.15500453  0.14661888]\n",
      "Epoch: 3 Cost: 0.474547705428 with weights: [ 0.28665628  0.26998469]\n",
      "Epoch: 4 Cost: 0.40744543953 with weights: [ 0.39960889  0.37484977]\n",
      "Epoch: 5 Cost: 0.356730807896 with weights: [ 0.49785836  0.46529856]\n",
      "Epoch: 6 Cost: 0.317320414103 with weights: [ 0.58449688  0.54446942]\n",
      "Epoch: 7 Cost: 0.285926870946 with weights: [ 0.66184299  0.61469329]\n",
      "Epoch: 8 Cost: 0.260379842192 with weights: [ 0.73163368  0.6776996 ]\n",
      "Epoch: 9 Cost: 0.239207676979 with weights: [ 0.79518503  0.73478679]\n",
      "Epoch: 10 Cost: 0.221385031114 with weights: [ 0.85350961  0.7869457 ]\n",
      "Epoch: 11 Cost: 0.206179098211 with weights: [ 0.90739907  0.8349453 ]\n",
      "Epoch: 12 Cost: 0.193053894659 with weights: [ 0.95748198  0.87939216]\n",
      "Epoch: 13 Cost: 0.181609178627 with weights: [ 1.00426458  0.92077198]\n",
      "Epoch: 14 Cost: 0.171540481357 with weights: [ 1.04815993  0.95947897]\n",
      "Epoch: 15 Cost: 0.162612321428 with weights: [ 1.08950905  0.99583712]\n",
      "Epoch: 16 Cost: 0.154639851095 with weights: [ 1.12859655  1.03011562]\n",
      "Epoch: 17 Cost: 0.147476021304 with weights: [ 1.16566221  1.06254043]\n",
      "Epoch: 18 Cost: 0.14100243711 with weights: [ 1.20090986  1.09330295]\n",
      "Epoch: 19 Cost: 0.135122730516 with weights: [ 1.23451414  1.12256663]\n",
      "Epoch: 20 Cost: 0.129757682407 with weights: [ 1.26662578  1.15047214]\n",
      "Epoch: 21 Cost: 0.124841580434 with weights: [ 1.29737573  1.17714135]\n",
      "Epoch: 22 Cost: 0.120319463951 with weights: [ 1.32687848  1.20268055]\n",
      "Epoch: 23 Cost: 0.116145014785 with weights: [ 1.35523465  1.22718291]\n",
      "Epoch: 24 Cost: 0.112278924463 with weights: [ 1.38253318  1.25073062]\n",
      "Epoch: 25 Cost: 0.108687617287 with weights: [ 1.40885303  1.27339649]\n",
      "Epoch: 26 Cost: 0.105342242192 with weights: [ 1.43426462  1.29524532]\n",
      "Epoch: 27 Cost: 0.102217869785 with weights: [ 1.45883101  1.31633505]\n",
      "Epoch: 28 Cost: 0.0992928475439 with weights: [ 1.48260892  1.33671767]\n",
      "Epoch: 29 Cost: 0.0965482780604 with weights: [ 1.50564949  1.35644002]\n",
      "Epoch: 30 Cost: 0.0939675938199 with weights: [ 1.52799905  1.37554444]\n",
      "Epoch: 31 Cost: 0.0915362083383 with weights: [ 1.54969966  1.3940693 ]\n",
      "Epoch: 32 Cost: 0.08924122814 with weights: [ 1.57078965  1.41204954]\n",
      "Epoch: 33 Cost: 0.087071213563 with weights: [ 1.59130402  1.42951702]\n",
      "Epoch: 34 Cost: 0.0850159790069 with weights: [ 1.61127482  1.44650086]\n",
      "Epoch: 35 Cost: 0.0830664252456 with weights: [ 1.6307315   1.46302779]\n",
      "Epoch: 36 Cost: 0.0812143979584 with weights: [ 1.64970115  1.47912236]\n",
      "Epoch: 37 Cost: 0.0794525678207 with weights: [ 1.66820875  1.49480722]\n",
      "Epoch: 38 Cost: 0.0777743284184 with weights: [ 1.68627742  1.51010326]\n",
      "Epoch: 39 Cost: 0.0761737089682 with weights: [ 1.70392854  1.5250298 ]\n",
      "Epoch: 40 Cost: 0.0746452993996 with weights: [ 1.72118197  1.53960477]\n",
      "Epoch: 41 Cost: 0.0731841858021 with weights: [ 1.73805618  1.55384481]\n",
      "Epoch: 42 Cost: 0.0717858946021 with weights: [ 1.75456835  1.56776541]\n",
      "Epoch: 43 Cost: 0.0704463441217 with weights: [ 1.77073453  1.581381  ]\n",
      "Epoch: 44 Cost: 0.0691618024057 with weights: [ 1.7865697   1.59470506]\n",
      "Epoch: 45 Cost: 0.067928850389 with weights: [ 1.80208788  1.60775017]\n",
      "Epoch: 46 Cost: 0.0667443496317 with weights: [ 1.81730222  1.62052815]\n",
      "Epoch: 47 Cost: 0.0656054139739 with weights: [ 1.83222505  1.63305003]\n",
      "Epoch: 48 Cost: 0.0645093845658 with weights: [ 1.84686795  1.64532621]\n",
      "Epoch: 49 Cost: 0.0634538078116 with weights: [ 1.86124184  1.65736645]\n",
      "Epoch: 50 Cost: 0.062436415839 with weights: [ 1.87535698  1.66917993]\n",
      "Epoch: 51 Cost: 0.0614551091627 with weights: [ 1.88922305  1.68077531]\n",
      "Epoch: 52 Cost: 0.0605079412583 with weights: [ 1.90284922  1.69216076]\n",
      "Epoch: 53 Cost: 0.0595931048063 with weights: [ 1.91624412  1.703344  ]\n",
      "Epoch: 54 Cost: 0.0587089193987 with weights: [ 1.92941593  1.71433232]\n",
      "Epoch: 55 Cost: 0.0578538205283 with weights: [ 1.9423724   1.72513263]\n",
      "Epoch: 56 Cost: 0.057026349709 with weights: [ 1.95512089  1.73575147]\n",
      "Epoch: 57 Cost: 0.0562251455921 with weights: [ 1.96766836  1.74619505]\n",
      "Epoch: 58 Cost: 0.0554489359641 with weights: [ 1.98002145  1.75646926]\n",
      "Epoch: 59 Cost: 0.0546965305248 with weights: [ 1.99218643  1.7665797 ]\n",
      "Epoch: 60 Cost: 0.0539668143591 with weights: [ 2.00416932  1.77653168]\n",
      "Epoch: 61 Cost: 0.0532587420245 with weights: [ 2.01597581  1.78633027]\n",
      "Epoch: 62 Cost: 0.0525713321894 with weights: [ 2.02761134  1.7959803 ]\n",
      "Epoch: 63 Cost: 0.0519036627607 with weights: [ 2.03908111  1.80548637]\n",
      "Epoch: 64 Cost: 0.0512548664519 with weights: [ 2.05039005  1.81485286]\n",
      "Epoch: 65 Cost: 0.0506241267439 with weights: [ 2.06154291  1.82408396]\n",
      "Epoch: 66 Cost: 0.0500106741991 with weights: [ 2.0725442   1.83318367]\n",
      "Epoch: 67 Cost: 0.0494137830934 with weights: [ 2.08339825  1.84215582]\n",
      "Epoch: 68 Cost: 0.048832768334 with weights: [ 2.0941092   1.85100406]\n",
      "Epoch: 69 Cost: 0.0482669826359 with weights: [ 2.10468101  1.8597319 ]\n",
      "Epoch: 70 Cost: 0.0477158139308 with weights: [ 2.11511748  1.8683427 ]\n",
      "Epoch: 71 Cost: 0.0471786829875 with weights: [ 2.12542226  1.87683967]\n",
      "Epoch: 72 Cost: 0.0466550412231 with weights: [ 2.13559884  1.88522589]\n",
      "Epoch: 73 Cost: 0.0461443686882 with weights: [ 2.14565058  1.89350432]\n",
      "Epoch: 74 Cost: 0.0456461722086 with weights: [ 2.15558071  1.90167781]\n",
      "Epoch: 75 Cost: 0.0451599836719 with weights: [ 2.16539232  1.90974908]\n",
      "Epoch: 76 Cost: 0.0446853584428 with weights: [ 2.17508839  1.91772076]\n",
      "Epoch: 77 Cost: 0.0442218738995 with weights: [ 2.18467179  1.92559537]\n",
      "Epoch: 78 Cost: 0.043769128077 with weights: [ 2.19414529  1.93337534]\n",
      "Epoch: 79 Cost: 0.0433267384112 with weights: [ 2.20351154  1.941063  ]\n",
      "Epoch: 80 Cost: 0.0428943405732 with weights: [ 2.2127731   1.94866061]\n",
      "Epoch: 81 Cost: 0.0424715873871 with weights: [ 2.22193244  1.95617033]\n",
      "Epoch: 82 Cost: 0.0420581478249 with weights: [ 2.23099195  1.96359426]\n",
      "Epoch: 83 Cost: 0.0416537060705 with weights: [ 2.23995392  1.97093441]\n",
      "Epoch: 84 Cost: 0.0412579606495 with weights: [ 2.24882057  1.97819273]\n",
      "Epoch: 85 Cost: 0.0408706236173 with weights: [ 2.25759404  1.98537109]\n",
      "Epoch: 86 Cost: 0.0404914198029 with weights: [ 2.26627641  1.99247131]\n",
      "Epoch: 87 Cost: 0.0401200861023 with weights: [ 2.27486966  1.99949514]\n",
      "Epoch: 88 Cost: 0.039756370819 with weights: [ 2.28337575  2.00644427]\n",
      "Epoch: 89 Cost: 0.0394000330472 with weights: [ 2.29179653  2.01332034]\n",
      "Epoch: 90 Cost: 0.0390508420953 with weights: [ 2.30013382  2.02012493]\n",
      "Epoch: 91 Cost: 0.0387085769454 with weights: [ 2.30838937  2.02685957]\n",
      "Epoch: 92 Cost: 0.0383730257473 with weights: [ 2.31656487  2.03352575]\n",
      "Epoch: 93 Cost: 0.0380439853442 with weights: [ 2.32466197  2.0401249 ]\n",
      "Epoch: 94 Cost: 0.0377212608277 with weights: [ 2.33268226  2.04665841]\n",
      "Epoch: 95 Cost: 0.0374046651195 with weights: [ 2.34062728  2.05312763]\n",
      "Epoch: 96 Cost: 0.037094018579 with weights: [ 2.34849854  2.05953387]\n",
      "Epoch: 97 Cost: 0.036789148634 with weights: [ 2.35629748  2.06587838]\n",
      "Epoch: 98 Cost: 0.0364898894338 with weights: [ 2.36402551  2.07216241]\n",
      "Epoch: 99 Cost: 0.0361960815219 with weights: [ 2.37168399  2.07838713]\n",
      "Epoch: 100 Cost: 0.0359075715281 with weights: [ 2.37927426  2.08455371]\n",
      "Epoch: 101 Cost: 0.0356242118787 with weights: [ 2.3867976   2.09066326]\n",
      "Epoch: 102 Cost: 0.0353458605226 with weights: [ 2.39425526  2.09671688]\n",
      "Epoch: 103 Cost: 0.035072380673 with weights: [ 2.40164847  2.10271562]\n",
      "Epoch: 104 Cost: 0.0348036405637 with weights: [ 2.4089784   2.10866052]\n",
      "Epoch: 105 Cost: 0.0345395132189 with weights: [ 2.41624619  2.11455257]\n",
      "Epoch: 106 Cost: 0.0342798762355 with weights: [ 2.42345298  2.12039274]\n",
      "Epoch: 107 Cost: 0.034024611577 with weights: [ 2.43059985  2.12618199]\n",
      "Epoch: 108 Cost: 0.033773605379 with weights: [ 2.43768785  2.13192122]\n",
      "Epoch: 109 Cost: 0.0335267477649 with weights: [ 2.44471801  2.13761133]\n",
      "Epoch: 110 Cost: 0.033283932671 with weights: [ 2.45169134  2.14325319]\n",
      "Epoch: 111 Cost: 0.0330450576811 with weights: [ 2.45860882  2.14884765]\n",
      "Epoch: 112 Cost: 0.0328100238697 with weights: [ 2.46547138  2.15439553]\n",
      "Epoch: 113 Cost: 0.0325787356531 with weights: [ 2.47227997  2.15989764]\n",
      "Epoch: 114 Cost: 0.0323511006483 with weights: [ 2.47903548  2.16535476]\n",
      "Epoch: 115 Cost: 0.0321270295386 with weights: [ 2.48573879  2.17076764]\n",
      "Epoch: 116 Cost: 0.0319064359465 with weights: [ 2.49239075  2.17613704]\n",
      "Epoch: 117 Cost: 0.0316892363127 with weights: [ 2.49899221  2.18146367]\n",
      "Epoch: 118 Cost: 0.0314753497807 with weights: [ 2.50554399  2.18674825]\n",
      "Epoch: 119 Cost: 0.0312646980877 with weights: [ 2.51204686  2.19199145]\n",
      "Epoch: 120 Cost: 0.0310572054604 with weights: [ 2.51850162  2.19719395]\n",
      "Epoch: 121 Cost: 0.0308527985157 with weights: [ 2.52490901  2.20235642]\n",
      "Epoch: 122 Cost: 0.0306514061664 with weights: [ 2.53126979  2.20747947]\n",
      "Epoch: 123 Cost: 0.0304529595311 with weights: [ 2.53758466  2.21256375]\n",
      "Epoch: 124 Cost: 0.0302573918489 with weights: [ 2.54385433  2.21760985]\n",
      "Epoch: 125 Cost: 0.0300646383972 with weights: [ 2.5500795   2.22261837]\n",
      "Epoch: 126 Cost: 0.0298746364139 with weights: [ 2.55626084  2.2275899 ]\n",
      "Epoch: 127 Cost: 0.0296873250231 with weights: [ 2.56239899  2.23252499]\n",
      "Epoch: 128 Cost: 0.029502645164 with weights: [ 2.56849461  2.23742421]\n",
      "Epoch: 129 Cost: 0.029320539523 with weights: [ 2.57454832  2.2422881 ]\n",
      "Epoch: 130 Cost: 0.0291409524693 with weights: [ 2.58056074  2.24711718]\n",
      "Epoch: 131 Cost: 0.0289638299924 with weights: [ 2.58653246  2.25191196]\n",
      "Epoch: 132 Cost: 0.0287891196436 with weights: [ 2.59246407  2.25667297]\n",
      "Epoch: 133 Cost: 0.028616770479 with weights: [ 2.59835614  2.26140068]\n",
      "Epoch: 134 Cost: 0.0284467330053 with weights: [ 2.60420925  2.26609559]\n",
      "Epoch: 135 Cost: 0.0282789591284 with weights: [ 2.61002392  2.27075816]\n",
      "Epoch: 136 Cost: 0.0281134021036 with weights: [ 2.61580071  2.27538886]\n",
      "Epoch: 137 Cost: 0.027950016488 with weights: [ 2.62154014  2.27998815]\n",
      "Epoch: 138 Cost: 0.0277887580954 with weights: [ 2.62724272  2.28455646]\n",
      "Epoch: 139 Cost: 0.0276295839524 with weights: [ 2.63290896  2.28909422]\n",
      "Epoch: 140 Cost: 0.0274724522568 with weights: [ 2.63853935  2.29360187]\n",
      "Epoch: 141 Cost: 0.0273173223376 with weights: [ 2.64413437  2.29807982]\n",
      "Epoch: 142 Cost: 0.0271641546163 with weights: [ 2.6496945   2.30252846]\n",
      "Epoch: 143 Cost: 0.0270129105708 with weights: [ 2.6552202   2.30694822]\n",
      "Epoch: 144 Cost: 0.0268635526991 with weights: [ 2.66071193  2.31133946]\n",
      "Epoch: 145 Cost: 0.0267160444863 with weights: [ 2.66617013  2.31570258]\n",
      "Epoch: 146 Cost: 0.0265703503714 with weights: [ 2.67159523  2.32003795]\n",
      "Epoch: 147 Cost: 0.0264264357161 with weights: [ 2.67698767  2.32434593]\n",
      "Epoch: 148 Cost: 0.0262842667753 with weights: [ 2.68234787  2.3286269 ]\n",
      "Epoch: 149 Cost: 0.0261438106673 with weights: [ 2.68767623  2.33288119]\n",
      "Epoch: 150 Cost: 0.0260050353471 with weights: [ 2.69297316  2.33710915]\n",
      "Epoch: 151 Cost: 0.0258679095787 with weights: [ 2.69823905  2.34131113]\n",
      "Epoch: 152 Cost: 0.0257324029101 with weights: [ 2.7034743   2.34548745]\n",
      "Epoch: 153 Cost: 0.0255984856487 with weights: [ 2.70867927  2.34963845]\n",
      "Epoch: 154 Cost: 0.0254661288368 with weights: [ 2.71385436  2.35376443]\n",
      "Epoch: 155 Cost: 0.0253353042295 with weights: [ 2.71899991  2.35786572]\n",
      "Epoch: 156 Cost: 0.0252059842724 with weights: [ 2.72411629  2.36194263]\n",
      "Epoch: 157 Cost: 0.0250781420803 with weights: [ 2.72920386  2.36599544]\n",
      "Epoch: 158 Cost: 0.024951751417 with weights: [ 2.73426296  2.37002447]\n",
      "Epoch: 159 Cost: 0.0248267866756 with weights: [ 2.73929393  2.37403   ]\n",
      "Epoch: 160 Cost: 0.0247032228593 with weights: [ 2.7442971   2.37801231]\n",
      "Epoch: 161 Cost: 0.0245810355636 with weights: [ 2.74927281  2.38197169]\n",
      "Epoch: 162 Cost: 0.024460200958 with weights: [ 2.75422136  2.38590841]\n",
      "Epoch: 163 Cost: 0.0243406957699 with weights: [ 2.75914309  2.38982275]\n",
      "Epoch: 164 Cost: 0.0242224972675 with weights: [ 2.7640383   2.39371496]\n",
      "Epoch: 165 Cost: 0.0241055832444 with weights: [ 2.76890729  2.3975853 ]\n",
      "Epoch: 166 Cost: 0.0239899320041 with weights: [ 2.77375036  2.40143404]\n",
      "Epoch: 167 Cost: 0.0238755223454 with weights: [ 2.77856781  2.40526142]\n",
      "Epoch: 168 Cost: 0.0237623335484 with weights: [ 2.78335993  2.4090677 ]\n",
      "Epoch: 169 Cost: 0.0236503453604 with weights: [ 2.788127   2.4128531]\n",
      "Epoch: 170 Cost: 0.0235395379829 with weights: [ 2.79286931  2.41661788]\n",
      "Epoch: 171 Cost: 0.0234298920587 with weights: [ 2.79758711  2.42036227]\n",
      "Epoch: 172 Cost: 0.0233213886597 with weights: [ 2.8022807   2.42408649]\n",
      "Epoch: 173 Cost: 0.0232140092749 with weights: [ 2.80695033  2.42779077]\n",
      "Epoch: 174 Cost: 0.0231077357985 with weights: [ 2.81159626  2.43147534]\n",
      "Epoch: 175 Cost: 0.0230025505193 with weights: [ 2.81621875  2.43514041]\n",
      "Epoch: 176 Cost: 0.0228984361095 with weights: [ 2.82081805  2.4387862 ]\n",
      "Epoch: 177 Cost: 0.0227953756147 with weights: [ 2.82539441  2.44241292]\n",
      "Epoch: 178 Cost: 0.022693352443 with weights: [ 2.82994807  2.44602078]\n",
      "Epoch: 179 Cost: 0.0225923503561 with weights: [ 2.83447928  2.44960998]\n",
      "[ 2.83898827  2.45318073]\n"
     ]
    }
   ],
   "source": [
    "def grad_desc(w, X, y, lr=.01, converge=.0001, log=True):\n",
    "    \"\"\"\n",
    "    given a vector of initial weights, features matrix X, correct labels y, \n",
    "    a learning_rate and a change value at which to converge,\n",
    "    We can optimize the weights w with the gradiant descent algorithm\n",
    "    \n",
    "    Regularization could also be added to improve\n",
    "    A decay rate could be tuned as well.\n",
    "    \"\"\"\n",
    "    # Minimize the feature space\n",
    "    X = regularize_feature_space(X)\n",
    "    # Get initial cost\n",
    "    cost = total_loss(w, X, y)\n",
    "    # Set a default cost_change to track for convergence\n",
    "    cost_change = 1.0\n",
    "    gradient = np.zeros(len(w))\n",
    "    i = 1\n",
    "    while(cost_change > converge):\n",
    "        if log:\n",
    "            print(\"Epoch: \" + str(i) + \" Cost: \" + str(cost) + \" with weights: \" + str(w))\n",
    "        old_cost = cost\n",
    "        \"\"\"\n",
    "        Calculate the gradient of the cost function with respect to w\n",
    "        \n",
    "        Note on numpy: (sigmoid(X, w) - y) is a vector of size (33), and X is a matrix of size (33, 2),\n",
    "        so numpy is taking the dot product of the 33 dimensions of the derivative of the loss function and\n",
    "        the 33 dimensions of each feature in x, and returning a vector of those 2 features\n",
    "        \n",
    "        E.g with 3 training examples and made up values:\n",
    "        \n",
    "        [.5, \n",
    "         .5,\n",
    "         .5]\n",
    "         \n",
    "        [[.1, .2],\n",
    "         [.1, .2],\n",
    "         [.1, .2]]\n",
    "         \n",
    "        = [.15, .3]\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        Compute the partial derivative of the loss function \n",
    "        w.r.t w at each dimension of the vector, aka y_hat - y * x\n",
    "        in order to find the gradient\n",
    "        \"\"\"\n",
    "        gradient = (sigmoid(X, w) - y).dot(X)\n",
    "        # Update the parameters to the opposite of the gradiant * the learning rate\n",
    "        w = w - (lr * gradient)\n",
    "        \n",
    "        # Update cost\n",
    "        cost = total_loss(w, X, y)\n",
    "        cost_change = old_cost - cost\n",
    "        i+=1\n",
    "    \n",
    "    return w\n",
    "\n",
    "X = housing_df[[\"LotArea\", \"SalePrice\"]].as_matrix()\n",
    "y = [neighborhood2int(house.Neighborhood) for ID, house in housing_df.iterrows()] \n",
    "print(grad_desc(w, X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"./img/grad_desc_gif.gif\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  3010 167240]\n",
      " [  3182 192500]\n",
      " [  3182 192000]\n",
      " [  3922 172500]\n",
      " [  3072 178740]\n",
      " [  3196 234000]\n",
      " [  3922 194201]\n",
      " [  3982 264561]\n",
      " [  3182 160200]\n",
      " [  3196 215000]\n",
      " [  3182 159895]\n",
      " [  3182 181000]\n",
      " [  3013 213490]\n",
      " [  3182 191000]\n",
      " [  3684 174000]\n",
      " [  4045 246578]\n",
      " [  3635 175900]\n",
      " [  1680 112000]\n",
      " [  1869 106000]\n",
      " [  1680  94500]\n",
      " [  1680  89500]\n",
      " [  1680 118000]\n",
      " [  1680  85400]\n",
      " [  1920 122500]\n",
      " [  1890 113000]\n",
      " [  1680  88000]\n",
      " [  1680 100000]\n",
      " [  1680 118000]\n",
      " [  2016 106000]\n",
      " [  1680  91500]\n",
      " [  1680 119500]\n",
      " [  2368 125000]\n",
      " [  1953  83000]]\n",
      "Epoch: 1 Cost: 0.69314718056 with weights: [ 0.  0.]\n",
      "Epoch: 2 Cost: 0.603327072482 with weights: [ 0.1156266   0.10721565]\n",
      "Epoch: 3 Cost: 0.533812930565 with weights: [ 0.21769874  0.20094944]\n",
      "Epoch: 4 Cost: 0.479400024031 with weights: [ 0.30826606  0.2832789 ]\n",
      "Epoch: 5 Cost: 0.436123864728 with weights: [ 0.38923895  0.356147  ]\n",
      "Epoch: 6 Cost: 0.401104130679 with weights: [ 0.46224729  0.42120887]\n",
      "Epoch: 7 Cost: 0.372282423194 with weights: [ 0.52862423  0.47981292]\n",
      "Epoch: 8 Cost: 0.348186872896 with weights: [ 0.58944127  0.53303749]\n",
      "Epoch: 9 Cost: 0.327754998042 with weights: [ 0.64555611  0.58174094]\n",
      "Epoch: 10 Cost: 0.310209270419 with weights: [ 0.69765731  0.62660848]\n",
      "Epoch: 11 Cost: 0.294971912102 with weights: [ 0.74630132  0.66819075]\n",
      "Epoch: 12 Cost: 0.281606847852 with weights: [ 0.79194158  0.70693401]\n",
      "Epoch: 13 Cost: 0.26977994967 with weights: [ 0.83495093  0.74320327]\n",
      "Epoch: 14 Cost: 0.259231523612 with weights: [ 0.87563869  0.77729983]\n",
      "Epoch: 15 Cost: 0.249757021947 with weights: [ 0.91426377  0.80947468]\n",
      "Epoch: 16 Cost: 0.241193332879 with weights: [ 0.95104467  0.83993869]\n",
      "Epoch: 17 Cost: 0.233408897484 with weights: [ 0.98616729  0.86887047]\n",
      "Epoch: 18 Cost: 0.226296487218 with weights: [ 1.01979091  0.89642244]\n",
      "Epoch: 19 Cost: 0.219767855836 with weights: [ 1.05205298  0.92272562]\n",
      "Epoch: 20 Cost: 0.21374972947 with weights: [ 1.08307287  0.94789334]\n",
      "Epoch: 21 Cost: 0.208180764367 with weights: [ 1.11295485  0.97202427]\n",
      "Epoch: 22 Cost: 0.203009213043 with weights: [ 1.14179051  0.99520477]\n",
      "Epoch: 23 Cost: 0.198191115168 with weights: [ 1.16966071  1.01751088]\n",
      "Epoch: 24 Cost: 0.193688881465 with weights: [ 1.19663722  1.03900981]\n",
      "Epoch: 25 Cost: 0.189470175084 with weights: [ 1.22278397  1.05976132]\n",
      "Epoch: 26 Cost: 0.18550702035 with weights: [ 1.24815818  1.0798187 ]\n",
      "Epoch: 27 Cost: 0.18177508695 with weights: [ 1.27281126  1.09922973]\n",
      "Epoch: 28 Cost: 0.178253110681 with weights: [ 1.29678956  1.11803737]\n",
      "Epoch: 29 Cost: 0.17492242136 with weights: [ 1.32013504  1.13628038]\n",
      "Epoch: 30 Cost: 0.171766555516 with weights: [ 1.34288575  1.15399388]\n",
      "Epoch: 31 Cost: 0.168770936625 with weights: [ 1.36507637  1.17120976]\n",
      "Epoch: 32 Cost: 0.165922609551 with weights: [ 1.38673855  1.1879571 ]\n",
      "Epoch: 33 Cost: 0.163210018764 with weights: [ 1.40790128  1.20426243]\n",
      "Epoch: 34 Cost: 0.16062282214 with weights: [ 1.42859115  1.22015007]\n",
      "Epoch: 35 Cost: 0.15815173385 with weights: [ 1.44883266  1.23564238]\n",
      "Epoch: 36 Cost: 0.155788391166 with weights: [ 1.46864837  1.25075991]\n",
      "Epoch: 37 Cost: 0.153525241034 with weights: [ 1.48805915  1.26552162]\n",
      "Epoch: 38 Cost: 0.151355443067 with weights: [ 1.50708433  1.27994505]\n",
      "Epoch: 39 Cost: 0.149272786248 with weights: [ 1.52574185  1.29404646]\n",
      "Epoch: 40 Cost: 0.147271617119 with weights: [ 1.54404838  1.30784092]\n",
      "Epoch: 41 Cost: 0.145346777658 with weights: [ 1.56201946  1.32134246]\n",
      "Epoch: 42 Cost: 0.143493551333 with weights: [ 1.57966958  1.33456415]\n",
      "Epoch: 43 Cost: 0.141707616119 with weights: [ 1.59701227  1.34751816]\n",
      "Epoch: 44 Cost: 0.139985003422 with weights: [ 1.61406022  1.3602159 ]\n",
      "Epoch: 45 Cost: 0.138322062085 with weights: [ 1.6308253   1.37266803]\n",
      "Epoch: 46 Cost: 0.136715426736 with weights: [ 1.64731867  1.38488454]\n",
      "Epoch: 47 Cost: 0.135161989879 with weights: [ 1.66355082  1.39687482]\n",
      "Epoch: 48 Cost: 0.133658877233 with weights: [ 1.67953159  1.40864768]\n",
      "Epoch: 49 Cost: 0.132203425859 with weights: [ 1.6952703   1.42021144]\n",
      "Epoch: 50 Cost: 0.130793164738 with weights: [ 1.71077572  1.43157391]\n",
      "Epoch: 51 Cost: 0.129425797469 with weights: [ 1.72605613  1.44274247]\n",
      "Epoch: 52 Cost: 0.128099186823 with weights: [ 1.74111937  1.45372409]\n",
      "Epoch: 53 Cost: 0.126811340926 with weights: [ 1.75597286  1.46452537]\n",
      "Epoch: 54 Cost: 0.125560400868 with weights: [ 1.77062362  1.47515254]\n",
      "Epoch: 55 Cost: 0.124344629579 with weights: [ 1.78507833  1.48561153]\n",
      "Epoch: 56 Cost: 0.123162401807 with weights: [ 1.79934331  1.49590793]\n",
      "Epoch: 57 Cost: 0.122012195082 with weights: [ 1.81342459  1.50604707]\n",
      "Epoch: 58 Cost: 0.120892581561 with weights: [ 1.82732788  1.51603401]\n",
      "Epoch: 59 Cost: 0.119802220627 with weights: [ 1.84105864  1.52587357]\n",
      "Epoch: 60 Cost: 0.118739852203 with weights: [ 1.85462205  1.53557033]\n",
      "Epoch: 61 Cost: 0.117704290657 with weights: [ 1.86802308  1.54512864]\n",
      "Epoch: 62 Cost: 0.116694419274 with weights: [ 1.88126644  1.55455268]\n",
      "Epoch: 63 Cost: 0.115709185212 with weights: [ 1.89435665  1.56384642]\n",
      "Epoch: 64 Cost: 0.114747594904 with weights: [ 1.90729803  1.57301364]\n",
      "Epoch: 65 Cost: 0.11380870985 with weights: [ 1.92009469  1.58205798]\n",
      "Epoch: 66 Cost: 0.112891642773 with weights: [ 1.93275059  1.59098289]\n",
      "Epoch: 67 Cost: 0.111995554096 with weights: [ 1.94526951  1.5997917 ]\n",
      "Epoch: 68 Cost: 0.111119648704 with weights: [ 1.95765508  1.60848759]\n",
      "Epoch: 69 Cost: 0.110263172977 with weights: [ 1.96991077  1.61707359]\n",
      "Epoch: 70 Cost: 0.109425412056 with weights: [ 1.98203992  1.62555263]\n",
      "Epoch: 71 Cost: 0.108605687324 with weights: [ 1.99404573  1.63392751]\n",
      "Epoch: 72 Cost: 0.107803354089 with weights: [ 2.00593127  1.64220091]\n",
      "Epoch: 73 Cost: 0.107017799436 with weights: [ 2.01769952  1.65037543]\n",
      "Epoch: 74 Cost: 0.106248440256 with weights: [ 2.0293533   1.65845353]\n",
      "Epoch: 75 Cost: 0.105494721404 with weights: [ 2.04089537  1.66643762]\n",
      "Epoch: 76 Cost: 0.104756114011 with weights: [ 2.05232835  1.67432998]\n",
      "Epoch: 77 Cost: 0.104032113907 with weights: [ 2.06365478  1.68213283]\n",
      "Epoch: 78 Cost: 0.103322240161 with weights: [ 2.07487712  1.68984829]\n",
      "Epoch: 79 Cost: 0.102626033728 with weights: [ 2.08599771  1.69747842]\n",
      "Epoch: 80 Cost: 0.101943056186 with weights: [ 2.09701885  1.7050252 ]\n",
      "Epoch: 81 Cost: 0.101272888564 with weights: [ 2.10794272  1.71249054]\n",
      "Epoch: 82 Cost: 0.100615130249 with weights: [ 2.11877144  1.71987627]\n",
      "Epoch: 83 Cost: 0.0999693979638 with weights: [ 2.12950706  1.72718418]\n",
      "Epoch: 84 Cost: 0.0993353248214 with weights: [ 2.14015158  1.73441598]\n",
      "Epoch: 85 Cost: 0.0987125594328 with weights: [ 2.15070688  1.74157332]\n",
      "Epoch: 86 Cost: 0.098100765078 with weights: [ 2.16117484  1.74865782]\n",
      "Epoch: 87 Cost: 0.0974996189298 with weights: [ 2.17155724  1.75567103]\n",
      "Epoch: 88 Cost: 0.096908811326 with weights: [ 2.18185581  1.76261444]\n",
      "Epoch: 89 Cost: 0.0963280450888 with weights: [ 2.19207224  1.7694895 ]\n",
      "Epoch: 90 Cost: 0.0957570348859 with weights: [ 2.20220815  1.77629762]\n",
      "Epoch: 91 Cost: 0.0951955066309 with weights: [ 2.21226511  1.78304017]\n",
      "Epoch: 92 Cost: 0.0946431969209 with weights: [ 2.22224465  1.78971846]\n",
      "Epoch: 93 Cost: 0.0940998525075 with weights: [ 2.23214826  1.79633376]\n",
      "Epoch: 94 Cost: 0.0935652297996 with weights: [ 2.24197737  1.80288733]\n",
      "Epoch: 95 Cost: 0.0930390943957 with weights: [ 2.25173337  1.80938035]\n",
      "Epoch: 96 Cost: 0.0925212206432 with weights: [ 2.26141762  1.815814  ]\n",
      "Epoch: 97 Cost: 0.0920113912236 with weights: [ 2.27103144  1.82218941]\n",
      "Epoch: 98 Cost: 0.0915093967611 with weights: [ 2.28057608  1.82850767]\n",
      "Epoch: 99 Cost: 0.0910150354535 with weights: [ 2.29005281  1.83476985]\n",
      "Epoch: 100 Cost: 0.090528112724 with weights: [ 2.29946282  1.84097699]\n",
      "Epoch: 101 Cost: 0.0900484408921 with weights: [ 2.30880728  1.84713009]\n",
      "Epoch: 102 Cost: 0.0895758388628 with weights: [ 2.31808733  1.85323014]\n",
      "Epoch: 103 Cost: 0.0891101318322 with weights: [ 2.32730408  1.85927808]\n",
      "Epoch: 104 Cost: 0.08865115101 with weights: [ 2.3364586   1.86527484]\n",
      "Epoch: 105 Cost: 0.0881987333558 with weights: [ 2.34555196  1.87122132]\n",
      "Epoch: 106 Cost: 0.0877527213299 with weights: [ 2.35458515  1.8771184 ]\n",
      "Epoch: 107 Cost: 0.0873129626572 with weights: [ 2.36355919  1.88296692]\n",
      "Epoch: 108 Cost: 0.0868793101026 with weights: [ 2.37247504  1.88876772]\n",
      "Epoch: 109 Cost: 0.0864516212595 with weights: [ 2.38133363  1.8945216 ]\n",
      "Epoch: 110 Cost: 0.0860297583472 with weights: [ 2.3901359   1.90022936]\n",
      "Epoch: 111 Cost: 0.0856135880202 with weights: [ 2.39888273  1.90589175]\n",
      "Epoch: 112 Cost: 0.0852029811858 with weights: [ 2.407575    1.91150953]\n",
      "Epoch: 113 Cost: 0.0847978128314 with weights: [ 2.41621356  1.91708342]\n",
      "Epoch: 114 Cost: 0.0843979618604 with weights: [ 2.42479925  1.92261414]\n",
      "Epoch: 115 Cost: 0.0840033109355 with weights: [ 2.43333286  1.92810237]\n",
      "Epoch: 116 Cost: 0.0836137463302 with weights: [ 2.4418152   1.93354879]\n",
      "Epoch: 117 Cost: 0.0832291577869 with weights: [ 2.45024702  1.93895407]\n",
      "Epoch: 118 Cost: 0.0828494383823 with weights: [ 2.4586291   1.94431883]\n",
      "Epoch: 119 Cost: 0.0824744843983 with weights: [ 2.46696216  1.94964372]\n",
      "Epoch: 120 Cost: 0.0821041951999 with weights: [ 2.47524691  1.95492934]\n",
      "Epoch: 121 Cost: 0.0817384731184 with weights: [ 2.48348407  1.9601763 ]\n",
      "Epoch: 122 Cost: 0.0813772233391 with weights: [ 2.49167432  1.96538516]\n",
      "Epoch: 123 Cost: 0.0810203537959 with weights: [ 2.49981832  1.97055652]\n",
      "Epoch: 124 Cost: 0.0806677750688 with weights: [ 2.50791673  1.97569091]\n",
      "Epoch: 125 Cost: 0.0803194002872 with weights: [ 2.51597019  1.9807889 ]\n",
      "Epoch: 126 Cost: 0.0799751450371 with weights: [ 2.52397934  1.98585101]\n",
      "Epoch: 127 Cost: 0.0796349272723 with weights: [ 2.53194476  1.99087776]\n",
      "Epoch: 128 Cost: 0.07929866723 with weights: [ 2.53986708  1.99586966]\n",
      "Epoch: 129 Cost: 0.078966287349 with weights: [ 2.54774687  2.0008272 ]\n",
      "Epoch: 130 Cost: 0.0786377121925 with weights: [ 2.5555847   2.00575089]\n",
      "Epoch: 131 Cost: 0.078312868374 with weights: [ 2.56338114  2.01064118]\n",
      "Epoch: 132 Cost: 0.0779916844855 with weights: [ 2.57113673  2.01549855]\n",
      "Epoch: 133 Cost: 0.07767409103 with weights: [ 2.57885202  2.02032345]\n",
      "Epoch: 134 Cost: 0.0773600203557 with weights: [ 2.58652752  2.02511634]\n",
      "Epoch: 135 Cost: 0.0770494065937 with weights: [ 2.59416375  2.02987764]\n",
      "Epoch: 136 Cost: 0.0767421855978 with weights: [ 2.60176122  2.03460778]\n",
      "Epoch: 137 Cost: 0.0764382948869 with weights: [ 2.60932042  2.03930719]\n",
      "Epoch: 138 Cost: 0.0761376735899 with weights: [ 2.61684184  2.04397627]\n",
      "Epoch: 139 Cost: 0.0758402623925 with weights: [ 2.62432594  2.04861542]\n",
      "Epoch: 140 Cost: 0.0755460034866 with weights: [ 2.63177319  2.05322504]\n",
      "Epoch: 141 Cost: 0.075254840521 with weights: [ 2.63918406  2.05780552]\n",
      "Epoch: 142 Cost: 0.0749667185546 with weights: [ 2.64655898  2.06235723]\n",
      "Epoch: 143 Cost: 0.0746815840115 with weights: [ 2.65389839  2.06688054]\n",
      "Epoch: 144 Cost: 0.0743993846373 with weights: [ 2.66120273  2.07137582]\n",
      "Epoch: 145 Cost: 0.0741200694577 with weights: [ 2.66847241  2.07584342]\n",
      "Epoch: 146 Cost: 0.073843588738 with weights: [ 2.67570784  2.08028369]\n",
      "Epoch: 147 Cost: 0.073569893945 with weights: [ 2.68290944  2.08469697]\n",
      "Epoch: 148 Cost: 0.0732989377095 with weights: [ 2.6900776  2.0890836]\n",
      "Epoch: 149 Cost: 0.0730306737909 with weights: [ 2.6972127   2.09344391]\n",
      "Epoch: 150 Cost: 0.0727650570424 with weights: [ 2.70431514  2.09777823]\n",
      "Epoch: 151 Cost: 0.0725020433782 with weights: [ 2.71138528  2.10208686]\n",
      "Epoch: 152 Cost: 0.0722415897415 with weights: [ 2.7184235   2.10637012]\n",
      "Epoch: 153 Cost: 0.0719836540738 with weights: [ 2.72543016  2.11062832]\n",
      "Epoch: 154 Cost: 0.0717281952851 with weights: [ 2.73240562  2.11486175]\n",
      "Epoch: 155 Cost: 0.0714751732256 with weights: [ 2.73935021  2.11907071]\n",
      "Epoch: 156 Cost: 0.071224548658 with weights: [ 2.74626429  2.12325548]\n",
      "Epoch: 157 Cost: 0.0709762832309 with weights: [ 2.7531482   2.12741636]\n",
      "Epoch: 158 Cost: 0.0707303394533 with weights: [ 2.76000225  2.13155362]\n",
      "Epoch: 159 Cost: 0.07048668067 with weights: [ 2.76682679  2.13566754]\n",
      "Epoch: 160 Cost: 0.0702452710375 with weights: [ 2.77362212  2.13975837]\n",
      "Epoch: 161 Cost: 0.0700060755009 with weights: [ 2.78038856  2.14382639]\n",
      "Epoch: 162 Cost: 0.0697690597721 with weights: [ 2.78712643  2.14787186]\n",
      "Epoch: 163 Cost: 0.0695341903079 with weights: [ 2.79383601  2.15189503]\n",
      "Epoch: 164 Cost: 0.0693014342894 with weights: [ 2.80051762  2.15589615]\n",
      "Epoch: 165 Cost: 0.0690707596023 with weights: [ 2.80717154  2.15987546]\n",
      "Epoch: 166 Cost: 0.0688421348168 with weights: [ 2.81379806  2.16383322]\n",
      "Epoch: 167 Cost: 0.0686155291695 with weights: [ 2.82039747  2.16776965]\n",
      "Epoch: 168 Cost: 0.0683909125451 with weights: [ 2.82697003  2.171685  ]\n",
      "Epoch: 169 Cost: 0.068168255459 with weights: [ 2.83351604  2.17557948]\n",
      "Epoch: 170 Cost: 0.0679475290401 with weights: [ 2.84003575  2.17945333]\n",
      "Epoch: 171 Cost: 0.0677287050148 with weights: [ 2.84652944  2.18330677]\n",
      "Epoch: 172 Cost: 0.0675117556908 with weights: [ 2.85299736  2.18714002]\n",
      "Epoch: 173 Cost: 0.067296653942 with weights: [ 2.85943976  2.19095329]\n",
      "Epoch: 174 Cost: 0.0670833731937 with weights: [ 2.86585691  2.19474679]\n",
      "Epoch: 175 Cost: 0.0668718874081 with weights: [ 2.87224905  2.19852074]\n",
      "Epoch: 176 Cost: 0.0666621710704 with weights: [ 2.87861642  2.20227533]\n",
      "Epoch: 177 Cost: 0.0664541991752 with weights: [ 2.88495926  2.20601077]\n",
      "Epoch: 178 Cost: 0.066247947214 with weights: [ 2.89127782  2.20972726]\n",
      "Epoch: 179 Cost: 0.0660433911618 with weights: [ 2.89757232  2.21342499]\n",
      "Epoch: 180 Cost: 0.0658405074653 with weights: [ 2.903843    2.21710416]\n",
      "Epoch: 181 Cost: 0.0656392730311 with weights: [ 2.91009008  2.22076494]\n",
      "Epoch: 182 Cost: 0.0654396652138 with weights: [ 2.91631378  2.22440754]\n",
      "Epoch: 183 Cost: 0.0652416618053 with weights: [ 2.92251433  2.22803213]\n",
      "Epoch: 184 Cost: 0.0650452410235 with weights: [ 2.92869193  2.23163889]\n",
      "Epoch: 185 Cost: 0.0648503815023 with weights: [ 2.93484681  2.23522801]\n",
      "Epoch: 186 Cost: 0.064657062281 with weights: [ 2.94097917  2.23879964]\n",
      "Epoch: 187 Cost: 0.0644652627945 with weights: [ 2.94708921  2.24235398]\n",
      "Epoch: 188 Cost: 0.0642749628641 with weights: [ 2.95317715  2.24589118]\n",
      "Epoch: 189 Cost: 0.0640861426877 with weights: [ 2.95924317  2.24941142]\n",
      "Epoch: 190 Cost: 0.063898782831 with weights: [ 2.96528749  2.25291486]\n",
      "Epoch: 191 Cost: 0.0637128642187 with weights: [ 2.97131029  2.25640166]\n",
      "Epoch: 192 Cost: 0.0635283681259 with weights: [ 2.97731176  2.25987198]\n",
      "Epoch: 193 Cost: 0.0633452761703 with weights: [ 2.9832921   2.26332598]\n",
      "Epoch: 194 Cost: 0.0631635703033 with weights: [ 2.98925149  2.26676381]\n",
      "Epoch: 195 Cost: 0.0629832328031 with weights: [ 2.99519011  2.27018563]\n",
      "Epoch: 196 Cost: 0.0628042462664 with weights: [ 3.00110815  2.27359159]\n",
      "Epoch: 197 Cost: 0.0626265936016 with weights: [ 3.00700578  2.27698183]\n",
      "Epoch: 198 Cost: 0.0624502580213 with weights: [ 3.01288318  2.28035651]\n",
      "Epoch: 199 Cost: 0.0622752230355 with weights: [ 3.01874052  2.28371576]\n",
      "Epoch: 200 Cost: 0.0621014724446 with weights: [ 3.02457798  2.28705973]\n",
      "Epoch: 201 Cost: 0.0619289903332 with weights: [ 3.03039573  2.29038856]\n",
      "Epoch: 202 Cost: 0.0617577610634 with weights: [ 3.03619392  2.29370239]\n",
      "Epoch: 203 Cost: 0.0615877692688 with weights: [ 3.04197272  2.29700136]\n",
      "Epoch: 204 Cost: 0.0614189998483 with weights: [ 3.04773231  2.30028559]\n",
      "Epoch: 205 Cost: 0.0612514379601 with weights: [ 3.05347283  2.30355523]\n",
      "Epoch: 206 Cost: 0.0610850690163 with weights: [ 3.05919444  2.30681039]\n",
      "Epoch: 207 Cost: 0.0609198786771 with weights: [ 3.0648973   2.31005122]\n",
      "Epoch: 208 Cost: 0.0607558528455 with weights: [ 3.07058157  2.31327784]\n",
      "Epoch: 209 Cost: 0.0605929776618 with weights: [ 3.07624739  2.31649037]\n",
      "Epoch: 210 Cost: 0.0604312394988 with weights: [ 3.08189491  2.31968894]\n",
      "Epoch: 211 Cost: 0.0602706249565 with weights: [ 3.08752428  2.32287367]\n",
      "Epoch: 212 Cost: 0.0601111208574 with weights: [ 3.09313565  2.32604468]\n",
      "Epoch: 213 Cost: 0.0599527142415 with weights: [ 3.09872917  2.32920209]\n",
      "Epoch: 214 Cost: 0.0597953923621 with weights: [ 3.10430496  2.33234602]\n",
      "Epoch: 215 Cost: 0.0596391426811 with weights: [ 3.10986318  2.33547658]\n",
      "Epoch: 216 Cost: 0.0594839528643 with weights: [ 3.11540395  2.33859389]\n",
      "Epoch: 217 Cost: 0.0593298107777 with weights: [ 3.12092743  2.34169806]\n",
      "Epoch: 218 Cost: 0.0591767044829 with weights: [ 3.12643373  2.3447892 ]\n",
      "Epoch: 219 Cost: 0.0590246222333 with weights: [ 3.131923    2.34786742]\n",
      "Epoch: 220 Cost: 0.0588735524698 with weights: [ 3.13739537  2.35093283]\n",
      "Epoch: 221 Cost: 0.0587234838174 with weights: [ 3.14285096  2.35398554]\n",
      "Epoch: 222 Cost: 0.0585744050811 with weights: [ 3.14828991  2.35702566]\n",
      "Epoch: 223 Cost: 0.0584263052424 with weights: [ 3.15371234  2.36005328]\n",
      "Epoch: 224 Cost: 0.0582791734557 with weights: [ 3.15911837  2.36306851]\n",
      "Epoch: 225 Cost: 0.0581329990446 with weights: [ 3.16450813  2.36607145]\n",
      "Epoch: 226 Cost: 0.0579877714989 with weights: [ 3.16988174  2.36906221]\n",
      "Epoch: 227 Cost: 0.0578434804709 with weights: [ 3.17523933  2.37204088]\n",
      "Epoch: 228 Cost: 0.0577001157724 with weights: [ 3.180581    2.37500756]\n",
      "Epoch: 229 Cost: 0.0575576673716 with weights: [ 3.18590689  2.37796235]\n",
      "Epoch: 230 Cost: 0.0574161253895 with weights: [ 3.19121709  2.38090534]\n",
      "Epoch: 231 Cost: 0.0572754800976 with weights: [ 3.19651174  2.38383663]\n",
      "Epoch: 232 Cost: 0.0571357219147 with weights: [ 3.20179094  2.38675631]\n",
      "Epoch: 233 Cost: 0.0569968414036 with weights: [ 3.2070548   2.38966447]\n",
      "Epoch: 234 Cost: 0.0568588292691 with weights: [ 3.21230344  2.39256121]\n",
      "Epoch: 235 Cost: 0.0567216763544 with weights: [ 3.21753696  2.39544661]\n",
      "Epoch: 236 Cost: 0.0565853736393 with weights: [ 3.22275548  2.39832076]\n",
      "Epoch: 237 Cost: 0.0564499122369 with weights: [ 3.22795909  2.40118375]\n",
      "Epoch: 238 Cost: 0.0563152833914 with weights: [ 3.23314791  2.40403568]\n",
      "Epoch: 239 Cost: 0.0561814784755 with weights: [ 3.23832204  2.40687661]\n",
      "Epoch: 240 Cost: 0.0560484889881 with weights: [ 3.24348158  2.40970665]\n",
      "Epoch: 241 Cost: 0.0559163065518 with weights: [ 3.24862664  2.41252586]\n",
      "Epoch: 242 Cost: 0.0557849229104 with weights: [ 3.25375732  2.41533434]\n",
      "Epoch: 243 Cost: 0.0556543299273 with weights: [ 3.25887371  2.41813217]\n",
      "Epoch: 244 Cost: 0.0555245195825 with weights: [ 3.26397591  2.42091943]\n",
      "Epoch: 245 Cost: 0.0553954839708 with weights: [ 3.26906403  2.42369619]\n",
      "Epoch: 246 Cost: 0.0552672152998 with weights: [ 3.27413815  2.42646254]\n",
      "Epoch: 247 Cost: 0.0551397058876 with weights: [ 3.27919838  2.42921855]\n",
      "Epoch: 248 Cost: 0.0550129481609 with weights: [ 3.28424481  2.43196431]\n",
      "Epoch: 249 Cost: 0.0548869346531 with weights: [ 3.28927753  2.43469989]\n",
      "Epoch: 250 Cost: 0.0547616580021 with weights: [ 3.29429663  2.43742535]\n",
      "Epoch: 251 Cost: 0.0546371109486 with weights: [ 3.29930221  2.44014079]\n",
      "Epoch: 252 Cost: 0.0545132863343 with weights: [ 3.30429435  2.44284627]\n",
      "Epoch: 253 Cost: 0.0543901771001 with weights: [ 3.30927315  2.44554187]\n",
      "Epoch: 254 Cost: 0.0542677762841 with weights: [ 3.31423869  2.44822765]\n",
      "Epoch: 255 Cost: 0.0541460770202 with weights: [ 3.31919106  2.45090369]\n",
      "Epoch: 256 Cost: 0.054025072536 with weights: [ 3.32413035  2.45357006]\n",
      "Epoch: 257 Cost: 0.0539047561517 with weights: [ 3.32905664  2.45622683]\n",
      "Epoch: 258 Cost: 0.0537851212778 with weights: [ 3.33397002  2.45887407]\n",
      "Epoch: 259 Cost: 0.0536661614141 with weights: [ 3.33887056  2.46151184]\n",
      "Epoch: 260 Cost: 0.053547870148 with weights: [ 3.34375836  2.46414022]\n",
      "Epoch: 261 Cost: 0.0534302411528 with weights: [ 3.3486335   2.46675927]\n",
      "Epoch: 262 Cost: 0.0533132681862 with weights: [ 3.35349605  2.46936906]\n",
      "Epoch: 263 Cost: 0.0531969450893 with weights: [ 3.3583461   2.47196965]\n",
      "Epoch: 264 Cost: 0.0530812657844 with weights: [ 3.36318372  2.4745611 ]\n",
      "Epoch: 265 Cost: 0.0529662242745 with weights: [ 3.368009    2.47714349]\n",
      "Epoch: 266 Cost: 0.0528518146412 with weights: [ 3.37282202  2.47971687]\n",
      "Epoch: 267 Cost: 0.0527380310437 with weights: [ 3.37762284  2.48228131]\n",
      "Epoch: 268 Cost: 0.0526248677176 with weights: [ 3.38241154  2.48483687]\n",
      "Epoch: 269 Cost: 0.0525123189732 with weights: [ 3.38718821  2.48738361]\n",
      "Epoch: 270 Cost: 0.0524003791948 with weights: [ 3.39195291  2.48992159]\n",
      "Epoch: 271 Cost: 0.0522890428388 with weights: [ 3.39670572  2.49245087]\n",
      "Epoch: 272 Cost: 0.0521783044333 with weights: [ 3.40144672  2.49497151]\n",
      "Epoch: 273 Cost: 0.0520681585761 with weights: [ 3.40617597  2.49748357]\n",
      "Epoch: 274 Cost: 0.0519585999342 with weights: [ 3.41089354  2.49998711]\n",
      "Epoch: 275 Cost: 0.0518496232423 with weights: [ 3.41559952  2.50248219]\n",
      "Epoch: 276 Cost: 0.0517412233016 with weights: [ 3.42029396  2.50496885]\n",
      "Epoch: 277 Cost: 0.0516333949794 with weights: [ 3.42497694  2.50744717]\n",
      "Epoch: 278 Cost: 0.0515261332069 with weights: [ 3.42964853  2.50991718]\n",
      "Epoch: 279 Cost: 0.0514194329793 with weights: [ 3.43430879  2.51237896]\n",
      "Epoch: 280 Cost: 0.0513132893539 with weights: [ 3.43895779  2.51483256]\n",
      "Epoch: 281 Cost: 0.0512076974498 with weights: [ 3.4435956   2.51727802]\n",
      "Epoch: 282 Cost: 0.0511026524463 with weights: [ 3.44822229  2.5197154 ]\n",
      "Epoch: 283 Cost: 0.0509981495822 with weights: [ 3.45283792  2.52214476]\n",
      "Epoch: 284 Cost: 0.0508941841551 with weights: [ 3.45744256  2.52456615]\n",
      "Epoch: 285 Cost: 0.05079075152 with weights: [ 3.46203626  2.52697962]\n",
      "Epoch: 286 Cost: 0.0506878470887 with weights: [ 3.4666191   2.52938522]\n",
      "Epoch: 287 Cost: 0.0505854663288 with weights: [ 3.47119114  2.531783  ]\n",
      "Epoch: 288 Cost: 0.050483604763 with weights: [ 3.47575243  2.53417302]\n",
      "Epoch: 289 Cost: 0.0503822579679 with weights: [ 3.48030305  2.53655532]\n",
      "Epoch: 290 Cost: 0.0502814215733 with weights: [ 3.48484305  2.53892995]\n",
      "Epoch: 291 Cost: 0.0501810912618 with weights: [ 3.4893725   2.54129696]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "split the data into train/test and then evaluate our predictions\n",
    "\"\"\"\n",
    "train_length = int(X.shape[0] * 0.8)\n",
    "print(X)\n",
    "train_X = X[:train_length]\n",
    "test_X = X[train_length:]\n",
    "\n",
    "optimized_w = grad_desc(w, train_X, y[:train_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[(0.023602723907705209, 0), (0.36476532396583689, 0), (0.89316165699426264, 0), (0.0053868265066288959, 0), (0.42781788844290747, 0), (0.9999720576065334, 0), (0.056126534597605117, 0)]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "preds = [sigmoid(x, optimized_w) for x in regularize_feature_space(test_X)]\n",
    "\n",
    "print(y)\n",
    "# Compare to labels\n",
    "print([(x, y) for x, y in zip(preds, y[train_length:])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(y[:train_length])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The train data was a majority class 1; we need to randomize the data to reduce this bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.04243057  2.42765723]\n",
      "[(0.99886840743682759, 1), (0.079355855303686662, 0), (0.072009437671529855, 0), (0.072009437671529855, 0), (0.99992132080439, 1), (0.017786216790122406, 0), (0.0093954963692334109, 0)]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The train data above was almost exclusively class 1, we need \n",
    "to randomize the train and test data in order to ensure a more representative sample\n",
    "\"\"\"\n",
    "# Grab X and its labels as a single matrix\n",
    "dataset = housing_df[[\"LotArea\", \"SalePrice\", \"Neighborhood\"]].as_matrix()\n",
    "\n",
    "# 'shuffle' the matrix to randomize the position of each sample in it\n",
    "np.random.shuffle(dataset)\n",
    "\n",
    "# Not sure why shuffling changed the type, but need to \n",
    "# change the type of each scalar in X for some numpy methods to work\n",
    "X = dataset[:, :2].astype('int64')\n",
    "# Encode the labels\n",
    "y = [neighborhood2int(s) for s in dataset[:, 2]]\n",
    "\n",
    "# Find the length of 80% of the dataset for training data\n",
    "train_length = int(X.shape[0] * 0.8)\n",
    "\n",
    "# split 80%/20% for train and test\n",
    "train_X = X[:train_length]\n",
    "test_X = X[train_length:]\n",
    "\n",
    "optimized_w = grad_desc(w, train_X, y[:train_length], log=False)\n",
    "\n",
    "print(optimized_w)\n",
    "\n",
    "# Regularize the test values so the inputs are in the same space as the train data\n",
    "test_X = regularize_feature_space(test_X)\n",
    "preds = [sigmoid(x, optimized_w) for x in test_X]\n",
    "\n",
    "# Compare to labels\n",
    "print([(x, y) for x, y in zip(preds, y[train_length:])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
